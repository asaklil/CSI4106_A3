{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CSI 4106 Introduction to Artificial Intelligence** <br/>\n",
    "*Assignment 3: Neural Networks*\n",
    "\n",
    "# Identification\n",
    "\n",
    "Name: Ismail Asaklil <br/>\n",
    "Student Number: 300243534\n",
    "\n",
    "\n",
    "## 1. Exploratory Analysis\n",
    "\n",
    "### Loading the dataset\n",
    "\n",
    "A custom dataset has been created for this assignment. It has been made available on a public GitHub repository:\n",
    "\n",
    "- [github.com/turcotte/csi4106-f24/tree/main/assignments-data/a3](https://github.com/turcotte/csi4106-f24/tree/main/assignments-data/a3)\n",
    "\n",
    "Access and read the dataset directly from this GitHub repository in your Jupyter notebook.\n",
    "\n",
    "You can use this code cell for you import statements and other initializations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>453</th>\n",
       "      <th>454</th>\n",
       "      <th>455</th>\n",
       "      <th>456</th>\n",
       "      <th>457</th>\n",
       "      <th>458</th>\n",
       "      <th>459</th>\n",
       "      <th>460</th>\n",
       "      <th>461</th>\n",
       "      <th>462</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.1685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.0674</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.1573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 463 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0       1       2       3       4       5       6       7       8    \\\n",
       "0    2  0.0000  0.0556  0.0000  0.0556  0.1111  0.0000  0.0556  0.0000   \n",
       "1    2  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "2    2  0.1905  0.0000  0.3333  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "3    2  0.0225  0.0000  0.0112  0.1348  0.0000  0.0112  0.1348  0.0112   \n",
       "4    2  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "\n",
       "      9    ...     453     454     455     456     457     458  459     460  \\\n",
       "0  0.0000  ...  0.1667  0.2222  0.0000  0.0000  0.1667  0.0000  0.0  0.0000   \n",
       "1  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0  0.0000   \n",
       "2  0.2857  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0  0.1905   \n",
       "3  0.1685  ...  0.0000  0.0787  0.0674  0.0112  0.0225  0.1573  0.0  0.0225   \n",
       "4  0.0000  ...  0.0000  0.0000  0.0000  0.6667  0.0000  0.0000  0.0  0.0000   \n",
       "\n",
       "     461  462  \n",
       "0  0.000  0.0  \n",
       "1  0.000  0.0  \n",
       "2  0.381  0.0  \n",
       "3  0.000  0.0  \n",
       "4  0.000  0.0  \n",
       "\n",
       "[5 rows x 463 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code cell\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url1 = \"https://raw.githubusercontent.com/turcotte/csi4106-f24/refs/heads/main/assignments-data/a3/cb513_train.csv\"\n",
    "url2 = \"https://raw.githubusercontent.com/turcotte/csi4106-f24/refs/heads/main/assignments-data/a3/cb513_valid.csv\"\n",
    "url3 = \"https://raw.githubusercontent.com/turcotte/csi4106-f24/refs/heads/main/assignments-data/a3/cb513_test.csv\"\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(url1, sep=\",\", header=None);\n",
    "df_valid = pd.read_csv(url2, sep=\",\", header=None);\n",
    "df_test = pd.read_csv(url3, sep=\",\", header=None);\n",
    "\n",
    "df_train.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing\n",
    "\n",
    "2. **Shuffling the Rows**:\n",
    "\n",
    "    - Since examples are generated by sliding a window across each protein sequence, most adjacent examples originate from the same protein and share 20 positions. To mitigate the potential negative impact on model training, the initial step involves shuffling the **rows** of the data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>453</th>\n",
       "      <th>454</th>\n",
       "      <th>455</th>\n",
       "      <th>456</th>\n",
       "      <th>457</th>\n",
       "      <th>458</th>\n",
       "      <th>459</th>\n",
       "      <th>460</th>\n",
       "      <th>461</th>\n",
       "      <th>462</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1143</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 463 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0       1       2       3       4       5       6    7       8       9    \\\n",
       "0    0  0.1000  0.0000  0.0000  0.0333  0.1333  0.0333  0.0  0.0000  0.0333   \n",
       "1    2  1.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0  0.0000  0.0000   \n",
       "2    0  0.1143  0.0857  0.0000  0.0000  0.0000  0.0000  0.0  0.0286  0.0000   \n",
       "3    0  0.0909  0.0000  0.0455  0.0000  0.0000  0.0455  0.0  0.0455  0.1364   \n",
       "4    1  0.0000  0.0000  0.0000  0.0000  0.0000  0.7143  0.0  0.0000  0.1429   \n",
       "\n",
       "   ...  453     454  455     456  457     458  459  460  461  462  \n",
       "0  ...  0.0  0.0000  0.0  0.0667  0.0  0.0000  0.0  0.0  0.0  0.0  \n",
       "1  ...  0.0  0.0000  0.0  0.0000  1.0  0.0000  0.0  0.0  0.0  0.0  \n",
       "2  ...  0.0  0.0000  0.0  0.0000  0.0  0.0000  0.0  0.0  0.0  0.0  \n",
       "3  ...  0.0  0.0000  0.0  0.0000  0.0  0.2727  0.0  0.0  0.0  0.0  \n",
       "4  ...  0.0  0.1429  0.0  0.2857  0.0  0.0000  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 463 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code cell\n",
    "# Shuffling the rows of the train dataset\n",
    "df_train=df_train.sample(frac=1).reset_index(drop=True)\n",
    "df_test=df_test.sample(frac=1).reset_index(drop=True)\n",
    "df_valid=df_valid.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Scaling of Numerical Features**:\n",
    "\n",
    "    - Since all 462 features are proportions represented as values between 0 and 1, scaling may not be necessary. In our evaluations, using [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) actually degraded model performance. Within your pipeline, compare the effects of not scaling the data versus applying [MinMaxScaler](https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html). In the interest of time, a single experiment will suffice. It is important to note that when scaling is applied, a uniform method should be used across all columns, given their homogeneous nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of scaling the features is to enhance the performance, and this is by making the features values into a specific range so that the ML algorithms converge. In this test, we will compare the nto scaling vs MinMaxScaler which consists of using the following formula:\n",
    "\n",
    "$$\n",
    "X_{\\text{scaled}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of the regular model:  0.7154198062432723\n",
      "the accuracy of the scaled model:  0.714881593110872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Let us first split the data into features and target for both the train and test datasets\n",
    "X_train = df_train.iloc[:, 1:]\n",
    "y_train = df_train.iloc[:, 0]\n",
    "\n",
    "X_test = df_test.iloc[:, 1:]\n",
    "y_test = df_test.iloc[:, 0]\n",
    "\n",
    "\n",
    "# Here is the scaled data\n",
    "scaler = MinMaxScaler(feature_range=(0, 0.5))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# get the performance \n",
    "def get_performance(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# here we use LogisticRegression as an example\n",
    "model = LogisticRegression()\n",
    "print(\"the accuracy of the regular model: \", get_performance(model, X_train, y_train, X_test, y_test))\n",
    "print(\"the accuracy of the scaled model: \", get_performance(model, X_train_scaled, y_train, X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i have chosen the random range $(0, 0.5)$ as an input for the MinMaxScaler. \n",
    "We can still notice that the performance is quite similar where the model trained on the original dfs scored an accuracy of $0.7154$, whereas the one trained on the scaled data scored an accuracy of $0.7148$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Isolating the Target and the Data**:\n",
    "\n",
    "    - In the CSV files, the target and data are combined. To prepare for our machine learning experiments, separate the training data $X$ and the target vector $y$ for each of the three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I solating the features and the target variable\n",
    "\n",
    "X_train = df_train.iloc[:,1:]\n",
    "y_train = df_train.iloc[:,0]\n",
    "\n",
    "X_valid = df_valid.iloc[:,1:]\n",
    "y_valid = df_valid.iloc[:,0]\n",
    "\n",
    "X_test = df_test.iloc[:,1:]\n",
    "y_test = df_test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development & Evaluation\n",
    "\n",
    "5. **Model Development**:\n",
    "\n",
    "    - **Dummy Model**: Implement a model utilizing the [DummyClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html). This model disregards the input data and predicts the majority class. Such model is sometimes called a straw man model.\n",
    "\n",
    "    - **Basline Model**: As a baseline model, select one of the previously studied machine learning algorithms: Decision Trees, K-Nearest Neighbors (KNN), or Logistic Regression. Use the default parameters provided by scikit-learn to train each model as a baseline. Why did you choose this particular classifier? Why do you think it should be appropriate for this specific task?\n",
    "\n",
    "    - **Neural Network Model**: Utilizing [Keras](https://keras.io) and [TensorFlow](https://www.tensorflow.org), construct a sequential model comprising an input layer, a hidden layer, and an output layer. The input layer should consist of 462 nodes, reflecting the 462 attributes of each example. The hidden layer should include 8 nodes and employ the default activation function. The output layer should contain three nodes, corresponding to the three classes: helix (0), sheet (1), and coil (2). Apply the softmax activation function to the output layer to ensure that the outputs are treated as probabilities, with their sum equaling 1 for each training example.\n",
    "\n",
    "    We therefore have three models: dummy, baseline, and neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the dummy classifier:  0.41065662002152853\n"
     ]
    }
   ],
   "source": [
    "#DummyClassifier \n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dummy_classifier = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_classifier.fit(X_train, y_train)\n",
    "y_pred = dummy_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the dummy classifier: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose Logistic Regression for the baseline model due to its simplicity and effectiveness for classification tasks. It is computationally efficient, easy to implement, and interpretable. Additionaly, it performs well with a large number of features and provides a good baseline for comparing more complex models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the logistic regression classifier:  0.7154198062432723\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the logistic regression classifier: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6365 - loss: 0.8187 - val_accuracy: 0.6801 - val_loss: 0.7423\n",
      "Epoch 2/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7270 - loss: 0.6622 - val_accuracy: 0.7028 - val_loss: 0.7047\n",
      "Epoch 3/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7758 - loss: 0.5515 - val_accuracy: 0.7062 - val_loss: 0.7079\n",
      "Epoch 4/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8336 - loss: 0.4263 - val_accuracy: 0.7031 - val_loss: 0.7658\n",
      "Epoch 5/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8921 - loss: 0.2971 - val_accuracy: 0.6915 - val_loss: 0.8754\n",
      "Epoch 6/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9288 - loss: 0.1994 - val_accuracy: 0.6790 - val_loss: 1.0350\n",
      "Epoch 7/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9513 - loss: 0.1380 - val_accuracy: 0.6673 - val_loss: 1.2439\n",
      "Epoch 8/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9673 - loss: 0.0995 - val_accuracy: 0.6794 - val_loss: 1.4081\n",
      "Epoch 9/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.0790 - val_accuracy: 0.6770 - val_loss: 1.5668\n",
      "Epoch 10/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9800 - loss: 0.0628 - val_accuracy: 0.6695 - val_loss: 1.7452\n",
      "Epoch 11/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9805 - loss: 0.0608 - val_accuracy: 0.6585 - val_loss: 1.9230\n",
      "Epoch 12/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9853 - loss: 0.0462 - val_accuracy: 0.6677 - val_loss: 2.0175\n",
      "Epoch 13/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9843 - loss: 0.0483 - val_accuracy: 0.6638 - val_loss: 2.0917\n",
      "Epoch 14/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9851 - loss: 0.0439 - val_accuracy: 0.6610 - val_loss: 2.1298\n",
      "Epoch 15/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9849 - loss: 0.0450 - val_accuracy: 0.6580 - val_loss: 2.3689\n",
      "Epoch 16/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9881 - loss: 0.0382 - val_accuracy: 0.6616 - val_loss: 2.3598\n",
      "Epoch 17/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9886 - loss: 0.0361 - val_accuracy: 0.6650 - val_loss: 2.5145\n",
      "Epoch 18/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9895 - loss: 0.0345 - val_accuracy: 0.6682 - val_loss: 2.6094\n",
      "Epoch 19/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9882 - loss: 0.0347 - val_accuracy: 0.6632 - val_loss: 2.6881\n",
      "Epoch 20/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 994us/step - accuracy: 0.9890 - loss: 0.0367 - val_accuracy: 0.6647 - val_loss: 2.5982\n",
      "Epoch 21/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9928 - loss: 0.0248 - val_accuracy: 0.6634 - val_loss: 2.8281\n",
      "Epoch 22/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9908 - loss: 0.0294 - val_accuracy: 0.6605 - val_loss: 2.8306\n",
      "Epoch 23/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9911 - loss: 0.0280 - val_accuracy: 0.6727 - val_loss: 2.7765\n",
      "Epoch 24/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9923 - loss: 0.0264 - val_accuracy: 0.6643 - val_loss: 2.9779\n",
      "Epoch 25/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 953us/step - accuracy: 0.9917 - loss: 0.0265 - val_accuracy: 0.6599 - val_loss: 2.8054\n",
      "Epoch 26/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9928 - loss: 0.0236 - val_accuracy: 0.6716 - val_loss: 2.9768\n",
      "Epoch 27/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9921 - loss: 0.0256 - val_accuracy: 0.6689 - val_loss: 2.8970\n",
      "Epoch 28/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9927 - loss: 0.0218 - val_accuracy: 0.6526 - val_loss: 3.0854\n",
      "Epoch 29/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9937 - loss: 0.0207 - val_accuracy: 0.6647 - val_loss: 3.1588\n",
      "Epoch 30/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9933 - loss: 0.0229 - val_accuracy: 0.6651 - val_loss: 3.1098\n",
      "Epoch 31/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9942 - loss: 0.0191 - val_accuracy: 0.6664 - val_loss: 3.1883\n",
      "Epoch 32/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9943 - loss: 0.0186 - val_accuracy: 0.6712 - val_loss: 3.1299\n",
      "Epoch 33/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9930 - loss: 0.0217 - val_accuracy: 0.6716 - val_loss: 3.2250\n",
      "Epoch 34/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9930 - loss: 0.0235 - val_accuracy: 0.6600 - val_loss: 3.3071\n",
      "Epoch 35/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9949 - loss: 0.0170 - val_accuracy: 0.6670 - val_loss: 3.3712\n",
      "Epoch 36/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9951 - loss: 0.0154 - val_accuracy: 0.6659 - val_loss: 3.2409\n",
      "Epoch 37/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9938 - loss: 0.0201 - val_accuracy: 0.6673 - val_loss: 3.3281\n",
      "Epoch 38/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9960 - loss: 0.0132 - val_accuracy: 0.6627 - val_loss: 3.4516\n",
      "Epoch 39/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9930 - loss: 0.0207 - val_accuracy: 0.6709 - val_loss: 3.3526\n",
      "Epoch 40/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9957 - loss: 0.0137 - val_accuracy: 0.6686 - val_loss: 3.4870\n",
      "Epoch 41/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9952 - loss: 0.0154 - val_accuracy: 0.6573 - val_loss: 3.5372\n",
      "Epoch 42/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0182 - val_accuracy: 0.6677 - val_loss: 3.5393\n",
      "Epoch 43/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9964 - loss: 0.0120 - val_accuracy: 0.6605 - val_loss: 3.6424\n",
      "Epoch 44/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 996us/step - accuracy: 0.9953 - loss: 0.0157 - val_accuracy: 0.6676 - val_loss: 3.6405\n",
      "Epoch 45/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 998us/step - accuracy: 0.9951 - loss: 0.0175 - val_accuracy: 0.6654 - val_loss: 3.6461\n",
      "Epoch 46/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9961 - loss: 0.0120 - val_accuracy: 0.6608 - val_loss: 3.8541\n",
      "Epoch 47/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 895us/step - accuracy: 0.9957 - loss: 0.0142 - val_accuracy: 0.6680 - val_loss: 3.6726\n",
      "Epoch 48/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 877us/step - accuracy: 0.9957 - loss: 0.0142 - val_accuracy: 0.6699 - val_loss: 3.6711\n",
      "Epoch 49/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 879us/step - accuracy: 0.9975 - loss: 0.0082 - val_accuracy: 0.6669 - val_loss: 3.6590\n",
      "Epoch 50/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 914us/step - accuracy: 0.9968 - loss: 0.0109 - val_accuracy: 0.6669 - val_loss: 3.8754\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.6791 - loss: 3.9274\n"
     ]
    }
   ],
   "source": [
    "#Neural Network model \n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# Addition of the layers inot our NN model \n",
    "model.add(Dense(462, input_dim=462, activation='relu')) \n",
    "model.add(Dense(8, activation='relu'))  \n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "#Compile the NN\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# here i have chosen 50 epochs and a batch size of 32 because i want to train the model for 50 iterations and i want to use 32 samples to update the model's weights at each iteration\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_valid, y_valid))\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Model Evaluation**:\n",
    "\n",
    "    - Employ cross-validation to assess the performance of the baseline model. Select a small number of folds to prevent excessive computational demands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performed cross validation and displayed the different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: {'fit_time': array([0.83251405, 1.32074881, 1.31347919, 1.07715988, 0.71812296]), 'score_time': array([0.01081395, 0.00673318, 0.00673985, 0.00660205, 0.00742197]), 'test_accuracy': array([0.68582211, 0.6840796 , 0.68965517, 0.68699605, 0.68365071]), 'test_precision': array([0.68582211, 0.6840796 , 0.68965517, 0.68699605, 0.68365071]), 'test_recall': array([0.68582211, 0.6840796 , 0.68965517, 0.68699605, 0.68365071]), 'test_f1_score': array([0.68582211, 0.6840796 , 0.68965517, 0.68699605, 0.68365071])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "\n",
    "# We are going to use the following metrics to evaluate the models\n",
    "metrics ={\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='micro'),\n",
    "    'recall': make_scorer(recall_score, average='micro'),\n",
    "    'f1_score': make_scorer(f1_score, average='micro')\n",
    "}\n",
    "\n",
    "#creating folds for the cross validation\n",
    "k_folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# we are calling the log_reg which is our baseline model we have used ealier\n",
    "# Here im using the cross_validate because i want to use multiple metrics to evaluate the model\n",
    "log_reg_score = cross_validate(log_reg, X_train, y_train, cv=k_folds, scoring=metrics) \n",
    "\n",
    "print(\"Logistic Regression:\", log_reg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice here that the format of the output is not really intuitive. Let us fix that by creating a function that will display in a better way the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold       Accuracy   Precision  Recall     F1-score  \n",
      "1          0.686      0.686      0.686      0.686     \n",
      "2          0.684      0.684      0.684      0.684     \n",
      "3          0.690      0.690      0.690      0.690     \n",
      "4          0.687      0.687      0.687      0.687     \n",
      "5          0.684      0.684      0.684      0.684     \n",
      "\n",
      "Mean values of the metrics\n",
      "Mean       0.686      0.686      0.686      0.686     \n"
     ]
    }
   ],
   "source": [
    "def display_metrics(scores):\n",
    "    # I m using a format print to create a table of the metrics\n",
    "    print(f\"{'Fold':<10} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-score':<10}\")\n",
    "    for i, (accuracy, precision, recall, f1) in enumerate(zip(scores['test_accuracy'], scores['test_precision'], scores['test_recall'], scores['test_f1_score'])):\n",
    "        print(f\"{i+1:<10} {accuracy:<10.3f} {precision:<10.3f} {recall:<10.3f} {f1:<10.3f}\")\n",
    "    print()\n",
    "    print(\"Mean values of the metrics\")\n",
    "    print(f\"{'Mean':<10} {np.mean(scores['test_accuracy']):<10.3f} {np.mean(scores['test_precision']):<10.3f} {np.mean(scores['test_recall']):<10.3f} {np.mean(scores['test_f1_score']):<10.3f}\")\n",
    "\n",
    "display_metrics(log_reg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Neural Network on the validation set:\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.6699 - loss: 3.7518\n",
      "Validation Loss: 3.8754\n",
      "Validation Accuracy: 0.6669\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the Neural Network model\n",
    "print(\"\\nEvaluating Neural Network on the validation set:\")\n",
    "nn_eval = model.evaluate(X_valid, y_valid)\n",
    "print(f\"Validation Loss: {nn_eval[0]:.4f}\")\n",
    "print(f\"Validation Accuracy: {nn_eval[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - **Training neural networks can be time-consuming.** Consequently, their performance is typically assessed once using a validation set. Make sure to not use the test set until the very end of the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Assess the models using metrics such as precision, recall, and F1-score.\n",
    "\n",
    "### Hyperparameter Optimization\n",
    "\n",
    "7. **Baseline Model:**\n",
    "\n",
    "    - To ensure a fair comparison for our baseline model, we will examine how varying hyperparameter values affect its performance. This prevents the erroneous conclusion that neural networks inherently perform better, when in fact, appropriate hyperparameter tuning could enhance the baseline model's performance.\n",
    "\n",
    "    - Focus on the following relevant hyperparameters for each model:\n",
    "\n",
    "        - [DecisionTreeClassifier](https://scikit-learn.org/dev/modules/generated/sklearn.tree.DecisionTreeClassifier.html): `criterion` and `max_depth`.\n",
    "  \n",
    "        - [LogisticRegression](https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html): `penalty`, `max_iter`, and `tol`.\n",
    "  \n",
    "        - [KNeighborsClassifier](https://scikit-learn.org/dev/modules/generated/sklearn.neighbors.KNeighborsClassifier.html): `n_neighbors` and `weights`.\n",
    "\n",
    "    - Employ a grid search strategy or utilize scikit-learn's built-in methods [GridSearchCV](https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.GridSearchCV.html) to thoroughly evaluate all combinations of hyperparameter values. Cross-validation should be used to assess each combination.\n",
    "\n",
    "    - Quantify the performance of each hyperparameter configuration using precision, recall, and F1-score as metrics.\n",
    "\n",
    "    - Analyze the findings and offer insights into which hyperparameter configurations achieved optimal performance for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "15 fits failed out of a total of 75.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/numpy/ma/core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.6870871  0.68696701 0.6870871  0.68696701 0.6870871  0.68696701\n",
      "        nan 0.6870871  0.68696701        nan 0.6870871  0.68696701\n",
      "        nan 0.6870871  0.68696701]\n",
      "  warnings.warn(\n",
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.69538179 0.69534319 0.69538179 0.69534319 0.69538179 0.69534319\n",
      "        nan 0.69538179 0.69534319        nan 0.69538179 0.69534319\n",
      "        nan 0.69538179 0.69534319]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=LogisticRegression(random_state=42), n_jobs=-1,\n",
       "             param_grid=[{&#x27;max_iter&#x27;: [100, 200, 500], &#x27;penalty&#x27;: [&#x27;l2&#x27;, None],\n",
       "                          &#x27;tol&#x27;: [0.0001]},\n",
       "                         {&#x27;max_iter&#x27;: [100, 200, 500],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, None], &#x27;tol&#x27;: [0.0001]}],\n",
       "             refit=&#x27;f1_score&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: make_scorer(accuracy_score, response_method=&#x27;predict&#x27;),\n",
       "                      &#x27;f1_score&#x27;: make_scorer(f1_score, response_method=&#x27;predict&#x27;, average=micro),\n",
       "                      &#x27;precision&#x27;: make_scorer(precision_score, response_method=&#x27;predict&#x27;, average=micro),\n",
       "                      &#x27;recall&#x27;: make_scorer(recall_score, response_method=&#x27;predict&#x27;, average=micro)},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=LogisticRegression(random_state=42), n_jobs=-1,\n",
       "             param_grid=[{&#x27;max_iter&#x27;: [100, 200, 500], &#x27;penalty&#x27;: [&#x27;l2&#x27;, None],\n",
       "                          &#x27;tol&#x27;: [0.0001]},\n",
       "                         {&#x27;max_iter&#x27;: [100, 200, 500],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, None], &#x27;tol&#x27;: [0.0001]}],\n",
       "             refit=&#x27;f1_score&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: make_scorer(accuracy_score, response_method=&#x27;predict&#x27;),\n",
       "                      &#x27;f1_score&#x27;: make_scorer(f1_score, response_method=&#x27;predict&#x27;, average=micro),\n",
       "                      &#x27;precision&#x27;: make_scorer(precision_score, response_method=&#x27;predict&#x27;, average=micro),\n",
       "                      &#x27;recall&#x27;: make_scorer(recall_score, response_method=&#x27;predict&#x27;, average=micro)},\n",
       "             verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: LogisticRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=LogisticRegression(random_state=42), n_jobs=-1,\n",
       "             param_grid=[{'max_iter': [100, 200, 500], 'penalty': ['l2', None],\n",
       "                          'tol': [0.0001]},\n",
       "                         {'max_iter': [100, 200, 500],\n",
       "                          'penalty': ['l1', 'l2', None], 'tol': [0.0001]}],\n",
       "             refit='f1_score', return_train_score=True,\n",
       "             scoring={'accuracy': make_scorer(accuracy_score, response_method='predict'),\n",
       "                      'f1_score': make_scorer(f1_score, response_method='predict', average=micro),\n",
       "                      'precision': make_scorer(precision_score, response_method='predict', average=micro),\n",
       "                      'recall': make_scorer(recall_score, response_method='predict', average=micro)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code cell\n",
    "# Hyperparameter grid for Logistic Regression including default values\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "\n",
    "# We are going to use the following metrics to evaluate the models\n",
    "metrics ={\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='micro'),\n",
    "    'recall': make_scorer(recall_score, average='micro'),\n",
    "    'f1_score': make_scorer(f1_score, average='micro')\n",
    "}\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'penalty': ['l2', None],       # Default is 'l2'\n",
    "        'max_iter': [100, 200, 500],  # Default is 100\n",
    "        'tol': [1e-4]                  # Default is 1e-4\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['l1', 'l2', None], # 'l2' is default\n",
    "        'max_iter': [100, 200, 500],  # Default is 100\n",
    "        'tol': [1e-4]                  # Default is 1e-4\n",
    "    }\n",
    "]\n",
    "\n",
    "# Cross-validation strategy\n",
    "cv_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Grid Search with Cross-Validation\n",
    "grid_search_lr = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=parameters,\n",
    "    cv=cv_folds,\n",
    "    scoring=metrics, # i want to use multiple metrics to evaluate the model\n",
    "    refit='f1_score',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying the GirdSearch strategy, Let us visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "Best F1 Score: 0.6870870970558096\n",
      "\n",
      "Statistics for Penalty: l1\n",
      "Tolerance (tol)      Max Iterations       Mean Precision       Mean Recall          Mean F1 Score       \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0.0001               100                  nan                  nan                  nan                 \n",
      "0.0001               200                  nan                  nan                  nan                 \n",
      "0.0001               500                  nan                  nan                  nan                 \n",
      "\n",
      "Statistics for Penalty: l2\n",
      "Tolerance (tol)      Max Iterations       Mean Precision       Mean Recall          Mean F1 Score       \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0.0001               100                  0.687                0.687                0.687               \n",
      "0.0001               200                  0.687                0.687                0.687               \n",
      "0.0001               500                  0.687                0.687                0.687               \n",
      "0.0001               100                  0.687                0.687                0.687               \n",
      "0.0001               200                  0.687                0.687                0.687               \n",
      "0.0001               500                  0.687                0.687                0.687               \n",
      "\n",
      "Statistics for Penalty: none\n",
      "Tolerance (tol)      Max Iterations       Mean Precision       Mean Recall          Mean F1 Score       \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0.0001               100                  0.687                0.687                0.687               \n",
      "0.0001               200                  0.687                0.687                0.687               \n",
      "0.0001               500                  0.687                0.687                0.687               \n",
      "0.0001               100                  0.687                0.687                0.687               \n",
      "0.0001               200                  0.687                0.687                0.687               \n",
      "0.0001               500                  0.687                0.687                0.687               \n"
     ]
    }
   ],
   "source": [
    "def display_best_params(grid_search_lr):\n",
    "    \"\"\"Display the best parameters and F1 score from grid search.\"\"\"\n",
    "    print(\"Best Parameters:\", grid_search_lr.best_params_)\n",
    "    print(\"Best F1 Score:\", grid_search_lr.best_score_)\n",
    "\n",
    "def process_results(grid_search_lr):\n",
    "    \"\"\"Convert cv_results_ to a DataFrame, process and sort it.\"\"\"\n",
    "    results_df = pd.DataFrame(grid_search_lr.cv_results_)\n",
    "    results_df['param_penalty'] = results_df['param_penalty'].apply(lambda x: 'none' if x is None else x)\n",
    "    return results_df.sort_values(by='mean_test_f1_score', ascending=False)\n",
    "\n",
    "def print_grouped_results(results_df):\n",
    "    \"\"\"Group results by penalty and print detailed statistics.\"\"\"\n",
    "    for penalty, group in results_df.groupby('param_penalty'):\n",
    "        print(f\"\\nStatistics for Penalty: {penalty}\")\n",
    "        print(f\"{'Tolerance (tol)':<20} {'Max Iterations':<20} {'Mean Precision':<20} \"\n",
    "              f\"{'Mean Recall':<20} {'Mean F1 Score':<20}\")\n",
    "        print(\"-\" * 100)\n",
    "\n",
    "        # Sort by F1 score in descending order and print each row\n",
    "        for _, row in group.sort_values(by='mean_test_f1_score', ascending=False).iterrows():\n",
    "            print(f\"{row['param_tol']:<20.4f} {row['param_max_iter']:<20} \"\n",
    "                  f\"{row['mean_test_precision']:<20.3f} {row['mean_test_recall']:<20.3f} \"\n",
    "                  f\"{row['mean_test_f1_score']:<20.3f}\")\n",
    "\n",
    "# Execute the functions\n",
    "display_best_params(grid_search_lr)\n",
    "sorted_results_df = process_results(grid_search_lr)\n",
    "print_grouped_results(sorted_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **Neural Network:**\n",
    "\n",
    "    In our exploration and tuning of neural networks, we focus on the following hyperparameters:\n",
    "\n",
    "    - **Single hidden layer, varying the number of nodes**. \n",
    "\n",
    "        - Start with a single node in the hidden layer. Use a graph to depict the progression of loss and accuracy for both the training and validation sets, with the horizontal axis representing the number of training epochs and the vertical axis showing loss and accuracy. Training this network should be relatively fast, so let's conduct training for 50 epochs. Observing the graph, what do you conclude? Is the network underfitting or overfitting? Why?\n",
    "\n",
    "        - Repeat the above process using 2 and 4 nodes in the hidden layer. Use the same type of graph to document your observations regarding loss and accuracy.\n",
    "\n",
    "        - Start with 8 nodes in the hidden layer and progressively double the number of nodes until it surpasses the number of nodes in the input layer. This results in seven experiments and corresponding graphs for the following configurations: 8, 16, 32, 64, 128, 256, and 512 nodes. Document your observations throughout the process.\n",
    "        \n",
    "        - Ensure that the **number of training epochs** is adequate for **observing an increase in validation loss**. **Tip**: During model development, start with a small number of epochs, such as 5 or 10. Once the model appears to perform well, test with larger values, like 40 or 80 epochs, which proved reasonable in our tests. Based on your observations, consider conducting further experiments, if needed. How many epochs were ultimately necessary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-2b024f231e6d4c0babf83124ab920838.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-2b024f231e6d4c0babf83124ab920838.vega-embed details,\n",
       "  #altair-viz-2b024f231e6d4c0babf83124ab920838.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-2b024f231e6d4c0babf83124ab920838\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-2b024f231e6d4c0babf83124ab920838\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-2b024f231e6d4c0babf83124ab920838\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"vconcat\": [{\"hconcat\": [{\"data\": {\"name\": \"data-111b120d5abf13116f1eaba4f9fb231a\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"title\": \"Accuracy for Model with 1 Hidden Nodes\"}, {\"data\": {\"name\": \"data-36cd56dd133380d80217a0b9a1c097f9\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"title\": \"Loss for Model with 1 Hidden Nodes\"}]}, {\"hconcat\": [{\"data\": {\"name\": \"data-5e61d8eea515dec481e00857f07882d7\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"title\": \"Accuracy for Model with 2 Hidden Nodes\"}, {\"data\": {\"name\": \"data-a283488fc5bd26facea15b7810d36e0b\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"title\": \"Loss for Model with 2 Hidden Nodes\"}]}, {\"hconcat\": [{\"data\": {\"name\": \"data-8bb891dd78e9719e07c55d59f47f1acf\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"title\": \"Accuracy for Model with 4 Hidden Nodes\"}, {\"data\": {\"name\": \"data-28aa2c43d79be16bd049c80064c56317\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"title\": \"Loss for Model with 4 Hidden Nodes\"}]}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-111b120d5abf13116f1eaba4f9fb231a\": [{\"epoch\": 1, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.5134754776954651}, {\"epoch\": 2, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.5871403813362122}, {\"epoch\": 3, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6014478802680969}, {\"epoch\": 4, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6096652746200562}, {\"epoch\": 5, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6137139797210693}, {\"epoch\": 6, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6163558959960938}, {\"epoch\": 7, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6187232732772827}, {\"epoch\": 8, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6202672719955444}, {\"epoch\": 9, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6205074787139893}, {\"epoch\": 10, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6208677291870117}, {\"epoch\": 11, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6211764812469482}, {\"epoch\": 12, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6213995218276978}, {\"epoch\": 13, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.621605396270752}, {\"epoch\": 14, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6212965846061707}, {\"epoch\": 15, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6211936473846436}, {\"epoch\": 16, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.621313750743866}, {\"epoch\": 17, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6212623119354248}, {\"epoch\": 18, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6211422085762024}, {\"epoch\": 19, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6211422085762024}, {\"epoch\": 20, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6212794184684753}, {\"epoch\": 21, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6210907101631165}, {\"epoch\": 22, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6212451457977295}, {\"epoch\": 23, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6210736036300659}, {\"epoch\": 24, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6210564374923706}, {\"epoch\": 25, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6209535002708435}, {\"epoch\": 26, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6209706664085388}, {\"epoch\": 27, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6209363341331482}, {\"epoch\": 28, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6209020018577576}, {\"epoch\": 29, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.620884895324707}, {\"epoch\": 30, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6209020018577576}, {\"epoch\": 31, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.620884895324707}, {\"epoch\": 32, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6208505630493164}, {\"epoch\": 33, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6208162307739258}, {\"epoch\": 34, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6208505630493164}, {\"epoch\": 35, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6208505630493164}, {\"epoch\": 36, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6207647919654846}, {\"epoch\": 37, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6206961870193481}, {\"epoch\": 38, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6207132935523987}, {\"epoch\": 39, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.620730459690094}, {\"epoch\": 40, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6207647919654846}, {\"epoch\": 41, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6208333969116211}, {\"epoch\": 42, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6208505630493164}, {\"epoch\": 43, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6208505630493164}, {\"epoch\": 44, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.620884895324707}, {\"epoch\": 45, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.620884895324707}, {\"epoch\": 46, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6208505630493164}, {\"epoch\": 47, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6209877729415894}, {\"epoch\": 48, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6210049390792847}, {\"epoch\": 49, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6210736036300659}, {\"epoch\": 50, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6210736036300659}, {\"epoch\": 1, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5523012280464172}, {\"epoch\": 2, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5725468993186951}, {\"epoch\": 3, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5840194225311279}, {\"epoch\": 4, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5922526717185974}, {\"epoch\": 5, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5975165367126465}, {\"epoch\": 6, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5994061231613159}, {\"epoch\": 7, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6004859209060669}, {\"epoch\": 8, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6004859209060669}, {\"epoch\": 9, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6003509163856506}, {\"epoch\": 10, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6011607646942139}, {\"epoch\": 11, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6004859209060669}, {\"epoch\": 12, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6008908152580261}, {\"epoch\": 13, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6007558107376099}, {\"epoch\": 14, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6002159714698792}, {\"epoch\": 15, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6010257601737976}, {\"epoch\": 16, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6008908152580261}, {\"epoch\": 17, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6007558107376099}, {\"epoch\": 18, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6004859209060669}, {\"epoch\": 19, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6000809669494629}, {\"epoch\": 20, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5999460220336914}, {\"epoch\": 21, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5996760725975037}, {\"epoch\": 22, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6000809669494629}, {\"epoch\": 23, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6002159714698792}, {\"epoch\": 24, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5998110175132751}, {\"epoch\": 25, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5996760725975037}, {\"epoch\": 26, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5999460220336914}, {\"epoch\": 27, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5999460220336914}, {\"epoch\": 28, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5999460220336914}, {\"epoch\": 29, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5999460220336914}, {\"epoch\": 30, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5999460220336914}, {\"epoch\": 31, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5999460220336914}, {\"epoch\": 32, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6000809669494629}, {\"epoch\": 33, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6002159714698792}, {\"epoch\": 34, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6007558107376099}, {\"epoch\": 35, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6007558107376099}, {\"epoch\": 36, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6007558107376099}, {\"epoch\": 37, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6007558107376099}, {\"epoch\": 38, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6007558107376099}, {\"epoch\": 39, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6004859209060669}, {\"epoch\": 40, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6004859209060669}, {\"epoch\": 41, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6004859209060669}, {\"epoch\": 42, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6004859209060669}, {\"epoch\": 43, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6006208658218384}, {\"epoch\": 44, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6006208658218384}, {\"epoch\": 45, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6006208658218384}, {\"epoch\": 46, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6006208658218384}, {\"epoch\": 47, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6006208658218384}, {\"epoch\": 48, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6006208658218384}, {\"epoch\": 49, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6004859209060669}, {\"epoch\": 50, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.6006208658218384}], \"data-36cd56dd133380d80217a0b9a1c097f9\": [{\"epoch\": 1, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 1.0036251544952393}, {\"epoch\": 2, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.906096875667572}, {\"epoch\": 3, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8881015181541443}, {\"epoch\": 4, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8801876306533813}, {\"epoch\": 5, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.874113917350769}, {\"epoch\": 6, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8694761991500854}, {\"epoch\": 7, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8661831617355347}, {\"epoch\": 8, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8640126585960388}, {\"epoch\": 9, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8626624345779419}, {\"epoch\": 10, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.861825168132782}, {\"epoch\": 11, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8613413572311401}, {\"epoch\": 12, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.861007571220398}, {\"epoch\": 13, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8608148097991943}, {\"epoch\": 14, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8606836795806885}, {\"epoch\": 15, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8605934381484985}, {\"epoch\": 16, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8605177998542786}, {\"epoch\": 17, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8604471683502197}, {\"epoch\": 18, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8603861331939697}, {\"epoch\": 19, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8603396415710449}, {\"epoch\": 20, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8602966070175171}, {\"epoch\": 21, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.860255241394043}, {\"epoch\": 22, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8601965308189392}, {\"epoch\": 23, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8601540923118591}, {\"epoch\": 24, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8601177334785461}, {\"epoch\": 25, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8600757718086243}, {\"epoch\": 26, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.860041081905365}, {\"epoch\": 27, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8600025177001953}, {\"epoch\": 28, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8599680066108704}, {\"epoch\": 29, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8599367737770081}, {\"epoch\": 30, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8599028587341309}, {\"epoch\": 31, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8598727583885193}, {\"epoch\": 32, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8598399758338928}, {\"epoch\": 33, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8598110675811768}, {\"epoch\": 34, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8597811460494995}, {\"epoch\": 35, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8597496151924133}, {\"epoch\": 36, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.859718918800354}, {\"epoch\": 37, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8596912622451782}, {\"epoch\": 38, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8596663475036621}, {\"epoch\": 39, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8596381545066833}, {\"epoch\": 40, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8596130013465881}, {\"epoch\": 41, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8595883846282959}, {\"epoch\": 42, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8595626354217529}, {\"epoch\": 43, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8595379590988159}, {\"epoch\": 44, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8595148324966431}, {\"epoch\": 45, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8594908118247986}, {\"epoch\": 46, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.859464704990387}, {\"epoch\": 47, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8594420552253723}, {\"epoch\": 48, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8594229817390442}, {\"epoch\": 49, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8593988418579102}, {\"epoch\": 50, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8593763113021851}, {\"epoch\": 1, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.9445702433586121}, {\"epoch\": 2, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.9143067002296448}, {\"epoch\": 3, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.9050256609916687}, {\"epoch\": 4, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8989589214324951}, {\"epoch\": 5, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8938656449317932}, {\"epoch\": 6, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8903342485427856}, {\"epoch\": 7, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8879963755607605}, {\"epoch\": 8, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8864961862564087}, {\"epoch\": 9, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8855543732643127}, {\"epoch\": 10, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8849011063575745}, {\"epoch\": 11, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8847002983093262}, {\"epoch\": 12, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8846138715744019}, {\"epoch\": 13, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8844810724258423}, {\"epoch\": 14, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8844444751739502}, {\"epoch\": 15, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8843747973442078}, {\"epoch\": 16, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8843610882759094}, {\"epoch\": 17, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.884336531162262}, {\"epoch\": 18, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.884364128112793}, {\"epoch\": 19, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8844735622406006}, {\"epoch\": 20, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8844636678695679}, {\"epoch\": 21, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.884479284286499}, {\"epoch\": 22, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8844626545906067}, {\"epoch\": 23, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8844538927078247}, {\"epoch\": 24, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845241069793701}, {\"epoch\": 25, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845271468162537}, {\"epoch\": 26, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845241069793701}, {\"epoch\": 27, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845312595367432}, {\"epoch\": 28, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845436573028564}, {\"epoch\": 29, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845294117927551}, {\"epoch\": 30, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845227956771851}, {\"epoch\": 31, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845051527023315}, {\"epoch\": 32, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845075964927673}, {\"epoch\": 33, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845107555389404}, {\"epoch\": 34, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845545053482056}, {\"epoch\": 35, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845498561859131}, {\"epoch\": 36, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845723271369934}, {\"epoch\": 37, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845687508583069}, {\"epoch\": 38, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845647573471069}, {\"epoch\": 39, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845729231834412}, {\"epoch\": 40, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845667243003845}, {\"epoch\": 41, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845725059509277}, {\"epoch\": 42, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845642805099487}, {\"epoch\": 43, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845534324645996}, {\"epoch\": 44, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845664262771606}, {\"epoch\": 45, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845797777175903}, {\"epoch\": 46, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845731616020203}, {\"epoch\": 47, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845728635787964}, {\"epoch\": 48, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845672011375427}, {\"epoch\": 49, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845646381378174}, {\"epoch\": 50, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8845668435096741}], \"data-5e61d8eea515dec481e00857f07882d7\": [{\"epoch\": 1, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6085330247879028}, {\"epoch\": 2, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6884768009185791}, {\"epoch\": 3, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6905868649482727}, {\"epoch\": 4, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6910157799720764}, {\"epoch\": 5, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6910157799720764}, {\"epoch\": 6, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6911015510559082}, {\"epoch\": 7, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.690895676612854}, {\"epoch\": 8, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.690655529499054}, {\"epoch\": 9, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6910672187805176}, {\"epoch\": 10, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6910843849182129}, {\"epoch\": 11, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6910843849182129}, {\"epoch\": 12, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6911701560020447}, {\"epoch\": 13, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6909986138343811}, {\"epoch\": 14, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6910672187805176}, {\"epoch\": 15, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6910843849182129}, {\"epoch\": 16, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.69118732213974}, {\"epoch\": 17, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6913416981697083}, {\"epoch\": 18, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.691478967666626}, {\"epoch\": 19, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6912730932235718}, {\"epoch\": 20, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6914961338043213}, {\"epoch\": 21, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6915132403373718}, {\"epoch\": 22, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6915304064750671}, {\"epoch\": 23, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6916676759719849}, {\"epoch\": 24, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.691770613193512}, {\"epoch\": 25, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6916505098342896}, {\"epoch\": 26, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6917362809181213}, {\"epoch\": 27, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6919078230857849}, {\"epoch\": 28, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6918563842773438}, {\"epoch\": 29, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6919421553611755}, {\"epoch\": 30, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6919249892234802}, {\"epoch\": 31, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6918906569480896}, {\"epoch\": 32, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6919078230857849}, {\"epoch\": 33, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6919935941696167}, {\"epoch\": 34, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6919078230857849}, {\"epoch\": 35, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6918392181396484}, {\"epoch\": 36, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.691770613193512}, {\"epoch\": 37, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6917877793312073}, {\"epoch\": 38, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6919078230857849}, {\"epoch\": 39, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6919249892234802}, {\"epoch\": 40, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6919249892234802}, {\"epoch\": 41, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6919764876365662}, {\"epoch\": 42, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6919935941696167}, {\"epoch\": 43, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6919593214988708}, {\"epoch\": 44, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.692062258720398}, {\"epoch\": 45, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6920450925827026}, {\"epoch\": 46, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6919935941696167}, {\"epoch\": 47, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6921308636665344}, {\"epoch\": 48, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6920793652534485}, {\"epoch\": 49, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6920793652534485}, {\"epoch\": 50, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6920965313911438}, {\"epoch\": 1, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.671750545501709}, {\"epoch\": 2, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6716156005859375}, {\"epoch\": 3, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6722904443740845}, {\"epoch\": 4, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.671480655670166}, {\"epoch\": 5, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6718855500221252}, {\"epoch\": 6, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6712107062339783}, {\"epoch\": 7, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6706708073616028}, {\"epoch\": 8, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6702659130096436}, {\"epoch\": 9, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6705358624458313}, {\"epoch\": 10, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6709407567977905}, {\"epoch\": 11, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6708057522773743}, {\"epoch\": 12, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6706708073616028}, {\"epoch\": 13, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6712107062339783}, {\"epoch\": 14, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6709407567977905}, {\"epoch\": 15, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6706708073616028}, {\"epoch\": 16, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6706708073616028}, {\"epoch\": 17, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6701309084892273}, {\"epoch\": 18, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6702659130096436}, {\"epoch\": 19, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6708057522773743}, {\"epoch\": 20, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6709407567977905}, {\"epoch\": 21, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6709407567977905}, {\"epoch\": 22, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6713456511497498}, {\"epoch\": 23, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6709407567977905}, {\"epoch\": 24, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.671480655670166}, {\"epoch\": 25, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6709407567977905}, {\"epoch\": 26, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6713456511497498}, {\"epoch\": 27, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6722904443740845}, {\"epoch\": 28, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6718855500221252}, {\"epoch\": 29, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6718855500221252}, {\"epoch\": 30, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.671750545501709}, {\"epoch\": 31, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.671750545501709}, {\"epoch\": 32, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6713456511497498}, {\"epoch\": 33, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6712107062339783}, {\"epoch\": 34, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6713456511497498}, {\"epoch\": 35, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6713456511497498}, {\"epoch\": 36, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6713456511497498}, {\"epoch\": 37, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.671075701713562}, {\"epoch\": 38, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6709407567977905}, {\"epoch\": 39, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.671075701713562}, {\"epoch\": 40, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6712107062339783}, {\"epoch\": 41, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6706708073616028}, {\"epoch\": 42, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6709407567977905}, {\"epoch\": 43, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6708057522773743}, {\"epoch\": 44, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6712107062339783}, {\"epoch\": 45, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6712107062339783}, {\"epoch\": 46, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.671075701713562}, {\"epoch\": 47, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.671075701713562}, {\"epoch\": 48, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.671075701713562}, {\"epoch\": 49, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6706708073616028}, {\"epoch\": 50, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6706708073616028}], \"data-a283488fc5bd26facea15b7810d36e0b\": [{\"epoch\": 1, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.9033163189888}, {\"epoch\": 2, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.760560154914856}, {\"epoch\": 3, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.746313750743866}, {\"epoch\": 4, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7428113222122192}, {\"epoch\": 5, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7412983179092407}, {\"epoch\": 6, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7405186891555786}, {\"epoch\": 7, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7400016784667969}, {\"epoch\": 8, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7396090626716614}, {\"epoch\": 9, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.739305317401886}, {\"epoch\": 10, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7390353083610535}, {\"epoch\": 11, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7388014793395996}, {\"epoch\": 12, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7385993003845215}, {\"epoch\": 13, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7384135723114014}, {\"epoch\": 14, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7382463216781616}, {\"epoch\": 15, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7380841374397278}, {\"epoch\": 16, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7379382252693176}, {\"epoch\": 17, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7377883791923523}, {\"epoch\": 18, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7376503348350525}, {\"epoch\": 19, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7375227212905884}, {\"epoch\": 20, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7373969554901123}, {\"epoch\": 21, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7372788190841675}, {\"epoch\": 22, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7371747493743896}, {\"epoch\": 23, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7370723485946655}, {\"epoch\": 24, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7369711995124817}, {\"epoch\": 25, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7368763089179993}, {\"epoch\": 26, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7367822527885437}, {\"epoch\": 27, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7366811633110046}, {\"epoch\": 28, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7365888953208923}, {\"epoch\": 29, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7365049123764038}, {\"epoch\": 30, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7364261746406555}, {\"epoch\": 31, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.736346960067749}, {\"epoch\": 32, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7362720966339111}, {\"epoch\": 33, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7362008094787598}, {\"epoch\": 34, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7361292839050293}, {\"epoch\": 35, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7360637187957764}, {\"epoch\": 36, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.735997200012207}, {\"epoch\": 37, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7359389066696167}, {\"epoch\": 38, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7358741164207458}, {\"epoch\": 39, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7358176112174988}, {\"epoch\": 40, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7357617616653442}, {\"epoch\": 41, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7357035279273987}, {\"epoch\": 42, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.735650360584259}, {\"epoch\": 43, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.735593318939209}, {\"epoch\": 44, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.735542356967926}, {\"epoch\": 45, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.735491156578064}, {\"epoch\": 46, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7354424595832825}, {\"epoch\": 47, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7353963255882263}, {\"epoch\": 48, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7353461980819702}, {\"epoch\": 49, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7353025674819946}, {\"epoch\": 50, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7352596521377563}, {\"epoch\": 1, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.8047212362289429}, {\"epoch\": 2, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7810834050178528}, {\"epoch\": 3, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7768677473068237}, {\"epoch\": 4, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7754068970680237}, {\"epoch\": 5, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7746472358703613}, {\"epoch\": 6, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7744640707969666}, {\"epoch\": 7, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7744254469871521}, {\"epoch\": 8, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7742516994476318}, {\"epoch\": 9, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7740538716316223}, {\"epoch\": 10, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7738993167877197}, {\"epoch\": 11, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7736977338790894}, {\"epoch\": 12, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.773568868637085}, {\"epoch\": 13, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7734376788139343}, {\"epoch\": 14, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7733201384544373}, {\"epoch\": 15, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7731835842132568}, {\"epoch\": 16, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7730900645256042}, {\"epoch\": 17, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.773108959197998}, {\"epoch\": 18, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7730323076248169}, {\"epoch\": 19, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7729628682136536}, {\"epoch\": 20, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7729212045669556}, {\"epoch\": 21, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7727054357528687}, {\"epoch\": 22, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7726563215255737}, {\"epoch\": 23, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7725827097892761}, {\"epoch\": 24, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7725251913070679}, {\"epoch\": 25, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7724685072898865}, {\"epoch\": 26, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7724379897117615}, {\"epoch\": 27, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7724133729934692}, {\"epoch\": 28, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7723866105079651}, {\"epoch\": 29, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7723178863525391}, {\"epoch\": 30, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7722101807594299}, {\"epoch\": 31, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7721884846687317}, {\"epoch\": 32, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7721468210220337}, {\"epoch\": 33, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7721049189567566}, {\"epoch\": 34, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7720653414726257}, {\"epoch\": 35, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7720574140548706}, {\"epoch\": 36, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7720406651496887}, {\"epoch\": 37, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.772040605545044}, {\"epoch\": 38, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7720174789428711}, {\"epoch\": 39, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7720070481300354}, {\"epoch\": 40, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7720041871070862}, {\"epoch\": 41, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7719882726669312}, {\"epoch\": 42, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7719841003417969}, {\"epoch\": 43, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7719627022743225}, {\"epoch\": 44, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7719549536705017}, {\"epoch\": 45, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7719516754150391}, {\"epoch\": 46, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7719073295593262}, {\"epoch\": 47, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7719339728355408}, {\"epoch\": 48, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7718824148178101}, {\"epoch\": 49, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7718717455863953}, {\"epoch\": 50, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7718796730041504}], \"data-8bb891dd78e9719e07c55d59f47f1acf\": [{\"epoch\": 1, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6459659337997437}, {\"epoch\": 2, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6893174052238464}, {\"epoch\": 3, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6910672187805176}, {\"epoch\": 4, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6915304064750671}, {\"epoch\": 5, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6926969885826111}, {\"epoch\": 6, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.69312584400177}, {\"epoch\": 7, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.693417489528656}, {\"epoch\": 8, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6947041749954224}, {\"epoch\": 9, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6948928833007812}, {\"epoch\": 10, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6953389048576355}, {\"epoch\": 11, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6956819891929626}, {\"epoch\": 12, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6959050297737122}, {\"epoch\": 13, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6959393620491028}, {\"epoch\": 14, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6962652802467346}, {\"epoch\": 15, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6962824463844299}, {\"epoch\": 16, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6966426968574524}, {\"epoch\": 17, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6968829035758972}, {\"epoch\": 18, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6967113018035889}, {\"epoch\": 19, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6967628002166748}, {\"epoch\": 20, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.697105884552002}, {\"epoch\": 21, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6971916556358337}, {\"epoch\": 22, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.697260320186615}, {\"epoch\": 23, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6976205706596375}, {\"epoch\": 24, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6978778839111328}, {\"epoch\": 25, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6980322599411011}, {\"epoch\": 26, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6981351971626282}, {\"epoch\": 27, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6981009244918823}, {\"epoch\": 28, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6984783411026001}, {\"epoch\": 29, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6985641121864319}, {\"epoch\": 30, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6986498832702637}, {\"epoch\": 31, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6989243626594543}, {\"epoch\": 32, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6989243626594543}, {\"epoch\": 33, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6988042593002319}, {\"epoch\": 34, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6992674469947815}, {\"epoch\": 35, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6995419263839722}, {\"epoch\": 36, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6998164653778076}, {\"epoch\": 37, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7002967596054077}, {\"epoch\": 38, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7001595497131348}, {\"epoch\": 39, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7002967596054077}, {\"epoch\": 40, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7007085084915161}, {\"epoch\": 41, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.700657069683075}, {\"epoch\": 42, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7007085084915161}, {\"epoch\": 43, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7010344862937927}, {\"epoch\": 44, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.700897216796875}, {\"epoch\": 45, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7012746334075928}, {\"epoch\": 46, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7015491127967834}, {\"epoch\": 47, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7017893195152283}, {\"epoch\": 48, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.701720654964447}, {\"epoch\": 49, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.701772153377533}, {\"epoch\": 50, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7019436955451965}, {\"epoch\": 1, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6667566299438477}, {\"epoch\": 2, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6716156005859375}, {\"epoch\": 3, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6745849847793579}, {\"epoch\": 4, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6713456511497498}, {\"epoch\": 5, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6731002926826477}, {\"epoch\": 6, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6735051870346069}, {\"epoch\": 7, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6732352375984192}, {\"epoch\": 8, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6726953983306885}, {\"epoch\": 9, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6729652881622314}, {\"epoch\": 10, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6737751364707947}, {\"epoch\": 11, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6739100813865662}, {\"epoch\": 12, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6739100813865662}, {\"epoch\": 13, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6745849847793579}, {\"epoch\": 14, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6741800308227539}, {\"epoch\": 15, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6735051870346069}, {\"epoch\": 16, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6732352375984192}, {\"epoch\": 17, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6735051870346069}, {\"epoch\": 18, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6739100813865662}, {\"epoch\": 19, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6741800308227539}, {\"epoch\": 20, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6744499802589417}, {\"epoch\": 21, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6752598285675049}, {\"epoch\": 22, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6755297780036926}, {\"epoch\": 23, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6749898791313171}, {\"epoch\": 24, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6749898791313171}, {\"epoch\": 25, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6749898791313171}, {\"epoch\": 26, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6752598285675049}, {\"epoch\": 27, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6748549342155457}, {\"epoch\": 28, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6756647229194641}, {\"epoch\": 29, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6762046217918396}, {\"epoch\": 30, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6762046217918396}, {\"epoch\": 31, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6759346723556519}, {\"epoch\": 32, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6755297780036926}, {\"epoch\": 33, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6759346723556519}, {\"epoch\": 34, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6747199296951294}, {\"epoch\": 35, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6752598285675049}, {\"epoch\": 36, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6748549342155457}, {\"epoch\": 37, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6756647229194641}, {\"epoch\": 38, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6759346723556519}, {\"epoch\": 39, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6759346723556519}, {\"epoch\": 40, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6762046217918396}, {\"epoch\": 41, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6763395667076111}, {\"epoch\": 42, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6763395667076111}, {\"epoch\": 43, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6768794655799866}, {\"epoch\": 44, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6770144701004028}, {\"epoch\": 45, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6776893138885498}, {\"epoch\": 46, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6767445206642151}, {\"epoch\": 47, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6764745712280273}, {\"epoch\": 48, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6766095161437988}, {\"epoch\": 49, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6768794655799866}, {\"epoch\": 50, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6774193644523621}], \"data-28aa2c43d79be16bd049c80064c56317\": [{\"epoch\": 1, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.8153550624847412}, {\"epoch\": 2, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.739997923374176}, {\"epoch\": 3, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.735342264175415}, {\"epoch\": 4, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7325670123100281}, {\"epoch\": 5, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7304503321647644}, {\"epoch\": 6, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7288320660591125}, {\"epoch\": 7, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7274879217147827}, {\"epoch\": 8, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7264200448989868}, {\"epoch\": 9, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7255242466926575}, {\"epoch\": 10, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7247191667556763}, {\"epoch\": 11, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.724043607711792}, {\"epoch\": 12, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7234742045402527}, {\"epoch\": 13, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7229481339454651}, {\"epoch\": 14, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.722439169883728}, {\"epoch\": 15, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7219770550727844}, {\"epoch\": 16, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7215519547462463}, {\"epoch\": 17, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.721168041229248}, {\"epoch\": 18, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7207699418067932}, {\"epoch\": 19, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7203929424285889}, {\"epoch\": 20, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7200099229812622}, {\"epoch\": 21, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7196566462516785}, {\"epoch\": 22, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7193024158477783}, {\"epoch\": 23, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7189884781837463}, {\"epoch\": 24, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7186617255210876}, {\"epoch\": 25, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.718323826789856}, {\"epoch\": 26, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7180571556091309}, {\"epoch\": 27, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7177759408950806}, {\"epoch\": 28, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7175063490867615}, {\"epoch\": 29, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7172582149505615}, {\"epoch\": 30, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7169912457466125}, {\"epoch\": 31, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7167180776596069}, {\"epoch\": 32, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7164641618728638}, {\"epoch\": 33, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7162319421768188}, {\"epoch\": 34, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7159807682037354}, {\"epoch\": 35, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7157272100448608}, {\"epoch\": 36, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7154812216758728}, {\"epoch\": 37, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7152562141418457}, {\"epoch\": 38, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7150172591209412}, {\"epoch\": 39, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7147855758666992}, {\"epoch\": 40, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7145818471908569}, {\"epoch\": 41, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7143761515617371}, {\"epoch\": 42, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7141488194465637}, {\"epoch\": 43, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7139412760734558}, {\"epoch\": 44, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7137715220451355}, {\"epoch\": 45, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7135917544364929}, {\"epoch\": 46, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7134223580360413}, {\"epoch\": 47, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7132253646850586}, {\"epoch\": 48, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7130029201507568}, {\"epoch\": 49, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7128111124038696}, {\"epoch\": 50, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7125860452651978}, {\"epoch\": 1, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7749367952346802}, {\"epoch\": 2, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.76987624168396}, {\"epoch\": 3, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7676954865455627}, {\"epoch\": 4, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7672920823097229}, {\"epoch\": 5, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7660902142524719}, {\"epoch\": 6, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7658957839012146}, {\"epoch\": 7, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7653906941413879}, {\"epoch\": 8, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7653162479400635}, {\"epoch\": 9, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7649416327476501}, {\"epoch\": 10, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7648937702178955}, {\"epoch\": 11, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7644718885421753}, {\"epoch\": 12, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7641746401786804}, {\"epoch\": 13, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.763859212398529}, {\"epoch\": 14, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7636603713035583}, {\"epoch\": 15, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7632780075073242}, {\"epoch\": 16, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7630138397216797}, {\"epoch\": 17, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7623480558395386}, {\"epoch\": 18, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7620472311973572}, {\"epoch\": 19, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7618048787117004}, {\"epoch\": 20, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7615385055541992}, {\"epoch\": 21, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7612897753715515}, {\"epoch\": 22, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.761038601398468}, {\"epoch\": 23, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7610663771629333}, {\"epoch\": 24, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7609224915504456}, {\"epoch\": 25, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7608507871627808}, {\"epoch\": 26, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7605550289154053}, {\"epoch\": 27, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7603081464767456}, {\"epoch\": 28, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7601611018180847}, {\"epoch\": 29, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7598677277565002}, {\"epoch\": 30, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7598827481269836}, {\"epoch\": 31, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7595756649971008}, {\"epoch\": 32, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7597100138664246}, {\"epoch\": 33, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7595117688179016}, {\"epoch\": 34, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.759524405002594}, {\"epoch\": 35, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7592838406562805}, {\"epoch\": 36, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.759159505367279}, {\"epoch\": 37, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7590452432632446}, {\"epoch\": 38, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7588388323783875}, {\"epoch\": 39, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7588857412338257}, {\"epoch\": 40, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7589051127433777}, {\"epoch\": 41, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7588001489639282}, {\"epoch\": 42, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7585321068763733}, {\"epoch\": 43, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7582104206085205}, {\"epoch\": 44, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7581624388694763}, {\"epoch\": 45, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7578914165496826}, {\"epoch\": 46, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7575584650039673}, {\"epoch\": 47, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7575722336769104}, {\"epoch\": 48, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7572603821754456}, {\"epoch\": 49, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7571584582328796}, {\"epoch\": 50, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7569654583930969}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define the models and number of hidden nodes\n",
    "models_config = [\n",
    "    {'model_name': 'one_node', 'hidden_nodes': 1},\n",
    "    {'model_name': 'two_nodes', 'hidden_nodes': 2},\n",
    "    {'model_name': 'four_nodes', 'hidden_nodes': 4}\n",
    "]\n",
    "\n",
    "def create_and_train_model(hidden_nodes):\n",
    "    \"\"\"Create, compile, and train a model based on the number of hidden nodes.\"\"\"\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=(462,)),\n",
    "        Dense(hidden_nodes, activation='relu'),  # Hidden layer with variable nodes\n",
    "        Dense(3, activation='softmax')  # Output layer with 3 nodes\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=0  # Set to 0 to reduce verbose output during training\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def prepare(history, hidden_nodes):\n",
    "    \"\"\"Prepare the training and validation data for Altair plotting.\"\"\"\n",
    "    # Convert history to DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': range(1, 51),\n",
    "        'training_accuracy': history.history['accuracy'],\n",
    "        'validation_accuracy': history.history['val_accuracy'],\n",
    "        'training_loss': history.history['loss'],\n",
    "        'validation_loss': history.history['val_loss'],\n",
    "        'hidden_nodes': [hidden_nodes] * 50\n",
    "    })\n",
    "    \n",
    "    # Melt the dataframe for better use in Altair\n",
    "    df = df.melt(id_vars=['epoch', 'hidden_nodes'], \n",
    "                 value_vars=['training_accuracy', 'validation_accuracy', 'training_loss', 'validation_loss'],\n",
    "                 var_name='metric', value_name='value')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def plot_training_results(df):\n",
    "    \"\"\"Plot the training and validation accuracy and loss using Altair.\"\"\"\n",
    "    # Accuracy plot\n",
    "    accuracy_chart = alt.Chart(df[df['metric'].str.contains('accuracy')]).mark_line().encode(\n",
    "        x='epoch',\n",
    "        y='value',\n",
    "        color='metric',\n",
    "        column='hidden_nodes',\n",
    "        tooltip=['epoch', 'value', 'metric']\n",
    "    ).properties(title=\"Accuracy for Different Models (Hidden Nodes)\")\n",
    "\n",
    "    # Loss plot\n",
    "    loss_chart = alt.Chart(df[df['metric'].str.contains('loss')]).mark_line().encode(\n",
    "        x='epoch',\n",
    "        y='value',\n",
    "        color='metric',\n",
    "        column='hidden_nodes',\n",
    "        tooltip=['epoch', 'value', 'metric']\n",
    "    ).properties(title=\"Loss for Different Models (Hidden Nodes)\")\n",
    "    \n",
    "    return accuracy_chart, loss_chart\n",
    "\n",
    "# Loop over model configurations (1, 2, and 4 hidden nodes)\n",
    "df_all_models = pd.DataFrame()\n",
    "for config in models_config:\n",
    "    history = create_and_train_model(config['hidden_nodes'])\n",
    "    df_model = prepare(history, config['hidden_nodes'])\n",
    "    df_all_models = pd.concat([df_all_models, df_model], ignore_index=True)\n",
    "\n",
    "# Plot the results\n",
    "accuracy_chart, loss_chart = plot_training_results(df_all_models)\n",
    "\n",
    "\n",
    "# Combine accuracy and loss charts for each model configuration\n",
    "combined_charts = alt.vconcat()\n",
    "\n",
    "for hidden_nodes in df_all_models['hidden_nodes'].unique():\n",
    "    accuracy_chart = alt.Chart(df_all_models[(df_all_models['hidden_nodes'] == hidden_nodes) & (df_all_models['metric'].str.contains('accuracy'))]).mark_line().encode(\n",
    "        x='epoch',\n",
    "        y='value',\n",
    "        color='metric',\n",
    "        tooltip=['epoch', 'value', 'metric']\n",
    "    ).properties(title=f\"Accuracy for Model with {hidden_nodes} Hidden Nodes\")\n",
    "\n",
    "    loss_chart = alt.Chart(df_all_models[(df_all_models['hidden_nodes'] == hidden_nodes) & (df_all_models['metric'].str.contains('loss'))]).mark_line().encode(\n",
    "        x='epoch',\n",
    "        y='value',\n",
    "        color='metric',\n",
    "        tooltip=['epoch', 'value', 'metric']\n",
    "    ).properties(title=f\"Loss for Model with {hidden_nodes} Hidden Nodes\")\n",
    "\n",
    "    combined_charts &= (accuracy_chart | loss_chart)\n",
    "\n",
    "# Display the combined charts\n",
    "combined_charts.display()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graphs we can clearly notice that increasing the number of hidden nodes to 2 and 4 improves the model's ability to learn the relationships in the data, leading to better accuracy on both the training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 8 hidden nodes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 16 hidden nodes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 32 hidden nodes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 64 hidden nodes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 128 hidden nodes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 256 hidden nodes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 512 hidden nodes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-5066378bb39c46f981e8adfdf895885d.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-5066378bb39c46f981e8adfdf895885d.vega-embed details,\n",
       "  #altair-viz-5066378bb39c46f981e8adfdf895885d.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-5066378bb39c46f981e8adfdf895885d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-5066378bb39c46f981e8adfdf895885d\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-5066378bb39c46f981e8adfdf895885d\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-bac143d18396440bb48016cbe45b651a\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"column\": {\"field\": \"hidden_nodes\", \"type\": \"ordinal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}, {\"field\": \"hidden_nodes\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Model Performance: Accuracy & Loss for Different Hidden Node Configurations\", \"width\": 300, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-bac143d18396440bb48016cbe45b651a\": [{\"epoch\": 1, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.6548008918762207}, {\"epoch\": 2, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.6878935098648071}, {\"epoch\": 3, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.6892316341400146}, {\"epoch\": 4, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.6921136975288391}, {\"epoch\": 5, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.6937434673309326}, {\"epoch\": 6, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.6954932808876038}, {\"epoch\": 7, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.6976720094680786}, {\"epoch\": 8, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7001423835754395}, {\"epoch\": 9, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7036935091018677}, {\"epoch\": 10, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7065584659576416}, {\"epoch\": 11, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7093376517295837}, {\"epoch\": 12, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7120310068130493}, {\"epoch\": 13, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7138494849205017}, {\"epoch\": 14, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7155135273933411}, {\"epoch\": 15, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7174692749977112}, {\"epoch\": 16, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7186529636383057}, {\"epoch\": 17, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7192362546920776}, {\"epoch\": 18, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7198538184165955}, {\"epoch\": 19, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7206944227218628}, {\"epoch\": 20, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7220325469970703}, {\"epoch\": 21, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7221012115478516}, {\"epoch\": 22, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7229760885238647}, {\"epoch\": 23, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7239367961883545}, {\"epoch\": 24, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7235937118530273}, {\"epoch\": 25, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7239196300506592}, {\"epoch\": 26, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7242284417152405}, {\"epoch\": 27, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7244343161582947}, {\"epoch\": 28, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7247259616851807}, {\"epoch\": 29, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7250862121582031}, {\"epoch\": 30, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7255837321281433}, {\"epoch\": 31, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7257895469665527}, {\"epoch\": 32, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7262356281280518}, {\"epoch\": 33, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7268703579902649}, {\"epoch\": 34, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7272306084632874}, {\"epoch\": 35, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7274193167686462}, {\"epoch\": 36, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7272992134094238}, {\"epoch\": 37, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.727556586265564}, {\"epoch\": 38, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7274708151817322}, {\"epoch\": 39, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7280197739601135}, {\"epoch\": 40, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7285172939300537}, {\"epoch\": 41, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7281569838523865}, {\"epoch\": 42, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7283285856246948}, {\"epoch\": 43, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7283628582954407}, {\"epoch\": 44, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7287402749061584}, {\"epoch\": 45, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7291176915168762}, {\"epoch\": 46, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7293235659599304}, {\"epoch\": 47, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7299754619598389}, {\"epoch\": 48, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.730370044708252}, {\"epoch\": 49, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7304386496543884}, {\"epoch\": 50, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7305930852890015}, {\"epoch\": 1, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6689161658287048}, {\"epoch\": 2, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6716156005859375}, {\"epoch\": 3, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6716156005859375}, {\"epoch\": 4, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6731002926826477}, {\"epoch\": 5, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6737751364707947}, {\"epoch\": 6, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6726953983306885}, {\"epoch\": 7, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6741800308227539}, {\"epoch\": 8, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6802537441253662}, {\"epoch\": 9, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6860575079917908}, {\"epoch\": 10, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6876771450042725}, {\"epoch\": 11, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6880820393562317}, {\"epoch\": 12, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6886219382286072}, {\"epoch\": 13, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6895667314529419}, {\"epoch\": 14, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6892967820167542}, {\"epoch\": 15, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6887569427490234}, {\"epoch\": 16, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6910514235496521}, {\"epoch\": 17, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6897017359733582}, {\"epoch\": 18, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6903765797615051}, {\"epoch\": 19, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6910514235496521}, {\"epoch\": 20, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6906465291976929}, {\"epoch\": 21, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6919962167739868}, {\"epoch\": 22, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6918612718582153}, {\"epoch\": 23, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6917262673377991}, {\"epoch\": 24, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6921312212944031}, {\"epoch\": 25, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6925361156463623}, {\"epoch\": 26, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6918612718582153}, {\"epoch\": 27, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6925361156463623}, {\"epoch\": 28, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6919962167739868}, {\"epoch\": 29, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.693480908870697}, {\"epoch\": 30, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6937508583068848}, {\"epoch\": 31, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6956404447555542}, {\"epoch\": 32, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6953704953193665}, {\"epoch\": 33, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6940208077430725}, {\"epoch\": 34, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6929410099983215}, {\"epoch\": 35, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.69280606508255}, {\"epoch\": 36, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6937508583068848}, {\"epoch\": 37, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6949656009674072}, {\"epoch\": 38, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6955054402351379}, {\"epoch\": 39, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6961803436279297}, {\"epoch\": 40, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6963152885437012}, {\"epoch\": 41, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6967201828956604}, {\"epoch\": 42, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6972600817680359}, {\"epoch\": 43, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6972600817680359}, {\"epoch\": 44, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6983398795127869}, {\"epoch\": 45, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6990147233009338}, {\"epoch\": 46, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6979349255561829}, {\"epoch\": 47, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6982048749923706}, {\"epoch\": 48, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6963152885437012}, {\"epoch\": 49, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6967201828956604}, {\"epoch\": 50, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6963152885437012}, {\"epoch\": 1, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.802757978439331}, {\"epoch\": 2, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.740449070930481}, {\"epoch\": 3, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.7349887490272522}, {\"epoch\": 4, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.7301960587501526}, {\"epoch\": 5, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.7256304621696472}, {\"epoch\": 6, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.7209758162498474}, {\"epoch\": 7, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.7159114480018616}, {\"epoch\": 8, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.710518479347229}, {\"epoch\": 9, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.7046533226966858}, {\"epoch\": 10, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6990148425102234}, {\"epoch\": 11, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6936671137809753}, {\"epoch\": 12, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6888647079467773}, {\"epoch\": 13, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6847196817398071}, {\"epoch\": 14, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6813437938690186}, {\"epoch\": 15, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6784855127334595}, {\"epoch\": 16, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6760508418083191}, {\"epoch\": 17, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6739066243171692}, {\"epoch\": 18, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6718670129776001}, {\"epoch\": 19, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6699344515800476}, {\"epoch\": 20, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6681046485900879}, {\"epoch\": 21, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6666227579116821}, {\"epoch\": 22, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6652740836143494}, {\"epoch\": 23, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6640216112136841}, {\"epoch\": 24, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6628424525260925}, {\"epoch\": 25, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6617496013641357}, {\"epoch\": 26, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6606512665748596}, {\"epoch\": 27, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6596773266792297}, {\"epoch\": 28, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6588228940963745}, {\"epoch\": 29, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6579249501228333}, {\"epoch\": 30, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6570847034454346}, {\"epoch\": 31, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.656326949596405}, {\"epoch\": 32, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6555352807044983}, {\"epoch\": 33, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6548647880554199}, {\"epoch\": 34, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6541694402694702}, {\"epoch\": 35, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6535975337028503}, {\"epoch\": 36, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6529890298843384}, {\"epoch\": 37, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6524564623832703}, {\"epoch\": 38, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6518599987030029}, {\"epoch\": 39, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6513780355453491}, {\"epoch\": 40, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.650810182094574}, {\"epoch\": 41, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6503508687019348}, {\"epoch\": 42, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6498317718505859}, {\"epoch\": 43, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6493474841117859}, {\"epoch\": 44, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6488242745399475}, {\"epoch\": 45, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6484102010726929}, {\"epoch\": 46, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6479799747467041}, {\"epoch\": 47, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6475735902786255}, {\"epoch\": 48, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6471590399742126}, {\"epoch\": 49, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6467936635017395}, {\"epoch\": 50, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6464372873306274}, {\"epoch\": 1, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7749068140983582}, {\"epoch\": 2, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7712455987930298}, {\"epoch\": 3, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7693754434585571}, {\"epoch\": 4, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7681925296783447}, {\"epoch\": 5, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7669293284416199}, {\"epoch\": 6, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7646157741546631}, {\"epoch\": 7, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7615914940834045}, {\"epoch\": 8, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7572800517082214}, {\"epoch\": 9, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7529423832893372}, {\"epoch\": 10, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7490853667259216}, {\"epoch\": 11, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7458231449127197}, {\"epoch\": 12, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7434871196746826}, {\"epoch\": 13, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7413901090621948}, {\"epoch\": 14, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7398905754089355}, {\"epoch\": 15, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7386982440948486}, {\"epoch\": 16, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7374763488769531}, {\"epoch\": 17, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.736795961856842}, {\"epoch\": 18, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7358312010765076}, {\"epoch\": 19, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7357936501502991}, {\"epoch\": 20, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7355297803878784}, {\"epoch\": 21, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7353548407554626}, {\"epoch\": 22, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7346475124359131}, {\"epoch\": 23, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7345659136772156}, {\"epoch\": 24, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7343978881835938}, {\"epoch\": 25, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7343798875808716}, {\"epoch\": 26, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7338239550590515}, {\"epoch\": 27, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7334775924682617}, {\"epoch\": 28, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7333297729492188}, {\"epoch\": 29, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.732943058013916}, {\"epoch\": 30, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7328367233276367}, {\"epoch\": 31, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7327775955200195}, {\"epoch\": 32, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7329440116882324}, {\"epoch\": 33, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7332471609115601}, {\"epoch\": 34, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7335337996482849}, {\"epoch\": 35, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.733451247215271}, {\"epoch\": 36, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7333934307098389}, {\"epoch\": 37, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7329258918762207}, {\"epoch\": 38, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7329221963882446}, {\"epoch\": 39, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7329833507537842}, {\"epoch\": 40, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.732870876789093}, {\"epoch\": 41, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7330285310745239}, {\"epoch\": 42, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7331199049949646}, {\"epoch\": 43, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7328552007675171}, {\"epoch\": 44, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7328758835792542}, {\"epoch\": 45, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7325185537338257}, {\"epoch\": 46, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7329471707344055}, {\"epoch\": 47, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7328447699546814}, {\"epoch\": 48, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7329102158546448}, {\"epoch\": 49, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7328829169273376}, {\"epoch\": 50, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7328895926475525}, {\"epoch\": 1, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.6562591195106506}, {\"epoch\": 2, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.6896604895591736}, {\"epoch\": 3, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.6936061978340149}, {\"epoch\": 4, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.6974146962165833}, {\"epoch\": 5, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7020809650421143}, {\"epoch\": 6, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7083941102027893}, {\"epoch\": 7, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7145699858665466}, {\"epoch\": 8, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7216894626617432}, {\"epoch\": 9, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.72808837890625}, {\"epoch\": 10, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7332178354263306}, {\"epoch\": 11, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7357396483421326}, {\"epoch\": 12, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.738964855670929}, {\"epoch\": 13, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7418984174728394}, {\"epoch\": 14, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7433909177780151}, {\"epoch\": 15, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7449005842208862}, {\"epoch\": 16, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7465131878852844}, {\"epoch\": 17, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7474395632743835}, {\"epoch\": 18, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7481600642204285}, {\"epoch\": 19, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7494467496871948}, {\"epoch\": 20, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7505446672439575}, {\"epoch\": 21, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.751591145992279}, {\"epoch\": 22, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7522430419921875}, {\"epoch\": 23, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7527405619621277}, {\"epoch\": 24, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7539585828781128}, {\"epoch\": 25, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7543359994888306}, {\"epoch\": 26, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7551766037940979}, {\"epoch\": 27, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.755811333656311}, {\"epoch\": 28, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7556055188179016}, {\"epoch\": 29, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7560687065124512}, {\"epoch\": 30, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7567892074584961}, {\"epoch\": 31, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7572181224822998}, {\"epoch\": 32, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7575268745422363}, {\"epoch\": 33, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7583332061767578}, {\"epoch\": 34, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7586591243743896}, {\"epoch\": 35, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7589336037635803}, {\"epoch\": 36, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7591909766197205}, {\"epoch\": 37, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7594654560089111}, {\"epoch\": 38, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7594311237335205}, {\"epoch\": 39, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7599114775657654}, {\"epoch\": 40, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.760185956954956}, {\"epoch\": 41, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7603918313980103}, {\"epoch\": 42, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7610437273979187}, {\"epoch\": 43, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7616784572601318}, {\"epoch\": 44, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7616612911224365}, {\"epoch\": 45, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7616956233978271}, {\"epoch\": 46, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7620216012001038}, {\"epoch\": 47, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7619529366493225}, {\"epoch\": 48, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7623303532600403}, {\"epoch\": 49, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7622445821762085}, {\"epoch\": 50, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7625190615653992}, {\"epoch\": 1, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6654069423675537}, {\"epoch\": 2, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6705358624458313}, {\"epoch\": 3, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6720204949378967}, {\"epoch\": 4, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6753947734832764}, {\"epoch\": 5, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6779592633247375}, {\"epoch\": 6, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6824132800102234}, {\"epoch\": 7, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6872722506523132}, {\"epoch\": 8, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6874071955680847}, {\"epoch\": 9, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6907814741134644}, {\"epoch\": 10, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.692401111125946}, {\"epoch\": 11, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6926710605621338}, {\"epoch\": 12, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6940208077430725}, {\"epoch\": 13, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6921312212944031}, {\"epoch\": 14, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6926710605621338}, {\"epoch\": 15, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6936158537864685}, {\"epoch\": 16, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.693480908870697}, {\"epoch\": 17, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6925361156463623}, {\"epoch\": 18, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6933459043502808}, {\"epoch\": 19, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6915913224220276}, {\"epoch\": 20, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6925361156463623}, {\"epoch\": 21, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6909164786338806}, {\"epoch\": 22, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6899716854095459}, {\"epoch\": 23, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6895667314529419}, {\"epoch\": 24, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6888918876647949}, {\"epoch\": 25, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6886219382286072}, {\"epoch\": 26, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6883519887924194}, {\"epoch\": 27, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.687542200088501}, {\"epoch\": 28, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.687137246131897}, {\"epoch\": 29, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6872722506523132}, {\"epoch\": 30, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6868672966957092}, {\"epoch\": 31, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6865974068641663}, {\"epoch\": 32, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.687542200088501}, {\"epoch\": 33, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6861924529075623}, {\"epoch\": 34, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.68646240234375}, {\"epoch\": 35, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.684707760810852}, {\"epoch\": 36, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6848427653312683}, {\"epoch\": 37, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.685112714767456}, {\"epoch\": 38, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6853826642036438}, {\"epoch\": 39, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6852476596832275}, {\"epoch\": 40, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6845728158950806}, {\"epoch\": 41, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6860575079917908}, {\"epoch\": 42, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6860575079917908}, {\"epoch\": 43, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.685112714767456}, {\"epoch\": 44, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6849777102470398}, {\"epoch\": 45, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6845728158950806}, {\"epoch\": 46, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6845728158950806}, {\"epoch\": 47, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6848427653312683}, {\"epoch\": 48, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6870023012161255}, {\"epoch\": 49, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.687137246131897}, {\"epoch\": 50, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6860575079917908}, {\"epoch\": 1, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.7952161431312561}, {\"epoch\": 2, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.7364858388900757}, {\"epoch\": 3, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.726158618927002}, {\"epoch\": 4, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.7164479494094849}, {\"epoch\": 5, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.7064122557640076}, {\"epoch\": 6, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6952365040779114}, {\"epoch\": 7, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6828184127807617}, {\"epoch\": 8, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.669251024723053}, {\"epoch\": 9, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6566022038459778}, {\"epoch\": 10, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6464177966117859}, {\"epoch\": 11, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6386076807975769}, {\"epoch\": 12, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6322796940803528}, {\"epoch\": 13, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6268573999404907}, {\"epoch\": 14, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6223351359367371}, {\"epoch\": 15, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6183916330337524}, {\"epoch\": 16, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6149691939353943}, {\"epoch\": 17, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6120102405548096}, {\"epoch\": 18, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6092033982276917}, {\"epoch\": 19, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6066913604736328}, {\"epoch\": 20, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6043346524238586}, {\"epoch\": 21, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.602319061756134}, {\"epoch\": 22, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6004436612129211}, {\"epoch\": 23, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5987449288368225}, {\"epoch\": 24, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5971945524215698}, {\"epoch\": 25, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5956748127937317}, {\"epoch\": 26, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5942566394805908}, {\"epoch\": 27, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5929740071296692}, {\"epoch\": 28, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5918253064155579}, {\"epoch\": 29, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5907725691795349}, {\"epoch\": 30, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5897713303565979}, {\"epoch\": 31, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5887326598167419}, {\"epoch\": 32, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5878620147705078}, {\"epoch\": 33, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5869106650352478}, {\"epoch\": 34, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5861185193061829}, {\"epoch\": 35, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5852946043014526}, {\"epoch\": 36, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5844826698303223}, {\"epoch\": 37, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5837318301200867}, {\"epoch\": 38, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5829266905784607}, {\"epoch\": 39, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5822872519493103}, {\"epoch\": 40, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5816565155982971}, {\"epoch\": 41, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.58111971616745}, {\"epoch\": 42, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5804753303527832}, {\"epoch\": 43, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5798433423042297}, {\"epoch\": 44, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5793321132659912}, {\"epoch\": 45, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5787836909294128}, {\"epoch\": 46, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5782524347305298}, {\"epoch\": 47, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.577667236328125}, {\"epoch\": 48, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5772207975387573}, {\"epoch\": 49, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5767486095428467}, {\"epoch\": 50, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5763174891471863}, {\"epoch\": 1, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7753707766532898}, {\"epoch\": 2, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7678498029708862}, {\"epoch\": 3, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7644100785255432}, {\"epoch\": 4, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7606189846992493}, {\"epoch\": 5, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7562718391418457}, {\"epoch\": 6, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7513257265090942}, {\"epoch\": 7, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7432461977005005}, {\"epoch\": 8, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7368531823158264}, {\"epoch\": 9, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7324849963188171}, {\"epoch\": 10, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7305223345756531}, {\"epoch\": 11, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7302227020263672}, {\"epoch\": 12, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7300792336463928}, {\"epoch\": 13, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7299994230270386}, {\"epoch\": 14, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7310519218444824}, {\"epoch\": 15, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7323700189590454}, {\"epoch\": 16, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7337562441825867}, {\"epoch\": 17, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7360028028488159}, {\"epoch\": 18, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7378882169723511}, {\"epoch\": 19, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7394850254058838}, {\"epoch\": 20, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7403671145439148}, {\"epoch\": 21, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7414206862449646}, {\"epoch\": 22, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7427034974098206}, {\"epoch\": 23, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7445250153541565}, {\"epoch\": 24, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7455450892448425}, {\"epoch\": 25, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7471328377723694}, {\"epoch\": 26, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7484259605407715}, {\"epoch\": 27, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7491855621337891}, {\"epoch\": 28, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7501270174980164}, {\"epoch\": 29, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.751671314239502}, {\"epoch\": 30, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.752281904220581}, {\"epoch\": 31, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7528377771377563}, {\"epoch\": 32, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7533161640167236}, {\"epoch\": 33, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7538706660270691}, {\"epoch\": 34, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7546036243438721}, {\"epoch\": 35, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7559332251548767}, {\"epoch\": 36, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7559084892272949}, {\"epoch\": 37, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7566795349121094}, {\"epoch\": 38, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7572226524353027}, {\"epoch\": 39, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.758014976978302}, {\"epoch\": 40, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7588146924972534}, {\"epoch\": 41, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7590954303741455}, {\"epoch\": 42, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7599543929100037}, {\"epoch\": 43, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7603000998497009}, {\"epoch\": 44, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7612436413764954}, {\"epoch\": 45, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7613550424575806}, {\"epoch\": 46, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7619162201881409}, {\"epoch\": 47, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7624634504318237}, {\"epoch\": 48, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7628238797187805}, {\"epoch\": 49, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.764107346534729}, {\"epoch\": 50, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7643054723739624}, {\"epoch\": 1, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.6626752018928528}, {\"epoch\": 2, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.6927655935287476}, {\"epoch\": 3, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7059409022331238}, {\"epoch\": 4, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7201111912727356}, {\"epoch\": 5, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7316566705703735}, {\"epoch\": 6, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7420356273651123}, {\"epoch\": 7, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7491894364356995}, {\"epoch\": 8, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7545762062072754}, {\"epoch\": 9, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7604604363441467}, {\"epoch\": 10, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7656584978103638}, {\"epoch\": 11, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7699301838874817}, {\"epoch\": 12, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.77373868227005}, {\"epoch\": 13, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7773755788803101}, {\"epoch\": 14, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7809782028198242}, {\"epoch\": 15, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.78416907787323}, {\"epoch\": 16, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7864679098129272}, {\"epoch\": 17, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7888010144233704}, {\"epoch\": 18, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.790825366973877}, {\"epoch\": 19, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7918203473091125}, {\"epoch\": 20, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.793450117111206}, {\"epoch\": 21, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7939819097518921}, {\"epoch\": 22, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7951656579971313}, {\"epoch\": 23, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7970870137214661}, {\"epoch\": 24, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7986481785774231}, {\"epoch\": 25, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7995745539665222}, {\"epoch\": 26, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8010327219963074}, {\"epoch\": 27, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.80165034532547}, {\"epoch\": 28, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8032629489898682}, {\"epoch\": 29, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8042064905166626}, {\"epoch\": 30, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8044809699058533}, {\"epoch\": 31, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8060078024864197}, {\"epoch\": 32, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8066768646240234}, {\"epoch\": 33, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8076546788215637}, {\"epoch\": 34, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8079463243484497}, {\"epoch\": 35, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8086668848991394}, {\"epoch\": 36, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8092330098152161}, {\"epoch\": 37, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8102108240127563}, {\"epoch\": 38, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8108798861503601}, {\"epoch\": 39, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8112916350364685}, {\"epoch\": 40, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8122351765632629}, {\"epoch\": 41, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8124924898147583}, {\"epoch\": 42, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8132301568984985}, {\"epoch\": 43, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8134188652038574}, {\"epoch\": 44, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8143795728683472}, {\"epoch\": 45, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.814859926700592}, {\"epoch\": 46, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8151687383651733}, {\"epoch\": 47, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8164210319519043}, {\"epoch\": 48, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8162494897842407}, {\"epoch\": 49, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8168156147003174}, {\"epoch\": 50, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8172788023948669}, {\"epoch\": 1, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6679713726043701}, {\"epoch\": 2, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6743150353431702}, {\"epoch\": 3, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.684707760810852}, {\"epoch\": 4, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6922661662101746}, {\"epoch\": 5, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6938858032226562}, {\"epoch\": 6, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6969901323318481}, {\"epoch\": 7, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6991496682167053}, {\"epoch\": 8, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6986097693443298}, {\"epoch\": 9, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6957753896713257}, {\"epoch\": 10, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6945606470108032}, {\"epoch\": 11, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6929410099983215}, {\"epoch\": 12, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6933459043502808}, {\"epoch\": 13, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6907814741134644}, {\"epoch\": 14, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6890268325805664}, {\"epoch\": 15, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6878121495246887}, {\"epoch\": 16, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6848427653312683}, {\"epoch\": 17, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6849777102470398}, {\"epoch\": 18, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6838979721069336}, {\"epoch\": 19, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.679848849773407}, {\"epoch\": 20, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6779592633247375}, {\"epoch\": 21, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6759346723556519}, {\"epoch\": 22, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6755297780036926}, {\"epoch\": 23, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6745849847793579}, {\"epoch\": 24, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6743150353431702}, {\"epoch\": 25, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6726953983306885}, {\"epoch\": 26, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6743150353431702}, {\"epoch\": 27, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6732352375984192}, {\"epoch\": 28, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6705358624458313}, {\"epoch\": 29, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6706708073616028}, {\"epoch\": 30, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6698609590530396}, {\"epoch\": 31, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6683763265609741}, {\"epoch\": 32, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6689161658287048}, {\"epoch\": 33, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6686462163925171}, {\"epoch\": 34, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6662167906761169}, {\"epoch\": 35, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6671615839004517}, {\"epoch\": 36, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6668916344642639}, {\"epoch\": 37, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6670265793800354}, {\"epoch\": 38, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6670265793800354}, {\"epoch\": 39, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6670265793800354}, {\"epoch\": 40, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6667566299438477}, {\"epoch\": 41, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6650020480155945}, {\"epoch\": 42, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6654069423675537}, {\"epoch\": 43, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6629774570465088}, {\"epoch\": 44, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6636523008346558}, {\"epoch\": 45, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6641921997070312}, {\"epoch\": 46, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6635173559188843}, {\"epoch\": 47, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6631124019622803}, {\"epoch\": 48, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.663787305355072}, {\"epoch\": 49, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6640572547912598}, {\"epoch\": 50, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6624375581741333}, {\"epoch\": 1, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.783126711845398}, {\"epoch\": 2, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.7286641001701355}, {\"epoch\": 3, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.7026496529579163}, {\"epoch\": 4, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.6724063158035278}, {\"epoch\": 5, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.6456794738769531}, {\"epoch\": 6, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.6257045269012451}, {\"epoch\": 7, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.6101319789886475}, {\"epoch\": 8, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.596994161605835}, {\"epoch\": 9, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5852187275886536}, {\"epoch\": 10, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5750075578689575}, {\"epoch\": 11, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5657249093055725}, {\"epoch\": 12, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5575382113456726}, {\"epoch\": 13, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5500376224517822}, {\"epoch\": 14, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5432203412055969}, {\"epoch\": 15, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5369869470596313}, {\"epoch\": 16, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5314786434173584}, {\"epoch\": 17, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5265254974365234}, {\"epoch\": 18, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5220507383346558}, {\"epoch\": 19, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5181388258934021}, {\"epoch\": 20, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5145816206932068}, {\"epoch\": 21, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5112437009811401}, {\"epoch\": 22, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5079997777938843}, {\"epoch\": 23, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5051642060279846}, {\"epoch\": 24, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5022374987602234}, {\"epoch\": 25, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4996509552001953}, {\"epoch\": 26, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4971133768558502}, {\"epoch\": 27, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4947672486305237}, {\"epoch\": 28, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.49263107776641846}, {\"epoch\": 29, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4905964732170105}, {\"epoch\": 30, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.48873060941696167}, {\"epoch\": 31, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.48684635758399963}, {\"epoch\": 32, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4851733148097992}, {\"epoch\": 33, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4835169315338135}, {\"epoch\": 34, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4818554222583771}, {\"epoch\": 35, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.48041680455207825}, {\"epoch\": 36, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4789331257343292}, {\"epoch\": 37, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.477559894323349}, {\"epoch\": 38, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4761393368244171}, {\"epoch\": 39, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4747367203235626}, {\"epoch\": 40, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.47356924414634705}, {\"epoch\": 41, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4723057150840759}, {\"epoch\": 42, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4711495339870453}, {\"epoch\": 43, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.46989670395851135}, {\"epoch\": 44, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.46890708804130554}, {\"epoch\": 45, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4678046405315399}, {\"epoch\": 46, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4666709303855896}, {\"epoch\": 47, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.46569257974624634}, {\"epoch\": 48, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.46470141410827637}, {\"epoch\": 49, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.46373632550239563}, {\"epoch\": 50, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.46276357769966125}, {\"epoch\": 1, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7731444239616394}, {\"epoch\": 2, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7576425075531006}, {\"epoch\": 3, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.736961305141449}, {\"epoch\": 4, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7203062772750854}, {\"epoch\": 5, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7099658250808716}, {\"epoch\": 6, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.707872211933136}, {\"epoch\": 7, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7080357074737549}, {\"epoch\": 8, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7099134922027588}, {\"epoch\": 9, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7140467166900635}, {\"epoch\": 10, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.718967080116272}, {\"epoch\": 11, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7246568202972412}, {\"epoch\": 12, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7302041053771973}, {\"epoch\": 13, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7371610999107361}, {\"epoch\": 14, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7434743642807007}, {\"epoch\": 15, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7507108449935913}, {\"epoch\": 16, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7579221129417419}, {\"epoch\": 17, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7642536163330078}, {\"epoch\": 18, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.771916389465332}, {\"epoch\": 19, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.77829909324646}, {\"epoch\": 20, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7854160666465759}, {\"epoch\": 21, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7915847897529602}, {\"epoch\": 22, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7982507944107056}, {\"epoch\": 23, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8047617077827454}, {\"epoch\": 24, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8107958436012268}, {\"epoch\": 25, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8171069622039795}, {\"epoch\": 26, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8228842616081238}, {\"epoch\": 27, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8283330202102661}, {\"epoch\": 28, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8334294557571411}, {\"epoch\": 29, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8383306860923767}, {\"epoch\": 30, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8431976437568665}, {\"epoch\": 31, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8476992249488831}, {\"epoch\": 32, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8519443273544312}, {\"epoch\": 33, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8569574356079102}, {\"epoch\": 34, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8615779280662537}, {\"epoch\": 35, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8658870458602905}, {\"epoch\": 36, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8696297407150269}, {\"epoch\": 37, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8728156089782715}, {\"epoch\": 38, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8759888410568237}, {\"epoch\": 39, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.879472553730011}, {\"epoch\": 40, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8830978870391846}, {\"epoch\": 41, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8861322999000549}, {\"epoch\": 42, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8897152543067932}, {\"epoch\": 43, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.893303632736206}, {\"epoch\": 44, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8966476321220398}, {\"epoch\": 45, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8986632227897644}, {\"epoch\": 46, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.901886522769928}, {\"epoch\": 47, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.9047453999519348}, {\"epoch\": 48, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.9073838591575623}, {\"epoch\": 49, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.9096812605857849}, {\"epoch\": 50, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.912433922290802}, {\"epoch\": 1, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.6679075956344604}, {\"epoch\": 2, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.6980494260787964}, {\"epoch\": 3, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.7212605476379395}, {\"epoch\": 4, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.7406288981437683}, {\"epoch\": 5, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.7558799982070923}, {\"epoch\": 6, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.7693125605583191}, {\"epoch\": 7, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.780823826789856}, {\"epoch\": 8, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.7919576168060303}, {\"epoch\": 9, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8022850751876831}, {\"epoch\": 10, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8117033243179321}, {\"epoch\": 11, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8193374872207642}, {\"epoch\": 12, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8260108828544617}, {\"epoch\": 13, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8324955701828003}, {\"epoch\": 14, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8375049233436584}, {\"epoch\": 15, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8421883583068848}, {\"epoch\": 16, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.846854567527771}, {\"epoch\": 17, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8518467545509338}, {\"epoch\": 18, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8551062941551208}, {\"epoch\": 19, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8589662313461304}, {\"epoch\": 20, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8624830842018127}, {\"epoch\": 21, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.86672043800354}, {\"epoch\": 22, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8697226047515869}, {\"epoch\": 23, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8729134798049927}, {\"epoch\": 24, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8763960003852844}, {\"epoch\": 25, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8796727061271667}, {\"epoch\": 26, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8824518322944641}, {\"epoch\": 27, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8856255412101746}, {\"epoch\": 28, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8879243731498718}, {\"epoch\": 29, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8900859355926514}, {\"epoch\": 30, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8927278518676758}, {\"epoch\": 31, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8952839970588684}, {\"epoch\": 32, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8970681428909302}, {\"epoch\": 33, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8984405994415283}, {\"epoch\": 34, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9000532031059265}, {\"epoch\": 35, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9019917249679565}, {\"epoch\": 36, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9034156203269958}, {\"epoch\": 37, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9051311612129211}, {\"epoch\": 38, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9073270559310913}, {\"epoch\": 39, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9090768694877625}, {\"epoch\": 40, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.911238431930542}, {\"epoch\": 41, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.912645161151886}, {\"epoch\": 42, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9139832854270935}, {\"epoch\": 43, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9147552847862244}, {\"epoch\": 44, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9172256588935852}, {\"epoch\": 45, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9180319309234619}, {\"epoch\": 46, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.919301450252533}, {\"epoch\": 47, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9213429093360901}, {\"epoch\": 48, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9224237203598022}, {\"epoch\": 49, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9237618446350098}, {\"epoch\": 50, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9245337843894958}, {\"epoch\": 1, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6682413220405579}, {\"epoch\": 2, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6833580732345581}, {\"epoch\": 3, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6963152885437012}, {\"epoch\": 4, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6971251368522644}, {\"epoch\": 5, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6969901323318481}, {\"epoch\": 6, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6961803436279297}, {\"epoch\": 7, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6949656009674072}, {\"epoch\": 8, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6914563179016113}, {\"epoch\": 9, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6863274574279785}, {\"epoch\": 10, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6807936429977417}, {\"epoch\": 11, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6793089509010315}, {\"epoch\": 12, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6778242588043213}, {\"epoch\": 13, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6747199296951294}, {\"epoch\": 14, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6705358624458313}, {\"epoch\": 15, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6695910096168518}, {\"epoch\": 16, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6672965288162231}, {\"epoch\": 17, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6674314737319946}, {\"epoch\": 18, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6647320985794067}, {\"epoch\": 19, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6612228155136108}, {\"epoch\": 20, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6578485369682312}, {\"epoch\": 21, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6578485369682312}, {\"epoch\": 22, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6542043685913086}, {\"epoch\": 23, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6535294651985168}, {\"epoch\": 24, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6520448327064514}, {\"epoch\": 25, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6525846719741821}, {\"epoch\": 26, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6500202417373657}, {\"epoch\": 27, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6505601406097412}, {\"epoch\": 28, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6500202417373657}, {\"epoch\": 29, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.648400604724884}, {\"epoch\": 30, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.649075448513031}, {\"epoch\": 31, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6458361744880676}, {\"epoch\": 32, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6442164778709412}, {\"epoch\": 33, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.642056941986084}, {\"epoch\": 34, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6400324106216431}, {\"epoch\": 35, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6381428241729736}, {\"epoch\": 36, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6380078196525574}, {\"epoch\": 37, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6362531781196594}, {\"epoch\": 38, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6365231275558472}, {\"epoch\": 39, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6338237524032593}, {\"epoch\": 40, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6344985961914062}, {\"epoch\": 41, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6342286467552185}, {\"epoch\": 42, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6322040557861328}, {\"epoch\": 43, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6328789591789246}, {\"epoch\": 44, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6303144693374634}, {\"epoch\": 45, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.628424882888794}, {\"epoch\": 46, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6282899379730225}, {\"epoch\": 47, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.628424882888794}, {\"epoch\": 48, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6281549334526062}, {\"epoch\": 49, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6280199885368347}, {\"epoch\": 50, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6269401907920837}, {\"epoch\": 1, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.7758174538612366}, {\"epoch\": 2, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.716478705406189}, {\"epoch\": 3, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.6698808073997498}, {\"epoch\": 4, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.629084050655365}, {\"epoch\": 5, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.5974346995353699}, {\"epoch\": 6, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.5705695152282715}, {\"epoch\": 7, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.54608553647995}, {\"epoch\": 8, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.5228650569915771}, {\"epoch\": 9, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.5011610388755798}, {\"epoch\": 10, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.4811944365501404}, {\"epoch\": 11, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.4631119966506958}, {\"epoch\": 12, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.44698238372802734}, {\"epoch\": 13, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.4323388338088989}, {\"epoch\": 14, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.41918453574180603}, {\"epoch\": 15, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.40696439146995544}, {\"epoch\": 16, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.3958612084388733}, {\"epoch\": 17, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.385370671749115}, {\"epoch\": 18, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.37589573860168457}, {\"epoch\": 19, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.3671497702598572}, {\"epoch\": 20, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.35894539952278137}, {\"epoch\": 21, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.351226806640625}, {\"epoch\": 22, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.3440507650375366}, {\"epoch\": 23, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.3371937572956085}, {\"epoch\": 24, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.33048874139785767}, {\"epoch\": 25, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.3243615925312042}, {\"epoch\": 26, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.31857702136039734}, {\"epoch\": 27, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.31289100646972656}, {\"epoch\": 28, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.30753353238105774}, {\"epoch\": 29, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.30244582891464233}, {\"epoch\": 30, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.2971883714199066}, {\"epoch\": 31, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.2921712398529053}, {\"epoch\": 32, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.28747713565826416}, {\"epoch\": 33, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.283157080411911}, {\"epoch\": 34, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.2786642909049988}, {\"epoch\": 35, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.27471715211868286}, {\"epoch\": 36, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.2707485854625702}, {\"epoch\": 37, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.26667582988739014}, {\"epoch\": 38, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.26290273666381836}, {\"epoch\": 39, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.2592005431652069}, {\"epoch\": 40, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.25566431879997253}, {\"epoch\": 41, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.2522885203361511}, {\"epoch\": 42, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.24882543087005615}, {\"epoch\": 43, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.2456374317407608}, {\"epoch\": 44, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.24249614775180817}, {\"epoch\": 45, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.2392079085111618}, {\"epoch\": 46, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.23625029623508453}, {\"epoch\": 47, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.23329396545886993}, {\"epoch\": 48, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.23038709163665771}, {\"epoch\": 49, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.22744937241077423}, {\"epoch\": 50, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.22504585981369019}, {\"epoch\": 1, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7720524072647095}, {\"epoch\": 2, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7425732612609863}, {\"epoch\": 3, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7182112336158752}, {\"epoch\": 4, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.711658239364624}, {\"epoch\": 5, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7133861780166626}, {\"epoch\": 6, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7179710268974304}, {\"epoch\": 7, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7281718254089355}, {\"epoch\": 8, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7408528327941895}, {\"epoch\": 9, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7567550539970398}, {\"epoch\": 10, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7747848629951477}, {\"epoch\": 11, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7924347519874573}, {\"epoch\": 12, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.8129764795303345}, {\"epoch\": 13, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.8336665034294128}, {\"epoch\": 14, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.8558356165885925}, {\"epoch\": 15, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.8791568875312805}, {\"epoch\": 16, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.902480959892273}, {\"epoch\": 17, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.9255247116088867}, {\"epoch\": 18, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.9504728317260742}, {\"epoch\": 19, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.9753847718238831}, {\"epoch\": 20, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.0004442930221558}, {\"epoch\": 21, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.0259615182876587}, {\"epoch\": 22, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.0529197454452515}, {\"epoch\": 23, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.0769253969192505}, {\"epoch\": 24, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.1007176637649536}, {\"epoch\": 25, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.1242408752441406}, {\"epoch\": 26, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.1465140581130981}, {\"epoch\": 27, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.1707348823547363}, {\"epoch\": 28, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.1935744285583496}, {\"epoch\": 29, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.2191340923309326}, {\"epoch\": 30, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.245758056640625}, {\"epoch\": 31, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.2693958282470703}, {\"epoch\": 32, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.2938581705093384}, {\"epoch\": 33, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.3204652070999146}, {\"epoch\": 34, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.345481038093567}, {\"epoch\": 35, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.3710925579071045}, {\"epoch\": 36, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.4001047611236572}, {\"epoch\": 37, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.4270788431167603}, {\"epoch\": 38, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.452843189239502}, {\"epoch\": 39, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.4801372289657593}, {\"epoch\": 40, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.5063356161117554}, {\"epoch\": 41, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.530747413635254}, {\"epoch\": 42, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.558097004890442}, {\"epoch\": 43, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.5843534469604492}, {\"epoch\": 44, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.612612009048462}, {\"epoch\": 45, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.6407700777053833}, {\"epoch\": 46, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.6682218313217163}, {\"epoch\": 47, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.6949421167373657}, {\"epoch\": 48, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.7240439653396606}, {\"epoch\": 49, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.7528876066207886}, {\"epoch\": 50, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.7785775661468506}, {\"epoch\": 1, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.6685937643051147}, {\"epoch\": 2, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.7074162364006042}, {\"epoch\": 3, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.7363401055335999}, {\"epoch\": 4, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.7594482898712158}, {\"epoch\": 5, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.7824020981788635}, {\"epoch\": 6, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.8043094277381897}, {\"epoch\": 7, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.8242953419685364}, {\"epoch\": 8, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.8438524007797241}, {\"epoch\": 9, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.8606302738189697}, {\"epoch\": 10, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.877013623714447}, {\"epoch\": 11, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.8910466432571411}, {\"epoch\": 12, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9038444757461548}, {\"epoch\": 13, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9134857654571533}, {\"epoch\": 14, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9251170754432678}, {\"epoch\": 15, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9345868229866028}, {\"epoch\": 16, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9435762166976929}, {\"epoch\": 17, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9513646960258484}, {\"epoch\": 18, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.958141028881073}, {\"epoch\": 19, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9639052152633667}, {\"epoch\": 20, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.969703733921051}, {\"epoch\": 21, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9742670655250549}, {\"epoch\": 22, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9782642126083374}, {\"epoch\": 23, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9815580248832703}, {\"epoch\": 24, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9832563996315002}, {\"epoch\": 25, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9830334186553955}, {\"epoch\": 26, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9845945239067078}, {\"epoch\": 27, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9849719405174255}, {\"epoch\": 28, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9846288561820984}, {\"epoch\": 29, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9853836894035339}, {\"epoch\": 30, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.986207127571106}, {\"epoch\": 31, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9869791269302368}, {\"epoch\": 32, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9873908758163452}, {\"epoch\": 33, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.988437294960022}, {\"epoch\": 34, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9875280857086182}, {\"epoch\": 35, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9878197312355042}, {\"epoch\": 36, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9883172512054443}, {\"epoch\": 37, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9910449385643005}, {\"epoch\": 38, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9917482733726501}, {\"epoch\": 39, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.989415168762207}, {\"epoch\": 40, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.990135669708252}, {\"epoch\": 41, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.990581750869751}, {\"epoch\": 42, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9920056462287903}, {\"epoch\": 43, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9915252923965454}, {\"epoch\": 44, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9918512105941772}, {\"epoch\": 45, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9902729392051697}, {\"epoch\": 46, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9920227527618408}, {\"epoch\": 47, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9917311668395996}, {\"epoch\": 48, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9930521249771118}, {\"epoch\": 49, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9937382936477661}, {\"epoch\": 50, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9932065010070801}, {\"epoch\": 1, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6718855500221252}, {\"epoch\": 2, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6919962167739868}, {\"epoch\": 3, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.7033337950706482}, {\"epoch\": 4, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.7040086388587952}, {\"epoch\": 5, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.7030638456344604}, {\"epoch\": 6, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.7021190524101257}, {\"epoch\": 7, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6977999806404114}, {\"epoch\": 8, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6933459043502808}, {\"epoch\": 9, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6868672966957092}, {\"epoch\": 10, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6817384362220764}, {\"epoch\": 11, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6768794655799866}, {\"epoch\": 12, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6683763265609741}, {\"epoch\": 13, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6666216850280762}, {\"epoch\": 14, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6647320985794067}, {\"epoch\": 15, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6613578200340271}, {\"epoch\": 16, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6582534909248352}, {\"epoch\": 17, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6570387482643127}, {\"epoch\": 18, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6521797776222229}, {\"epoch\": 19, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.649075448513031}, {\"epoch\": 20, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6478607058525085}, {\"epoch\": 21, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6444864273071289}, {\"epoch\": 22, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6423268914222717}, {\"epoch\": 23, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6389526128768921}, {\"epoch\": 24, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6363881826400757}, {\"epoch\": 25, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6361182332038879}, {\"epoch\": 26, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6380078196525574}, {\"epoch\": 27, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6349034905433655}, {\"epoch\": 28, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6349034905433655}, {\"epoch\": 29, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6373329758644104}, {\"epoch\": 30, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6317991614341736}, {\"epoch\": 31, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6353083848953247}, {\"epoch\": 32, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6381428241729736}, {\"epoch\": 33, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6317991614341736}, {\"epoch\": 34, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6353083848953247}, {\"epoch\": 35, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6340936422348022}, {\"epoch\": 36, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6332838535308838}, {\"epoch\": 37, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6323390603065491}, {\"epoch\": 38, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6358482837677002}, {\"epoch\": 39, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6342286467552185}, {\"epoch\": 40, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.635443389415741}, {\"epoch\": 41, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6322040557861328}, {\"epoch\": 42, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6335538029670715}, {\"epoch\": 43, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6340936422348022}, {\"epoch\": 44, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.633013904094696}, {\"epoch\": 45, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6289647817611694}, {\"epoch\": 46, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6313942670822144}, {\"epoch\": 47, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6292347311973572}, {\"epoch\": 48, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6358482837677002}, {\"epoch\": 49, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6326090097427368}, {\"epoch\": 50, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6326090097427368}, {\"epoch\": 1, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.77159184217453}, {\"epoch\": 2, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.7024672031402588}, {\"epoch\": 3, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.6420682072639465}, {\"epoch\": 4, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.5910250544548035}, {\"epoch\": 5, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.5438517928123474}, {\"epoch\": 6, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.4980412721633911}, {\"epoch\": 7, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.4540618360042572}, {\"epoch\": 8, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.41333532333374023}, {\"epoch\": 9, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.3760547637939453}, {\"epoch\": 10, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.3418809771537781}, {\"epoch\": 11, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.311386376619339}, {\"epoch\": 12, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.2833855450153351}, {\"epoch\": 13, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.257919043302536}, {\"epoch\": 14, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.2341809868812561}, {\"epoch\": 15, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.21230359375476837}, {\"epoch\": 16, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.19199766218662262}, {\"epoch\": 17, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.17299878597259521}, {\"epoch\": 18, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.15561522543430328}, {\"epoch\": 19, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.1395512968301773}, {\"epoch\": 20, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.12496846169233322}, {\"epoch\": 21, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.11143597215414047}, {\"epoch\": 22, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.10021478682756424}, {\"epoch\": 23, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.0897931382060051}, {\"epoch\": 24, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.08252357691526413}, {\"epoch\": 25, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.07714401185512543}, {\"epoch\": 26, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.07103262096643448}, {\"epoch\": 27, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.06636743992567062}, {\"epoch\": 28, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.06545720249414444}, {\"epoch\": 29, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.06013540178537369}, {\"epoch\": 30, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.05658761039376259}, {\"epoch\": 31, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.05431738868355751}, {\"epoch\": 32, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.05016594007611275}, {\"epoch\": 33, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.04791910573840141}, {\"epoch\": 34, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.04805874824523926}, {\"epoch\": 35, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.04592038691043854}, {\"epoch\": 36, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.04452202841639519}, {\"epoch\": 37, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.03887128829956055}, {\"epoch\": 38, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.03618312254548073}, {\"epoch\": 39, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.04016374051570892}, {\"epoch\": 40, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.03756338730454445}, {\"epoch\": 41, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.03510468453168869}, {\"epoch\": 42, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.03290338069200516}, {\"epoch\": 43, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.03222624957561493}, {\"epoch\": 44, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.032345034182071686}, {\"epoch\": 45, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.03362729400396347}, {\"epoch\": 46, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.030654627829790115}, {\"epoch\": 47, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.03015822358429432}, {\"epoch\": 48, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.027085529640316963}, {\"epoch\": 49, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.025113200768828392}, {\"epoch\": 50, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.026586996391415596}, {\"epoch\": 1, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.7689257860183716}, {\"epoch\": 2, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.7291863560676575}, {\"epoch\": 3, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.7120729684829712}, {\"epoch\": 4, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.7130958437919617}, {\"epoch\": 5, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.7236890196800232}, {\"epoch\": 6, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.7426121830940247}, {\"epoch\": 7, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.7669904828071594}, {\"epoch\": 8, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.8031017184257507}, {\"epoch\": 9, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.8436270356178284}, {\"epoch\": 10, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.8876528143882751}, {\"epoch\": 11, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.9395349621772766}, {\"epoch\": 12, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.9918826818466187}, {\"epoch\": 13, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.0454199314117432}, {\"epoch\": 14, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.1023454666137695}, {\"epoch\": 15, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.1633377075195312}, {\"epoch\": 16, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.2344837188720703}, {\"epoch\": 17, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.3073923587799072}, {\"epoch\": 18, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.3842504024505615}, {\"epoch\": 19, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.4645636081695557}, {\"epoch\": 20, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.547414779663086}, {\"epoch\": 21, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.6362636089324951}, {\"epoch\": 22, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.716208577156067}, {\"epoch\": 23, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.8033535480499268}, {\"epoch\": 24, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.8842147588729858}, {\"epoch\": 25, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.9737540483474731}, {\"epoch\": 26, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.0580663681030273}, {\"epoch\": 27, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.1627256870269775}, {\"epoch\": 28, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.2197556495666504}, {\"epoch\": 29, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.280362844467163}, {\"epoch\": 30, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.337254762649536}, {\"epoch\": 31, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.4078264236450195}, {\"epoch\": 32, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.4677953720092773}, {\"epoch\": 33, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.548482894897461}, {\"epoch\": 34, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.593956470489502}, {\"epoch\": 35, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.6671395301818848}, {\"epoch\": 36, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.703090190887451}, {\"epoch\": 37, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.748964786529541}, {\"epoch\": 38, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.7756094932556152}, {\"epoch\": 39, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.91556715965271}, {\"epoch\": 40, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.98850679397583}, {\"epoch\": 41, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 3.0342540740966797}, {\"epoch\": 42, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 3.149104118347168}, {\"epoch\": 43, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 3.112830400466919}, {\"epoch\": 44, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 3.217123508453369}, {\"epoch\": 45, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 3.2365384101867676}, {\"epoch\": 46, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 3.2652158737182617}, {\"epoch\": 47, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 3.3400707244873047}, {\"epoch\": 48, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 3.2892019748687744}, {\"epoch\": 49, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 3.3284029960632324}, {\"epoch\": 50, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 3.369440793991089}, {\"epoch\": 1, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.6706352829933167}, {\"epoch\": 2, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.7207115888595581}, {\"epoch\": 3, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.7571322917938232}, {\"epoch\": 4, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.795440137386322}, {\"epoch\": 5, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.8325641751289368}, {\"epoch\": 6, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.8658283352851868}, {\"epoch\": 7, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.8955584764480591}, {\"epoch\": 8, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9207939505577087}, {\"epoch\": 9, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.94222092628479}, {\"epoch\": 10, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9589301943778992}, {\"epoch\": 11, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9720711708068848}, {\"epoch\": 12, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9823471903800964}, {\"epoch\": 13, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9874937534332275}, {\"epoch\": 14, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9840970039367676}, {\"epoch\": 15, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9825873374938965}, {\"epoch\": 16, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9839597940444946}, {\"epoch\": 17, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9855037927627563}, {\"epoch\": 18, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9885402321815491}, {\"epoch\": 19, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9897582530975342}, {\"epoch\": 20, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9889519810676575}, {\"epoch\": 21, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9900498986244202}, {\"epoch\": 22, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9915081262588501}, {\"epoch\": 23, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9931207299232483}, {\"epoch\": 24, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9921428561210632}, {\"epoch\": 25, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9935667514801025}, {\"epoch\": 26, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9932922720909119}, {\"epoch\": 27, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9933780431747437}, {\"epoch\": 28, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9939098954200745}, {\"epoch\": 29, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9946990013122559}, {\"epoch\": 30, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9952479600906372}, {\"epoch\": 31, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9946303963661194}, {\"epoch\": 32, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.99466472864151}, {\"epoch\": 33, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9957626461982727}, {\"epoch\": 34, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9958655834197998}, {\"epoch\": 35, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9951107501983643}, {\"epoch\": 36, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9939098954200745}, {\"epoch\": 37, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9950764179229736}, {\"epoch\": 38, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9955911040306091}, {\"epoch\": 39, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9955739378929138}, {\"epoch\": 40, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9961915016174316}, {\"epoch\": 41, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9949220418930054}, {\"epoch\": 42, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9953680634498596}, {\"epoch\": 43, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9959856867790222}, {\"epoch\": 44, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9954538345336914}, {\"epoch\": 45, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.997478187084198}, {\"epoch\": 46, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9958998560905457}, {\"epoch\": 47, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9952994585037231}, {\"epoch\": 48, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9971522092819214}, {\"epoch\": 49, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9975124597549438}, {\"epoch\": 50, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9953508973121643}, {\"epoch\": 1, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.679848849773407}, {\"epoch\": 2, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.7006343603134155}, {\"epoch\": 3, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.7027938961982727}, {\"epoch\": 4, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.7002294659614563}, {\"epoch\": 5, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6945606470108032}, {\"epoch\": 6, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6930760145187378}, {\"epoch\": 7, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.68646240234375}, {\"epoch\": 8, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6845728158950806}, {\"epoch\": 9, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.679443895816803}, {\"epoch\": 10, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6753947734832764}, {\"epoch\": 11, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6735051870346069}, {\"epoch\": 12, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6697260141372681}, {\"epoch\": 13, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6666216850280762}, {\"epoch\": 14, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.655689001083374}, {\"epoch\": 15, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6575786471366882}, {\"epoch\": 16, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6535294651985168}, {\"epoch\": 17, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6564988493919373}, {\"epoch\": 18, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.657443642616272}, {\"epoch\": 19, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.655419111251831}, {\"epoch\": 20, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6616277694702148}, {\"epoch\": 21, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6604130268096924}, {\"epoch\": 22, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6528546214103699}, {\"epoch\": 23, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6577135920524597}, {\"epoch\": 24, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6586583852767944}, {\"epoch\": 25, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.658118486404419}, {\"epoch\": 26, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6528546214103699}, {\"epoch\": 27, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6488054990768433}, {\"epoch\": 28, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6555540561676025}, {\"epoch\": 29, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6542043685913086}, {\"epoch\": 30, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6582534909248352}, {\"epoch\": 31, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6578485369682312}, {\"epoch\": 32, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6591982841491699}, {\"epoch\": 33, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6579835414886475}, {\"epoch\": 34, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6600080728530884}, {\"epoch\": 35, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6596031785011292}, {\"epoch\": 36, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6621676087379456}, {\"epoch\": 37, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6578485369682312}, {\"epoch\": 38, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6645970940589905}, {\"epoch\": 39, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6667566299438477}, {\"epoch\": 40, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6618977189064026}, {\"epoch\": 41, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6641921997070312}, {\"epoch\": 42, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6685112714767456}, {\"epoch\": 43, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6573086977005005}, {\"epoch\": 44, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6641921997070312}, {\"epoch\": 45, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6645970940589905}, {\"epoch\": 46, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6564988493919373}, {\"epoch\": 47, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6658118367195129}, {\"epoch\": 48, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6620326638221741}, {\"epoch\": 49, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6575786471366882}, {\"epoch\": 50, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6612228155136108}, {\"epoch\": 1, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.7662193775177002}, {\"epoch\": 2, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.6736735701560974}, {\"epoch\": 3, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.594571590423584}, {\"epoch\": 4, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.5170639157295227}, {\"epoch\": 5, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.440594345331192}, {\"epoch\": 6, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.36887624859809875}, {\"epoch\": 7, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.30415165424346924}, {\"epoch\": 8, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.24683938920497894}, {\"epoch\": 9, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.19711072742938995}, {\"epoch\": 10, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.15455187857151031}, {\"epoch\": 11, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.11837086081504822}, {\"epoch\": 12, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.08974935859441757}, {\"epoch\": 13, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.0714104026556015}, {\"epoch\": 14, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.06957507878541946}, {\"epoch\": 15, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.06700067967176437}, {\"epoch\": 16, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.06096373870968819}, {\"epoch\": 17, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.05409283563494682}, {\"epoch\": 18, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.04670017957687378}, {\"epoch\": 19, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.041944969445466995}, {\"epoch\": 20, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.04196403920650482}, {\"epoch\": 21, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.03903945907950401}, {\"epoch\": 22, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.034576382488012314}, {\"epoch\": 23, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.029456477612257004}, {\"epoch\": 24, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.030857425183057785}, {\"epoch\": 25, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.02713082917034626}, {\"epoch\": 26, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.027154913172125816}, {\"epoch\": 27, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.025720681995153427}, {\"epoch\": 28, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.025122104212641716}, {\"epoch\": 29, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.02202966995537281}, {\"epoch\": 30, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.020058678463101387}, {\"epoch\": 31, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.021487625315785408}, {\"epoch\": 32, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.020771460607647896}, {\"epoch\": 33, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.017040006816387177}, {\"epoch\": 34, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.017629265785217285}, {\"epoch\": 35, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.018555907532572746}, {\"epoch\": 36, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.021823624148964882}, {\"epoch\": 37, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.017866121605038643}, {\"epoch\": 38, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.016375776380300522}, {\"epoch\": 39, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.01595117338001728}, {\"epoch\": 40, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.013587293215095997}, {\"epoch\": 41, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.01679121144115925}, {\"epoch\": 42, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.014807743020355701}, {\"epoch\": 43, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.014391450211405754}, {\"epoch\": 44, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.015475994907319546}, {\"epoch\": 45, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.009909006766974926}, {\"epoch\": 46, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.01430834736675024}, {\"epoch\": 47, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.01624158024787903}, {\"epoch\": 48, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.010980969294905663}, {\"epoch\": 49, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.00971987098455429}, {\"epoch\": 50, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.01564936712384224}, {\"epoch\": 1, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 0.7536177635192871}, {\"epoch\": 2, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 0.7089571952819824}, {\"epoch\": 3, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 0.70545494556427}, {\"epoch\": 4, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 0.7230375409126282}, {\"epoch\": 5, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 0.756726086139679}, {\"epoch\": 6, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 0.8046635985374451}, {\"epoch\": 7, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 0.8690381050109863}, {\"epoch\": 8, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 0.9396743774414062}, {\"epoch\": 9, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.0235595703125}, {\"epoch\": 10, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.1174960136413574}, {\"epoch\": 11, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.2220085859298706}, {\"epoch\": 12, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.3319752216339111}, {\"epoch\": 13, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.4515292644500732}, {\"epoch\": 14, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.5708534717559814}, {\"epoch\": 15, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.639709234237671}, {\"epoch\": 16, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.7175817489624023}, {\"epoch\": 17, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.852980136871338}, {\"epoch\": 18, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.8826594352722168}, {\"epoch\": 19, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.9627102613449097}, {\"epoch\": 20, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.0371057987213135}, {\"epoch\": 21, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.9952858686447144}, {\"epoch\": 22, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.077928066253662}, {\"epoch\": 23, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.1253156661987305}, {\"epoch\": 24, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.1791398525238037}, {\"epoch\": 25, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.2401082515716553}, {\"epoch\": 26, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.3660943508148193}, {\"epoch\": 27, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.4099438190460205}, {\"epoch\": 28, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.443361282348633}, {\"epoch\": 29, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.5162811279296875}, {\"epoch\": 30, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.459949016571045}, {\"epoch\": 31, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.5036470890045166}, {\"epoch\": 32, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.5016262531280518}, {\"epoch\": 33, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.6022980213165283}, {\"epoch\": 34, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.61588978767395}, {\"epoch\": 35, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.6531424522399902}, {\"epoch\": 36, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.6940488815307617}, {\"epoch\": 37, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.714496612548828}, {\"epoch\": 38, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.8013134002685547}, {\"epoch\": 39, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.8211212158203125}, {\"epoch\": 40, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.8561582565307617}, {\"epoch\": 41, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.968278646469116}, {\"epoch\": 42, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.969827651977539}, {\"epoch\": 43, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 3.194612503051758}, {\"epoch\": 44, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 3.038019895553589}, {\"epoch\": 45, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 3.1058781147003174}, {\"epoch\": 46, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 3.115124225616455}, {\"epoch\": 47, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 3.1634981632232666}, {\"epoch\": 48, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 3.1561577320098877}, {\"epoch\": 49, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 3.3894975185394287}, {\"epoch\": 50, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 3.1893489360809326}, {\"epoch\": 1, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.6756274700164795}, {\"epoch\": 2, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.7325830459594727}, {\"epoch\": 3, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.7787994742393494}, {\"epoch\": 4, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.8353947997093201}, {\"epoch\": 5, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.886431872844696}, {\"epoch\": 6, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.927604615688324}, {\"epoch\": 7, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9572318196296692}, {\"epoch\": 8, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9777324199676514}, {\"epoch\": 9, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9878883361816406}, {\"epoch\": 10, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9814894199371338}, {\"epoch\": 11, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9780583381652832}, {\"epoch\": 12, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9845430850982666}, {\"epoch\": 13, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9892264604568481}, {\"epoch\": 14, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.989706814289093}, {\"epoch\": 15, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9897239804267883}, {\"epoch\": 16, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9906846880912781}, {\"epoch\": 17, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9921256899833679}, {\"epoch\": 18, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9919198751449585}, {\"epoch\": 19, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9934638142585754}, {\"epoch\": 20, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9932922720909119}, {\"epoch\": 21, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9948705434799194}, {\"epoch\": 22, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.993395209312439}, {\"epoch\": 23, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9948705434799194}, {\"epoch\": 24, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9954710006713867}, {\"epoch\": 25, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9953680634498596}, {\"epoch\": 26, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9960885643959045}, {\"epoch\": 27, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9949048757553101}, {\"epoch\": 28, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9952822923660278}, {\"epoch\": 29, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9965346455574036}, {\"epoch\": 30, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9959685206413269}, {\"epoch\": 31, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9966890215873718}, {\"epoch\": 32, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9969978332519531}, {\"epoch\": 33, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9955911040306091}, {\"epoch\": 34, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9977526664733887}, {\"epoch\": 35, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9957969784736633}, {\"epoch\": 36, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9963973760604858}, {\"epoch\": 37, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.997186541557312}, {\"epoch\": 38, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9957969784736633}, {\"epoch\": 39, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9968433976173401}, {\"epoch\": 40, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9979585409164429}, {\"epoch\": 41, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.99636310338974}, {\"epoch\": 42, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.997615396976471}, {\"epoch\": 43, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9977011680603027}, {\"epoch\": 44, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9964659810066223}, {\"epoch\": 45, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9975124597549438}, {\"epoch\": 46, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9974953532218933}, {\"epoch\": 47, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.99660325050354}, {\"epoch\": 48, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.997323751449585}, {\"epoch\": 49, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9976668953895569}, {\"epoch\": 50, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9984388947486877}, {\"epoch\": 1, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6868672966957092}, {\"epoch\": 2, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.7014442086219788}, {\"epoch\": 3, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.7054933309555054}, {\"epoch\": 4, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6979349255561829}, {\"epoch\": 5, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6899716854095459}, {\"epoch\": 6, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6824132800102234}, {\"epoch\": 7, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6778242588043213}, {\"epoch\": 8, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.671480655670166}, {\"epoch\": 9, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.67283034324646}, {\"epoch\": 10, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.670400857925415}, {\"epoch\": 11, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6757997274398804}, {\"epoch\": 12, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6691861152648926}, {\"epoch\": 13, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6686462163925171}, {\"epoch\": 14, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6708057522773743}, {\"epoch\": 15, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6731002926826477}, {\"epoch\": 16, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6709407567977905}, {\"epoch\": 17, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6739100813865662}, {\"epoch\": 18, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6663517355918884}, {\"epoch\": 19, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6668916344642639}, {\"epoch\": 20, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6579835414886475}, {\"epoch\": 21, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.658523440361023}, {\"epoch\": 22, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6645970940589905}, {\"epoch\": 23, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6713456511497498}, {\"epoch\": 24, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6725603938102722}, {\"epoch\": 25, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6662167906761169}, {\"epoch\": 26, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.663787305355072}, {\"epoch\": 27, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6636523008346558}, {\"epoch\": 28, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6629774570465088}, {\"epoch\": 29, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6731002926826477}, {\"epoch\": 30, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6655418872833252}, {\"epoch\": 31, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6745849847793579}, {\"epoch\": 32, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6675664782524109}, {\"epoch\": 33, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6621676087379456}, {\"epoch\": 34, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6631124019622803}, {\"epoch\": 35, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6614927649497986}, {\"epoch\": 36, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6639222502708435}, {\"epoch\": 37, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6647320985794067}, {\"epoch\": 38, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6596031785011292}, {\"epoch\": 39, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6679713726043701}, {\"epoch\": 40, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6623026132583618}, {\"epoch\": 41, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6654069423675537}, {\"epoch\": 42, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6678364276885986}, {\"epoch\": 43, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6578485369682312}, {\"epoch\": 44, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6667566299438477}, {\"epoch\": 45, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6664866805076599}, {\"epoch\": 46, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6629774570465088}, {\"epoch\": 47, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6591982841491699}, {\"epoch\": 48, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6654069423675537}, {\"epoch\": 49, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6678364276885986}, {\"epoch\": 50, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6632474064826965}, {\"epoch\": 1, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.7591387629508972}, {\"epoch\": 2, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.6507376432418823}, {\"epoch\": 3, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.5526469349861145}, {\"epoch\": 4, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.43691977858543396}, {\"epoch\": 5, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.32613396644592285}, {\"epoch\": 6, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.23249129951000214}, {\"epoch\": 7, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.15765772759914398}, {\"epoch\": 8, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.10159525275230408}, {\"epoch\": 9, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.0689929723739624}, {\"epoch\": 10, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.07321126013994217}, {\"epoch\": 11, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.07432299852371216}, {\"epoch\": 12, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.05779470503330231}, {\"epoch\": 13, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.045531265437603}, {\"epoch\": 14, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.04133275896310806}, {\"epoch\": 15, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.03874228149652481}, {\"epoch\": 16, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.03643281012773514}, {\"epoch\": 17, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.03141775727272034}, {\"epoch\": 18, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.03030749410390854}, {\"epoch\": 19, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.026375580579042435}, {\"epoch\": 20, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.025615321472287178}, {\"epoch\": 21, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.02087467536330223}, {\"epoch\": 22, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.02513028122484684}, {\"epoch\": 23, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.019671017304062843}, {\"epoch\": 24, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.01902122236788273}, {\"epoch\": 25, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.01807786151766777}, {\"epoch\": 26, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.016258398070931435}, {\"epoch\": 27, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.018601898103952408}, {\"epoch\": 28, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.01792813278734684}, {\"epoch\": 29, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.013177729211747646}, {\"epoch\": 30, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.015412080101668835}, {\"epoch\": 31, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.012737027369439602}, {\"epoch\": 32, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.01158237550407648}, {\"epoch\": 33, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.015846751630306244}, {\"epoch\": 34, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.009726863354444504}, {\"epoch\": 35, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.013770977035164833}, {\"epoch\": 36, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.01325669139623642}, {\"epoch\": 37, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.010539363138377666}, {\"epoch\": 38, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.014410804025828838}, {\"epoch\": 39, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.011377089656889439}, {\"epoch\": 40, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.008498246781527996}, {\"epoch\": 41, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.012667261995375156}, {\"epoch\": 42, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.008959290571510792}, {\"epoch\": 43, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.009479817934334278}, {\"epoch\": 44, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.011793718673288822}, {\"epoch\": 45, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.009934712201356888}, {\"epoch\": 46, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.009019505232572556}, {\"epoch\": 47, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.011183277703821659}, {\"epoch\": 48, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.009432587772607803}, {\"epoch\": 49, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.008917190134525299}, {\"epoch\": 50, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.006535314954817295}, {\"epoch\": 1, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 0.7360697388648987}, {\"epoch\": 2, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 0.7026447057723999}, {\"epoch\": 3, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 0.7143529057502747}, {\"epoch\": 4, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 0.7632628679275513}, {\"epoch\": 5, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 0.8413727283477783}, {\"epoch\": 6, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 0.9431805610656738}, {\"epoch\": 7, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.089343547821045}, {\"epoch\": 8, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.2603946924209595}, {\"epoch\": 9, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.3944026231765747}, {\"epoch\": 10, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.4804491996765137}, {\"epoch\": 11, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.506500005722046}, {\"epoch\": 12, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.6023366451263428}, {\"epoch\": 13, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.8026986122131348}, {\"epoch\": 14, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.790058970451355}, {\"epoch\": 15, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.8482083082199097}, {\"epoch\": 16, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.9251238107681274}, {\"epoch\": 17, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.9789693355560303}, {\"epoch\": 18, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.992303729057312}, {\"epoch\": 19, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.095522403717041}, {\"epoch\": 20, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.1598150730133057}, {\"epoch\": 21, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.2177627086639404}, {\"epoch\": 22, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.2518317699432373}, {\"epoch\": 23, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.3263235092163086}, {\"epoch\": 24, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.3698105812072754}, {\"epoch\": 25, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.400423526763916}, {\"epoch\": 26, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.4699718952178955}, {\"epoch\": 27, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.5376577377319336}, {\"epoch\": 28, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.5017244815826416}, {\"epoch\": 29, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.6764841079711914}, {\"epoch\": 30, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.614586353302002}, {\"epoch\": 31, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.6275620460510254}, {\"epoch\": 32, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.690580368041992}, {\"epoch\": 33, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.693664789199829}, {\"epoch\": 34, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.765472173690796}, {\"epoch\": 35, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.779203176498413}, {\"epoch\": 36, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.8351199626922607}, {\"epoch\": 37, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.8051857948303223}, {\"epoch\": 38, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.9429476261138916}, {\"epoch\": 39, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.877197742462158}, {\"epoch\": 40, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.9943668842315674}, {\"epoch\": 41, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.9824724197387695}, {\"epoch\": 42, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.966156005859375}, {\"epoch\": 43, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 3.050158739089966}, {\"epoch\": 44, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 3.060084819793701}, {\"epoch\": 45, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 3.121770143508911}, {\"epoch\": 46, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 3.2096378803253174}, {\"epoch\": 47, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 3.155256986618042}, {\"epoch\": 48, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 3.249047040939331}, {\"epoch\": 49, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 3.2978403568267822}, {\"epoch\": 50, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 3.2933096885681152}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# List of node counts to test\n",
    "nodes_list = [8, 16, 32, 64, 128, 256, 512]\n",
    "\n",
    "# Prepare a DataFrame to collect all metrics for plotting\n",
    "df_all_models = pd.DataFrame()\n",
    "\n",
    "for nodes in nodes_list:\n",
    "    print(f\"\\nTraining model with {nodes} hidden nodes:\")\n",
    "    \n",
    "    # Define the model architecture\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=(462,)),\n",
    "        Dense(nodes, activation='relu'),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': range(1, 51),\n",
    "        'training_accuracy': history.history['accuracy'],\n",
    "        'validation_accuracy': history.history['val_accuracy'],\n",
    "        'training_loss': history.history['loss'],\n",
    "        'validation_loss': history.history['val_loss'],\n",
    "        'hidden_nodes': [nodes] * 50\n",
    "    })\n",
    "    \n",
    "    # Melt the dataframe for long format\n",
    "    df_long = df.melt(id_vars=['epoch', 'hidden_nodes'], \n",
    "                      value_vars=['training_accuracy', 'validation_accuracy', 'training_loss', 'validation_loss'],\n",
    "                      var_name='metric', value_name='value')\n",
    "    \n",
    "    # Concatenate all data\n",
    "    df_all_models = pd.concat([df_all_models, df_long], ignore_index=True)\n",
    "\n",
    "# Plotting with Altair\n",
    "\n",
    "# Define the color mapping for metrics\n",
    "color_mapping = {\n",
    "    'training_accuracy': 'Training Accuracy',\n",
    "    'validation_accuracy': 'Validation Accuracy',\n",
    "    'training_loss': 'Training Loss',\n",
    "    'validation_loss': 'Validation Loss'\n",
    "}\n",
    "\n",
    "df_all_models['metric'] = df_all_models['metric'].map(color_mapping)\n",
    "\n",
    "# Altair plot: Interactive plot for all models\n",
    "chart = alt.Chart(df_all_models).mark_line().encode(\n",
    "    x='epoch',\n",
    "    y='value',\n",
    "    color='metric',\n",
    "    column='hidden_nodes:O',  # Separate charts for each node configuration\n",
    "    tooltip=['epoch', 'value', 'metric', 'hidden_nodes']\n",
    ").properties(\n",
    "    title=\"Model Performance: Accuracy & Loss for Different Hidden Node Configurations\",\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "chart.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graphs, we can notice that the more we increase the number of nodes, the more we tend to have an increase on loss metrics, especially the Validation_loss in the cases of 128, 256, 512."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - **Varying the number of layers**.\n",
    "\n",
    "        - Conduct similar experiments as described above, but this time vary the number of layers from 1 to 4. Document your findings.\n",
    "\n",
    "        - How many nodes should each layer contain? Test at least two scenarios. Traditionally, a common strategy involved decreasing the number of nodes from the input layer to the output layer, often by halving, to create a pyramid-like structure. However, recent experience suggests that maintaining a constant number of nodes across all layers can perform equally well. Describe your observations. It is acceptable if both strategies yield similar performance results.\n",
    "\n",
    "        - Select one your models that exemplifies overfitting. In our experiments, we easily constructed a model achieving nearly 100% accuracy on the training data, yet showing no similar improvement on the validation set. Present this neural network along with its accuracy and loss graphs. Explain the reasoning for concluding that the model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 1 hidden layers:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 2 hidden layers:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 3 hidden layers:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 4 hidden layers:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-c7c7e3aa45814b25a30d97e866ab365d.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-c7c7e3aa45814b25a30d97e866ab365d.vega-embed details,\n",
       "  #altair-viz-c7c7e3aa45814b25a30d97e866ab365d.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-c7c7e3aa45814b25a30d97e866ab365d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-c7c7e3aa45814b25a30d97e866ab365d\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-c7c7e3aa45814b25a30d97e866ab365d\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-26a39a12ecaaafe13d6f9ee7799327f3\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"column\": {\"field\": \"num_layers\", \"type\": \"ordinal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}, {\"field\": \"num_layers\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Model Performance: Accuracy & Loss for Different Layer Configurations\", \"width\": 300, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-26a39a12ecaaafe13d6f9ee7799327f3\": [{\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.6685251593589783}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7061982154846191}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7357739806175232}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7607177495956421}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7825736403465271}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8045324087142944}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8266284465789795}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8454821705818176}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8630492091178894}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8777684569358826}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8909608721733093}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9041532874107361}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9158703684806824}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9259920120239258}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9360793232917786}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9446226954460144}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.952222466468811}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9592561721801758}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9649860262870789}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9699438810348511}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9748502969741821}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9793278574943542}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9816266894340515}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9835652112960815}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9842514395713806}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9843543767929077}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9846460223197937}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9857267737388611}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9852121472358704}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9862586259841919}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9873050451278687}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9867560863494873}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9875109195709229}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9884544610977173}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9884030222892761}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9889348149299622}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9889348149299622}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9903415441513062}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9903243780136108}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9894837737083435}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.990530252456665}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9918169379234314}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9915938973426819}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9918855428695679}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9927947521209717}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9930177927017212}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9918512105941772}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.992811918258667}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9928805232048035}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9922457933425903}, {\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6737751364707947}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.693480908870697}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.7030638456344604}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.7036037445068359}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.700499415397644}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6972600817680359}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6959103941917419}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6917262673377991}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6852476596832275}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6826832294464111}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6786341071128845}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6748549342155457}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6681063771247864}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6658118367195129}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6600080728530884}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6569037437438965}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6531245708465576}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6515049338340759}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.650155246257782}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6481306552886963}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6447563767433167}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6444864273071289}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6415171027183533}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6444864273071289}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.642731785774231}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6386826634407043}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6388176679611206}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6403023600578308}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6419219970703125}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6421919465065002}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6417869925498962}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6400324106216431}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6408421993255615}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6432716846466064}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6455662250518799}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.642461895942688}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.64070725440979}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6443514823913574}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.64070725440979}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6417869925498962}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6408421993255615}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6416520476341248}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6339586973190308}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6416520476341248}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6382777690887451}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6359832882881165}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6393575668334961}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6381428241729736}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6392225623130798}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6412471532821655}, {\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.7715085744857788}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.7004325985908508}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.6400502920150757}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.5886278748512268}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.5404442548751831}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.4937760829925537}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.449837327003479}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.4090248942375183}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.37195339798927307}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.33828309178352356}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.3079987168312073}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2798711359500885}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2544098496437073}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.23095232248306274}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.20927459001541138}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.18910355865955353}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.17020267248153687}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.15305359661579132}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.136817067861557}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.12224864959716797}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.10919304192066193}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.09703557938337326}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.08799295127391815}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.08025115728378296}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.07425490021705627}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.0692889392375946}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.06663079559803009}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.06146957725286484}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.060231659561395645}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.055799487978219986}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.052454300224781036}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.05211259052157402}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.04906442388892174}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.04559110850095749}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.04472457244992256}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.04270317032933235}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.04233946651220322}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.03888130560517311}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.0382266603410244}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.03801067918539047}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.035080455243587494}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.03252475708723068}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.03194691240787506}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.03126995638012886}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.028656773269176483}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.02844727598130703}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.029160259291529655}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.02762552537024021}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.026402266696095467}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.027095891535282135}, {\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7645562887191772}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.721448540687561}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7032069563865662}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7037093639373779}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7143298983573914}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7338557243347168}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7570232152938843}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7873125076293945}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.826165497303009}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.8695861101150513}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.9209516644477844}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.9752680063247681}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.0357824563980103}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.0988919734954834}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.1686729192733765}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.2484060525894165}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.3201594352722168}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.397282600402832}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.4899364709854126}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.5884153842926025}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.677123785018921}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.7665883302688599}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.8360134363174438}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.9263211488723755}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.9976468086242676}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.098038673400879}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.143101692199707}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.209439277648926}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.2675089836120605}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.3237383365631104}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.4238734245300293}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.4672107696533203}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.49479079246521}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.577942132949829}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.615260124206543}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.6857998371124268}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.6883599758148193}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.7627358436584473}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.849764823913574}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.838686227798462}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.8850789070129395}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.902829647064209}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.009352207183838}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.076117753982544}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.0725605487823486}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.1040842533111572}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.173229694366455}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.2056686878204346}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.2656919956207275}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.311340093612671}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.6694172620773315}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7219125032424927}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7552623748779297}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7863821387290955}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8155461549758911}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8416050672531128}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8645073771476746}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8840644359588623}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8991954326629639}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9121305346488953}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9226810336112976}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9306411147117615}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9380693435668945}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9466641545295715}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9492374658584595}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9530287981033325}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9576435685157776}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9618980884552002}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9657922983169556}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9660667777061462}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9668731093406677}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.970578670501709}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9729289412498474}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9734607338905334}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9753821492195129}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9758110046386719}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9769604206085205}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9785730242729187}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9800312519073486}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9783157110214233}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9806316494941711}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9821584820747375}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9811806082725525}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9823815226554871}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9829819202423096}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.983393669128418}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9829304814338684}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9855895638465881}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9837710857391357}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9852121472358704}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9856410026550293}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9863615036010742}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9865502119064331}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9866188764572144}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9860527515411377}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9868761897087097}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9870992302894592}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9872021675109863}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9874423146247864}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9874594807624817}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6841679215431213}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6971251368522644}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6982048749923706}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6953704953193665}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6888918876647949}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6799837946891785}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6645970940589905}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6594682335853577}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6587933301925659}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6548792123794556}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6531245708465576}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6461060643196106}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6404373049736023}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6443514823913574}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6531245708465576}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6488054990768433}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6466459631919861}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6396274566650391}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6393575668334961}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6367930769920349}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6411121487617493}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6448913216590881}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.642731785774231}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6380078196525574}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6417869925498962}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.643136739730835}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6434066891670227}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6384127140045166}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6461060643196106}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6450263261795044}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6481306552886963}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6438115835189819}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6398974061012268}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6393575668334961}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6381428241729736}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6366581320762634}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6438115835189819}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6397624611854553}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6365231275558472}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.643136739730835}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6408421993255615}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6393575668334961}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6369280815124512}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6334187984466553}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6305844187736511}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6365231275558472}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6394925117492676}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6386826634407043}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6401673555374146}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6384127140045166}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.762952983379364}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.6655792593955994}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.5922089219093323}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.5244320034980774}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.4611971080303192}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.40234532952308655}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.34903931617736816}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.30261868238449097}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.26520493626594543}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.23178164660930634}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.20744046568870544}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.1854168176651001}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.16708271205425262}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.14667345583438873}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.13663862645626068}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.12497803568840027}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.11636132001876831}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.10585508495569229}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.09462849050760269}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.09463918954133987}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.09037870913743973}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.08125056326389313}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.07901652157306671}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.07464738190174103}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.07067766785621643}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.06798621267080307}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.06781771034002304}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.06176377832889557}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.05766059830784798}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.061127014458179474}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.05412047728896141}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.05306791514158249}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.053066372871398926}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.05307289958000183}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.04868069663643837}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.048321619629859924}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.04992842674255371}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.041994549334049225}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.04835779219865799}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.0453677773475647}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.041581351310014725}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.04039726033806801}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.03902532532811165}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.0402618870139122}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.04231073707342148}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.0408567413687706}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.03724362328648567}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.03863303363323212}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.038933996111154556}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.036364708095788956}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7475342750549316}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7130259275436401}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7308506369590759}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7784273624420166}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.8491640686988831}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.9426835179328918}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.0756818056106567}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.192563772201538}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.2881274223327637}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.4353725910186768}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.5476207733154297}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.7535505294799805}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.9066431522369385}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.9727911949157715}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.997239112854004}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.1240949630737305}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.2960221767425537}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.3991899490356445}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.524751663208008}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.5997393131256104}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.679347276687622}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.6978402137756348}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.749605178833008}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.815418004989624}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.865562915802002}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.982381582260132}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.9389712810516357}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.0908894538879395}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.0961217880249023}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.223923444747925}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.2739901542663574}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.37007212638855}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.3864641189575195}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.357849359512329}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.4869418144226074}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.5074527263641357}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.5572597980499268}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.620314836502075}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.6929004192352295}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.779168128967285}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.7731738090515137}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.8126752376556396}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.8742053508758545}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.8942184448242188}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.99240779876709}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.923074722290039}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.9977498054504395}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 4.109804630279541}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 4.202768802642822}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 4.170292854309082}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.6668611168861389}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7211747765541077}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7594311237335205}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7937074303627014}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8275548815727234}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8533564209938049}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.872107207775116}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8875641226768494}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9007908701896667}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9108781814575195}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9200047850608826}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9274673461914062}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9351529479026794}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9409857392311096}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9459436535835266}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.949409008026123}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9516735076904297}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9587414860725403}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9605427980422974}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.961108922958374}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9651919007301331}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.966598629951477}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9700468182563782}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9697209000587463}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9714364409446716}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9728260040283203}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9735808372497559}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9761884212493896}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9760854840278625}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.978590190410614}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9788818359375}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.979465126991272}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9800826907157898}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9818325042724609}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9815065860748291}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9817810654640198}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9832392930984497}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9826045036315918}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9834280014038086}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9831191897392273}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9844401478767395}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9857953786849976}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.983925461769104}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9853836894035339}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9852121472358704}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9854351282119751}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9860355854034424}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9870820641517639}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9870134592056274}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9876824617385864}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6838979721069336}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6953704953193665}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.695235550403595}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.684707760810852}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6751248240470886}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6691861152648926}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6650020480155945}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6658118367195129}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6596031785011292}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.657443642616272}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6521797776222229}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6479957103729248}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.650425136089325}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.642731785774231}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.643136739730835}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6371980309486389}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6425968408584595}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6440815329551697}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6454312205314636}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6444864273071289}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6436766386032104}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6408421993255615}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6452962756156921}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6292347311973572}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6428667902946472}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6415171027183533}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6421919465065002}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6331488490104675}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6405722498893738}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6288297772407532}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6384127140045166}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6362531781196594}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6351734399795532}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.633013904094696}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6371980309486389}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6403023600578308}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.635443389415741}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6409772038459778}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.641382098197937}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.634768545627594}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6370630264282227}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6359832882881165}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6308543682098389}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6326090097427368}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6358482837677002}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6393575668334961}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.633688747882843}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6388176679611206}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6389526128768921}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6335538029670715}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.7679141759872437}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.6651329398155212}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.5817568898200989}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.5073858499526978}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.4389611780643463}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.3805616796016693}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.33393535017967224}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.2943861782550812}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.2599317133426666}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.2352634072303772}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.20972317457199097}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.19058240950107574}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.17172963917255402}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.15608835220336914}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.14617758989334106}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.13608451187610626}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.12861387431621552}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.11165279150009155}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.10649281740188599}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.10584676265716553}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.09596865624189377}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.09017230570316315}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.08445277065038681}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.08394979685544968}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.07972928881645203}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.07469537109136581}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.07227908074855804}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.0678664818406105}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.06554963439702988}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.057718005031347275}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.060489680618047714}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.05673215538263321}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.057829100638628006}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.05311070755124092}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.053015854209661484}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.05176512151956558}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.04971838369965553}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.04832088574767113}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.047677814960479736}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.047428280115127563}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.0443883091211319}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.04012998566031456}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.04561399668455124}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.0410013422369957}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.042335327714681625}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.04135074093937874}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.038410842418670654}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.03826884180307388}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.037646614015102386}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.03485690429806709}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7548676133155823}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7264015078544617}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7676588296890259}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.862720251083374}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.9866679906845093}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.1128809452056885}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.1932623386383057}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.3293423652648926}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.4620722532272339}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.5370922088623047}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.7254762649536133}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.786560297012329}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.8961448669433594}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.017848253250122}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.1149485111236572}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.178169012069702}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.1800663471221924}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.345261335372925}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.5295679569244385}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.3904786109924316}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.4740054607391357}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.6551389694213867}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.7337732315063477}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.668679714202881}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.9334323406219482}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.918344020843506}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.9766039848327637}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.861496686935425}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.992276906967163}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.0973246097564697}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.0949745178222656}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.213000535964966}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.291461706161499}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.40939998626709}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.4919066429138184}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.386566400527954}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.4425389766693115}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.429138422012329}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.409015417098999}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.641127824783325}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.583738327026367}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.7730700969696045}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.6581175327301025}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.8238675594329834}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.6908352375030518}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.669975996017456}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.743898630142212}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.8724350929260254}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.9399912357330322}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 4.062245845794678}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.6668611168861389}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7190475463867188}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7560687065124512}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7914257645606995}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8201780915260315}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8450532555580139}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8658969402313232}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8808392286300659}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8938086628913879}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9020088911056519}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9109296202659607}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9195073246955872}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.927604615688324}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9330599904060364}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9363538026809692}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.944502592086792}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9487571120262146}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9526513814926147}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9562196731567383}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9591703414916992}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9603540897369385}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9641968607902527}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9668387770652771}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9670961499214172}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9697723388671875}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9711962342262268}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.972568690776825}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9730661511421204}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9733749628067017}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9761884212493896}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.976445734500885}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9775608777999878}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.978144109249115}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9797910451889038}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9788131713867188}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9814379811286926}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9807345867156982}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9815237522125244}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9812663793563843}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9825358986854553}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9828618764877319}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9841313362121582}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9836167097091675}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9847832322120667}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9846802949905396}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9854179620742798}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9850062727928162}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9852292537689209}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9857611060142517}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9867904186248779}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6790390014648438}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6925361156463623}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6918612718582153}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6855176091194153}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6829531788825989}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6767445206642151}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6678364276885986}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6636523008346558}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6551491618156433}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6524497270584106}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6536644697189331}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6602780222892761}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6519098281860352}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6482656002044678}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6409772038459778}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6369280815124512}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6417869925498962}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6378728747367859}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6461060643196106}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6409772038459778}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6403023600578308}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6455662250518799}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6474558115005493}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6454312205314636}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6443514823913574}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6482656002044678}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6411121487617493}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.648400604724884}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6434066891670227}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6482656002044678}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6428667902946472}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6434066891670227}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6466459631919861}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6473208069801331}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6482656002044678}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6474558115005493}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6465110182762146}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6520448327064514}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6415171027183533}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.633688747882843}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6479957103729248}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6423268914222717}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6498852968215942}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6408421993255615}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6417869925498962}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6408421993255615}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6419219970703125}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6467809677124023}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6544742584228516}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6552841067314148}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.7692156434059143}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.6683310270309448}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.586307942867279}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.5125508308410645}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.4483499228954315}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.39362916350364685}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.34623727202415466}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.3081114888191223}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.2761761546134949}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.2536250948905945}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.22822853922843933}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.20705106854438782}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.1864103227853775}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.17460376024246216}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.1647634655237198}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.1467333436012268}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.13733157515525818}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.12504206597805023}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.11752676218748093}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.11084935069084167}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.10472728312015533}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.09816405922174454}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.09099853038787842}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.09008286148309708}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.0825895443558693}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.07825016230344772}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.07461228221654892}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.07217616587877274}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.07184281200170517}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.0669359564781189}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.06406890600919724}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.061218369752168655}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.06165027618408203}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.05721522122621536}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.05824541673064232}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.053115151822566986}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.053812772035598755}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04996499791741371}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.053690169006586075}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.0501045361161232}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04942788928747177}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.045517049729824066}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.045040857046842575}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04428904503583908}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.044572584331035614}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04149521142244339}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04072364419698715}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04172294959425926}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04184827208518982}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.03756966069340706}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.757575273513794}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7316242456436157}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7591719627380371}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.841046154499054}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.9104887247085571}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.0594033002853394}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.1432836055755615}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.225927710533142}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.3580355644226074}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.4161440134048462}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.64658784866333}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.666430115699768}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.7549561262130737}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.8421624898910522}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.0202324390411377}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.1382360458374023}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.1888890266418457}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.4649691581726074}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.410106897354126}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.482504367828369}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.383671998977661}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.6329219341278076}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.6369857788085938}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.823061466217041}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.664426803588867}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.8806703090667725}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.079913854598999}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.987243890762329}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.875903606414795}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.0402894020080566}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.00993275642395}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.007875442504883}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.1881868839263916}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.143911600112915}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.3414409160614014}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.3697643280029297}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.2556257247924805}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.5693511962890625}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.3089888095855713}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.265123128890991}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.2948074340820312}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.570040464401245}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.7098121643066406}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.5023748874664307}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.5499229431152344}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.61200213432312}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.5249924659729004}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.6288721561431885}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.5852766036987305}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.793187379837036}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to build model with a given number of layers and nodes\n",
    "def build_model(num_layers, nodes_per_layer):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(462,)))\n",
    "    for _ in range(num_layers):\n",
    "        model.add(Dense(nodes_per_layer, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Number of layers to test\n",
    "layers_list = [1, 2, 3, 4]\n",
    "nodes_per_layer = 128  # You can adjust this value\n",
    "\n",
    "# Prepare a DataFrame to collect all metrics for plotting\n",
    "df_all_models = pd.DataFrame()\n",
    "\n",
    "for num_layers in layers_list:\n",
    "    print(f\"\\nTraining model with {num_layers} hidden layers:\")\n",
    "    model = build_model(num_layers, nodes_per_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': range(1, 51),\n",
    "        'training_accuracy': history.history['accuracy'],\n",
    "        'validation_accuracy': history.history['val_accuracy'],\n",
    "        'training_loss': history.history['loss'],\n",
    "        'validation_loss': history.history['val_loss'],\n",
    "        'num_layers': [num_layers] * 50\n",
    "    })\n",
    "    \n",
    "    # Melt the dataframe for long format\n",
    "    df_long = df.melt(id_vars=['epoch', 'num_layers'], \n",
    "                      value_vars=['training_accuracy', 'validation_accuracy', 'training_loss', 'validation_loss'],\n",
    "                      var_name='metric', value_name='value')\n",
    "    \n",
    "    # Concatenate all data\n",
    "    df_all_models = pd.concat([df_all_models, df_long], ignore_index=True)\n",
    "\n",
    "# Plotting with Altair\n",
    "\n",
    "# Define the color mapping for metrics\n",
    "color_mapping = {\n",
    "    'training_accuracy': 'Training Accuracy',\n",
    "    'validation_accuracy': 'Validation Accuracy',\n",
    "    'training_loss': 'Training Loss',\n",
    "    'validation_loss': 'Validation Loss'\n",
    "}\n",
    "\n",
    "df_all_models['metric'] = df_all_models['metric'].map(color_mapping)\n",
    "\n",
    "# Altair plot: Interactive plot for all models\n",
    "chart = alt.Chart(df_all_models).mark_line().encode(\n",
    "    x='epoch',\n",
    "    y='value',\n",
    "    color='metric',\n",
    "    column='num_layers:O',  # Separate charts for each layer configuration\n",
    "    tooltip=['epoch', 'value', 'metric', 'num_layers']\n",
    ").properties(\n",
    "    title=\"Model Performance: Accuracy & Loss for Different Layer Configurations\",\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "chart.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the scenario where we have constant nodes per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Constant Nodes per Layer:\n",
      "\n",
      "Training model with 1 layers of 64 nodes each\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 2 layers of 64 nodes each\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 3 layers of 64 nodes each\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 4 layers of 64 nodes each\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-ac8dbdc056de4078a70ccf9b21575fd4.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-ac8dbdc056de4078a70ccf9b21575fd4.vega-embed details,\n",
       "  #altair-viz-ac8dbdc056de4078a70ccf9b21575fd4.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-ac8dbdc056de4078a70ccf9b21575fd4\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ac8dbdc056de4078a70ccf9b21575fd4\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ac8dbdc056de4078a70ccf9b21575fd4\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-b70c533cbb498fce43816189fcb927de\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"column\": {\"field\": \"num_layers\", \"type\": \"ordinal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}, {\"field\": \"num_layers\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Model Performance: Accuracy & Loss for Different Layer Configurations\", \"width\": 300, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-b70c533cbb498fce43816189fcb927de\": [{\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.6681649088859558}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.6957849264144897}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.717263400554657}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7373350858688354}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7530665397644043}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7672882676124573}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7798973917961121}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7914772629737854}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8015645742416382}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8114803433418274}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8196977376937866}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.827674925327301}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8339709639549255}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8399066925048828}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8452591300010681}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8493935465812683}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8545401692390442}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8580912947654724}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8615395426750183}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8647818565368652}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8688305020332336}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8717812299728394}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8741658329963684}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8770650625228882}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8806848526000977}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8830522894859314}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8861402273178101}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8884733319282532}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8909780383110046}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8927964568138123}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8944605588912964}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.897016704082489}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8984405994415283}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9008594751358032}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9030210375785828}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9050796627998352}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9070010781288147}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.908424973487854}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9106037020683289}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9120447635650635}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9136402010917664}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9152184724807739}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9168310761451721}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9182892441749573}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9196445345878601}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9216345548629761}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9225952625274658}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9234015345573425}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9252028465270996}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9262321591377258}, {\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6691861152648926}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.679443895816803}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6938858032226562}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.7017141580581665}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.700769305229187}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6998245120048523}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6991496682167053}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6956404447555542}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6964502334594727}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6895667314529419}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.68646240234375}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6824132800102234}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.67917400598526}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6748549342155457}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6716156005859375}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6681063771247864}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6662167906761169}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6614927649497986}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.658523440361023}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.657443642616272}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6552841067314148}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6535294651985168}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6492103934288025}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.648400604724884}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6473208069801331}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6439465284347534}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.643136739730835}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6411121487617493}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6393575668334961}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6398974061012268}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6401673555374146}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6392225623130798}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6378728747367859}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6378728747367859}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6358482837677002}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.634768545627594}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6353083848953247}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.633688747882843}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6335538029670715}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6326090097427368}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6312592625617981}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6299095749855042}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.628424882888794}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6285598874092102}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6290997266769409}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6246457099914551}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6250506043434143}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6246457099914551}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6242408156394958}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6238358616828918}, {\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.7753736972808838}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.7223711609840393}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.6805453300476074}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.6355885863304138}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.6003930568695068}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.5713599324226379}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.5457661151885986}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.5223017930984497}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.5004631876945496}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.48040321469306946}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.4620625674724579}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.44543516635894775}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.43074214458465576}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.41732317209243774}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.4048830270767212}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.39381173253059387}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.38348546624183655}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.3741203844547272}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.3652437925338745}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.3569004535675049}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.34907597303390503}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.34182533621788025}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.33483877778053284}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.3283020555973053}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.32226991653442383}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.31614115834236145}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.310423880815506}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.3051673471927643}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.29982495307922363}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2948879301548004}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2900494933128357}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2854647636413574}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2809693515300751}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2765035331249237}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.27221351861953735}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2680884599685669}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.26406797766685486}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.26008716225624084}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.25624966621398926}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2524837553501129}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.24876931309700012}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.24515339732170105}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.24166640639305115}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.23825788497924805}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.23490050435066223}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2316262573003769}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.22850701212882996}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.22513964772224426}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.22255593538284302}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.21944351494312286}, {\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7747651934623718}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7521189451217651}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7231416702270508}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7106168866157532}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.710325300693512}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7160640954971313}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7267299890518188}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.739582896232605}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7544885873794556}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7719840407371521}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7902148365974426}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.8105161190032959}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.833477795124054}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.8571079969406128}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.8811978101730347}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.9080842137336731}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.9335303902626038}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.9592781066894531}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.9845045208930969}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.010557770729065}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.0347448587417603}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.0617295503616333}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.086836576461792}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.1122183799743652}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.138563632965088}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.1628930568695068}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.1885950565338135}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.2138185501098633}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.2359411716461182}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.2604817152023315}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.2849987745285034}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.308943748474121}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.335816740989685}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.3593840599060059}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.384550929069519}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.4095423221588135}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.4337035417556763}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.4577847719192505}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.4849798679351807}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.5103709697723389}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.5383623838424683}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.5630110502243042}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.590133547782898}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.6160551309585571}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.6397173404693604}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.6667087078094482}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.6937073469161987}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.7207211256027222}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.7480573654174805}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.775846242904663}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.6657631397247314}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7068672776222229}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7347617745399475}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7550565004348755}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7718001008033752}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7848209738731384}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7984423041343689}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8090957403182983}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8212416768074036}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8317579030990601}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8407129645347595}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8494793176651001}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.85627281665802}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8631006479263306}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8697740435600281}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8762587904930115}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8807706236839294}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8854883313179016}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8910466432571411}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8933454751968384}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8982518911361694}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9011511206626892}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.905903160572052}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.908133327960968}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9113070368766785}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9159904718399048}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9178260564804077}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9184951186180115}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9226981997489929}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9245166778564453}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9267982840538025}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9264208674430847}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9298862814903259}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.933334469795227}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.933094322681427}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9363023638725281}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.936199426651001}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9378291964530945}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.941689133644104}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9432502388954163}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9442452788352966}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9441594481468201}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9470930099487305}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9474704265594482}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9483796954154968}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9508329033851624}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9537664651870728}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9515191316604614}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9534233212471008}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9539036750793457}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6782291531562805}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6992846727371216}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.7037386894226074}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.701849102973938}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.7003644108772278}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6953704953193665}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6898366808891296}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6843028664588928}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6795789003372192}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6779592633247375}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6743150353431702}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6725603938102722}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6671615839004517}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6650020480155945}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6618977189064026}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6614927649497986}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6573086977005005}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.655419111251831}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6523147225379944}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.650155246257782}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6451612710952759}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.641382098197937}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6396274566650391}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6388176679611206}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6327439546585083}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6312592625617981}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6300445199012756}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6281549334526062}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.633013904094696}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.626400351524353}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6301795244216919}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6269401907920837}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6243757605552673}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.627750039100647}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6196517944335938}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6241058111190796}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6251856088638306}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.627750039100647}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6274800896644592}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6218113303184509}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6234309673309326}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6197867393493652}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6278849840164185}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6243757605552673}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6220812797546387}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6234309673309326}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.625320553779602}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6254554986953735}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6242408156394958}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6224861741065979}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.7720744013786316}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.6936473250389099}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.6373959183692932}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.5957188010215759}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.5603805184364319}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.5291444659233093}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.5005781650543213}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.47472280263900757}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.4511528015136719}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.4292103052139282}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.40966731309890747}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.39146688580513}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.37539204955101013}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.36002957820892334}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.34504517912864685}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.3314530551433563}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.31870049238204956}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.30633917450904846}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.2944329082965851}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.28429552912712097}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.2735203206539154}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.2645302414894104}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.2546744644641876}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.24773859977722168}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.23812232911586761}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.22898562252521515}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.22265148162841797}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.21932268142700195}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.2087980955839157}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.20434552431106567}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.19758795201778412}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.1968207210302353}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.18849968910217285}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.18042342364788055}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.17800675332546234}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.17339158058166504}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.17168357968330383}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.16522380709648132}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.15843747556209564}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.1538451761007309}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.15064561367034912}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.15030473470687866}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.14374366402626038}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.1414913833141327}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.13977070152759552}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.13342060148715973}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.12718254327774048}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.13094905018806458}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.1263624131679535}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.12523627281188965}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7588636875152588}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7174870371818542}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7105939984321594}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.72072833776474}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7385978102684021}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7669289708137512}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.8024677038192749}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.8468301296234131}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.88371741771698}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.9311144948005676}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.9722047448158264}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.0288969278335571}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.0776113271713257}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.1340532302856445}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.183590054512024}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.2364919185638428}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.2934274673461914}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.3439805507659912}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.4006829261779785}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.460984706878662}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.5205247402191162}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.5650255680084229}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.6447231769561768}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.6882878541946411}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.7489573955535889}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.8247945308685303}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.8726613521575928}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.9333971738815308}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.9854204654693604}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.030745029449463}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.103761911392212}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.172089099884033}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.224334716796875}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.283630609512329}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.376723051071167}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.4393911361694336}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.467862367630005}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.4745254516601562}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.551267385482788}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.676995277404785}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.71277117729187}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.7729814052581787}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.8554627895355225}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.863586664199829}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.9073476791381836}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.951073169708252}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.97879958152771}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.100493907928467}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.1632611751556396}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.1289584636688232}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.665694534778595}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7012574672698975}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7322056293487549}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7565318942070007}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7754884958267212}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7928153276443481}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8067111372947693}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8203839063644409}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8301967978477478}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8401640057563782}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8487244844436646}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8561698794364929}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.863804042339325}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8684702515602112}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8745089173316956}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8793123960494995}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.884630560874939}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8887993097305298}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8933797478675842}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8955070376396179}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9006364345550537}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9042218923568726}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9052340984344482}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9085107445716858}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9128853678703308}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9157674312591553}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9154415130615234}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.919249951839447}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9219262003898621}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9238476157188416}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.925906240940094}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9287368655204773}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9295603036880493}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9323223233222961}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9320821166038513}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9365940093994141}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9348269701004028}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9374688863754272}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9380007386207581}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9427012801170349}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9425469040870667}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9405053853988647}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9459264874458313}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9447255730628967}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9451888203620911}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.948139488697052}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9464754462242126}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9486713409423828}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9505412578582764}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9525998830795288}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6741800308227539}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6906465291976929}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6968551874160767}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6929410099983215}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6870023012161255}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6749898791313171}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6739100813865662}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6694560647010803}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6662167906761169}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6674314737319946}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6624375581741333}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6570387482643127}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6569037437438965}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6475907564163208}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6498852968215942}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6525846719741821}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.650155246257782}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6498852968215942}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6438115835189819}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6450263261795044}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6457011699676514}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6440815329551697}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6408421993255615}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6440815329551697}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6444864273071289}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.642461895942688}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6374679207801819}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6403023600578308}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6398974061012268}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6365231275558472}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6389526128768921}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6362531781196594}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6371980309486389}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6315292119979858}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6355783343315125}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6358482837677002}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6358482837677002}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6390876173973083}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6384127140045166}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.633013904094696}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6326090097427368}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6349034905433655}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6331488490104675}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6295046806335449}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6312592625617981}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6392225623130798}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6327439546585083}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6250506043434143}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6293696761131287}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.633688747882843}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.7737429738044739}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.7059969305992126}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.6438785195350647}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.5928300619125366}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.5523959398269653}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.5166926980018616}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.4852015972137451}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.45692482590675354}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.43203938007354736}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.40917786955833435}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.3885009288787842}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.36993664503097534}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.3518863320350647}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.3392762243747711}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.3242252469062805}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.31301453709602356}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.2991480827331543}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.28819653391838074}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.2773810029029846}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.269658625125885}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.259365051984787}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.2505006492137909}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.24420133233070374}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.2372462898492813}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.22546854615211487}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.22138060629367828}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.21822042763233185}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.20838965475559235}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.2045219987630844}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.1986117660999298}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.19166246056556702}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.18646737933158875}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.181564599275589}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.17890574038028717}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.1765821874141693}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.16367992758750916}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.16689158976078033}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.16438375413417816}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.16280747950077057}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.15098996460437775}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.15216867625713348}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.15605701506137848}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.1449366956949234}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.1451011598110199}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.14253030717372894}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.13560160994529724}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.13973741233348846}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.1355273723602295}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.13155710697174072}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.12501733005046844}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7725964188575745}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7292667031288147}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.725821316242218}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7402453422546387}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7765437960624695}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.8271851539611816}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.8791210055351257}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.9423100352287292}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.99642014503479}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.039448618888855}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.1073057651519775}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.1673247814178467}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.2058460712432861}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.279256820678711}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.370056390762329}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.3969167470932007}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.4731369018554688}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.5409023761749268}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.6040807962417603}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.6653246879577637}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.7514342069625854}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.7561798095703125}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.8248687982559204}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.870658040046692}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.9654597043991089}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.0256097316741943}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.0959632396698}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.1780202388763428}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.201272964477539}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.2732186317443848}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.2585718631744385}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.3626599311828613}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.488499879837036}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.488478183746338}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.55368971824646}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.6876344680786133}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.660734176635742}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.7305078506469727}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.815967321395874}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.7948338985443115}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.877636671066284}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.9050920009613037}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.8930654525756836}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.9384853839874268}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.070211887359619}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.006836175918579}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.0488877296447754}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.1073663234710693}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.1725704669952393}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.161916971206665}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.663944661617279}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7083426117897034}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7330291271209717}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7545247077941895}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7707536220550537}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7866394519805908}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7998661994934082}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8100907802581787}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8207613229751587}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8296821117401123}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8394091725349426}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8469231724739075}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8544715046882629}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8580226898193359}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.866325855255127}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.870648980140686}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8763960003852844}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8799128532409668}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8837384581565857}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8877356648445129}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8929508924484253}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8953011631965637}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8997958302497864}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9016314744949341}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9037415981292725}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9073956608772278}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9085622429847717}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9132970571517944}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9133828282356262}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9155615568161011}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9182378053665161}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9192842841148376}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9218404293060303}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9251685738563538}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9270041584968567}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9269355535507202}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9294230937957764}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9300063252449036}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9322708249092102}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.934792697429657}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9344838857650757}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9338319897651672}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9367483854293823}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9390643239021301}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9415690302848816}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9410543441772461}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9422037601470947}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9430786967277527}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9446055293083191}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9461151957511902}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6774193644523621}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6953704953193665}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6988797187805176}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6968551874160767}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6960453391075134}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.692401111125946}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6892967820167542}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6834930777549744}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6795789003372192}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.678769052028656}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6767445206642151}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.672155499458313}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6756647229194641}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6671615839004517}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6658118367195129}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6687812209129333}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6616277694702148}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6641921997070312}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6570387482643127}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6589283347129822}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6562288999557495}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6513699293136597}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6532595753669739}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6578485369682312}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6528546214103699}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6544742584228516}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.655419111251831}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6531245708465576}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6461060643196106}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6465110182762146}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.642056941986084}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6412471532821655}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6419219970703125}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6430017352104187}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6415171027183533}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6409772038459778}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6382777690887451}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6398974061012268}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6405722498893738}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6415171027183533}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6369280815124512}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6377378702163696}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6384127140045166}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6401673555374146}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6331488490104675}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6389526128768921}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6326090097427368}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6350384950637817}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6339586973190308}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6297745704650879}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.7732693552970886}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.6903716921806335}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.6348007321357727}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.5900612473487854}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.5513777136802673}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.5183653831481934}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.4889979958534241}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.46586671471595764}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.4446115791797638}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.42440712451934814}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.4066767394542694}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.3880341053009033}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.3737318813800812}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.3617187440395355}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.3443203270435333}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.334516704082489}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.3203775882720947}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.3131150007247925}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.3013501763343811}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.29117119312286377}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.28399497270584106}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.2756243050098419}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.2654862403869629}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.25874918699264526}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.2547459304332733}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.24576294422149658}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.2404911071062088}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.23348434269428253}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.22781796753406525}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.22353395819664001}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.2159944474697113}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.21575915813446045}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.20740410685539246}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.20133371651172638}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.19747412204742432}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.19405949115753174}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.1918044239282608}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.18687735497951508}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.18020424246788025}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.17758312821388245}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.17424826323986053}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.17691688239574432}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.16882140934467316}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.16367122530937195}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.15953388810157776}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.1599525809288025}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.15592029690742493}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.15147417783737183}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.1471773236989975}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.14570802450180054}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7631786465644836}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7312570214271545}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7318146228790283}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7489087581634521}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7915475368499756}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.8376187086105347}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.8806960582733154}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.924832284450531}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.9675658345222473}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.0346465110778809}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.0686585903167725}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.1608014106750488}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.2017160654067993}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.2258626222610474}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.2872837781906128}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.2711843252182007}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.3857307434082031}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.3866229057312012}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.4193519353866577}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.4403952360153198}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.530429482460022}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.60176420211792}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.619516372680664}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.7320581674575806}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.6809121370315552}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.6998151540756226}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.849292516708374}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.8848122358322144}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.9532544612884521}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.9772025346755981}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.0515286922454834}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.9706887006759644}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.052626609802246}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.106551170349121}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.1055047512054443}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.315664529800415}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.134129285812378}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.309217691421509}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.307950735092163}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.449620008468628}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.325131893157959}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.361859083175659}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.4225668907165527}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.4405572414398193}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.521771192550659}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.449829339981079}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.4802112579345703}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.610189914703369}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.670701742172241}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.637937068939209}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "nodes_per_layer = 64  # Adjust as needed\n",
    "layers_list = [1, 2, 3, 4]\n",
    "\n",
    "print(\"\\nTesting Constant Nodes per Layer:\")\n",
    "df_all_models = pd.DataFrame()\n",
    "\n",
    "for num_layers in layers_list:\n",
    "    print(f\"\\nTraining model with {num_layers} layers of {nodes_per_layer} nodes each\")\n",
    "    model = build_model(num_layers, nodes_per_layer)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': range(1, 51),\n",
    "        'training_accuracy': history.history['accuracy'],\n",
    "        'validation_accuracy': history.history['val_accuracy'],\n",
    "        'training_loss': history.history['loss'],\n",
    "        'validation_loss': history.history['val_loss'],\n",
    "        'num_layers': [num_layers] * 50\n",
    "    })\n",
    "    \n",
    "    # Melt the dataframe for long format\n",
    "    df_long = df.melt(id_vars=['epoch', 'num_layers'], \n",
    "                      value_vars=['training_accuracy', 'validation_accuracy', 'training_loss', 'validation_loss'],\n",
    "                      var_name='metric', value_name='value')\n",
    "    \n",
    "    # Concatenate all data\n",
    "    df_all_models = pd.concat([df_all_models, df_long], ignore_index=True)\n",
    "\n",
    "# Define the color mapping for metrics\n",
    "color_mapping = {\n",
    "    'training_accuracy': 'Training Accuracy',\n",
    "    'validation_accuracy': 'Validation Accuracy',\n",
    "    'training_loss': 'Training Loss',\n",
    "    'validation_loss': 'Validation Loss'\n",
    "}\n",
    "\n",
    "df_all_models['metric'] = df_all_models['metric'].map(color_mapping)\n",
    "\n",
    "# Altair plot: Interactive plot for all models\n",
    "chart = alt.Chart(df_all_models).mark_line().encode(\n",
    "    x='epoch',\n",
    "    y='value',\n",
    "    color='metric',\n",
    "    column='num_layers:O',  # Separate charts for each layer configuration\n",
    "    tooltip=['epoch', 'value', 'metric', 'num_layers']\n",
    ").properties(\n",
    "    title=\"Model Performance: Accuracy & Loss for Different Layer Configurations\",\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "chart.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to see the scenario of decreasing nodes per layer that forms a Pyramid Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Pyramid Structure:\n",
      "\n",
      "Training model with layers: [128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with layers: [128, 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 23\u001b[0m\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     29\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Plot the results\u001b[39;00m\n\u001b[1;32m     32\u001b[0m epochs_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m51\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layers_list = [1, 2, 3, 4]\n",
    "\n",
    "print(\"Testing Pyramid Structure:\")\n",
    "df_all_models\n",
    "    nodes = [128 // (2 ** i) for i in range(num_layers)]  # Decrease nodes per layer\n",
    "    print(f\"\\nTraining model with layers: {nodes}\")\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(462,)))\n",
    "    for n in nodes:\n",
    "        model.add(Dense(n, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # Compile, train, and plot as before\n",
    "    # ...\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Plot the results\n",
    "    epochs_range = range(1, 51)\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(epochs_range, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Époques')\n",
    "    plt.ylabel('Précision')\n",
    "    plt.title(f'Précision du Modèle avec {num_layers} Couches Cachées')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, history.history['loss'], label='Training Loss')\n",
    "    plt.plot(epochs_range, history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Époques')\n",
    "    plt.ylabel('Perte')\n",
    "    plt.title(f'Perte du Modèle avec {num_layers} Couches Cachées')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a complex model that overfits\n",
    "model_overfit = Sequential([\n",
    "    InputLayer(input_shape=(462,)),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_overfit.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_overfit = model_overfit.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=80,  # Increased epochs to observe overfitting\n",
    "    batch_size=32,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "epochs_range = range(1, 81)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, history_overfit.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(epochs_range, history_overfit.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Époques')\n",
    "plt.ylabel('Précision')\n",
    "plt.title('Précision du Modèle Illustrant le Surapprentissage')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, history_overfit.history['loss'], label='Training Loss')\n",
    "plt.plot(epochs_range, history_overfit.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Époques')\n",
    "plt.ylabel('Perte')\n",
    "plt.title('Perte du Modèle Illustrant le Surapprentissage')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - **Activation function**.\n",
    "\n",
    "        - Present results for one of the configurations mentioned above by varying the activation function. Test at least `relu` (the default) and `sigmoid`. The choice of the specific model, including the number of layers and nodes, is at your discretion. Document your observations accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - **Regularization** in neural networks is a technique used to prevent overfitting.\n",
    "\n",
    "        - One technique involves adding a penalty to the loss function to discourage excessively complex models. Apply an `l2` penalty to some or all layers. Exercise caution, as overly aggressive penalties have been problematic in our experiments. Begin with the default `l2` value of 0.01, then reduce it to 0.001 and 1e-4. Select a specific model from the above experiments and present a case where you successfully reduced overfitting. Include a pair of graphs comparing results with and without regularization. Explain your rationale to conclude that overfitting has been reduced. Do not expect to completely eliminate overfitting. Again, this is a challenging dataset to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "l2_values = [0.01, 0.001, 1e-4]\n",
    "\n",
    "for l2_value in l2_values:\n",
    "    print(f\"\\nTraining model with L2 regularization (lambda={l2_value})\")\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=(462,)),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(l2_value)),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(l2_value)),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile, train, and plot as before\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Plot the results\n",
    "    epochs_range = range(1, 51)\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(epochs_range, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Époques')\n",
    "    plt.ylabel('Précision')\n",
    "    plt.title(f'Précision du Modèle avec {num_layers} Couches Cachées')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, history.history['loss'], label='Training Loss')\n",
    "    plt.plot(epochs_range, history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Époques')\n",
    "    plt.ylabel('Perte')\n",
    "    plt.title(f'Perte du Modèle avec {num_layers} Couches Cachées')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        - Dropout layers are a regularization technique in neural networks where a random subset of neurons is temporarily removed during training. This helps prevent overfitting by promoting redundancy and improving the network's ability to generalize to new data. Select a specific model from the above experiments where you have muliple layers and experiment adding one or of few dropout layers into your network. Experiment with two different rates, say 0.25 and 0.5. Document your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "dropout_rates = [0.25, 0.5]\n",
    "\n",
    "for rate in dropout_rates:\n",
    "    print(f\"\\nTraining model with dropout rate {rate}\")\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=(462,)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(rate),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(rate),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Now we Compile, train, and plot as before\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Plot the results\n",
    "    epochs_range = range(1, 51)\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(epochs_range, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Époques')\n",
    "    plt.ylabel('Précision')\n",
    "    plt.title(f'Précision du Modèle avec {num_layers} Couches Cachées')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, history.history['loss'], label='Training Loss')\n",
    "    plt.plot(epochs_range, history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Époques')\n",
    "    plt.ylabel('Perte')\n",
    "    plt.title(f'Perte du Modèle avec {num_layers} Couches Cachées')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        - Summarize your experiments with using a graphical representation such as Figure 6.15 [on this page](https://egallic.fr/Enseignement/ML/ECB/book/deep-learning.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        - Early stopping is a regularization technique in neural network training wherein the process is halted when validation set performance starts to decline, thus preventing overfitting by avoiding the learning of noise in the training data. From all the experiments conducted thus far, choose **one** configuration (the number of layers, number of nodes, activation function, L2 penalty, and dropout layers) that yielded the best performance. Use a graph of loss and accuracy to determine the optimal number of training iterations for this network. What is the optimal number of epochs for this network configuration and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the model with the best configuration\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(462,)),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(1e-4)),\n",
    "    Dropout(0.25),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(1e-4)),\n",
    "    Dropout(0.25),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "epochs_range = range(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(epochs_range, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Époques')\n",
    "plt.ylabel('Précision')\n",
    "plt.title('Précision du Modèle avec Arrêt Anticipé')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, history.history['loss'], label='Training Loss')\n",
    "plt.plot(epochs_range, history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Époques')\n",
    "plt.ylabel('Perte')\n",
    "plt.title('Perte du Modèle avec Arrêt Anticipé')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Le nombre optimal d'époques est {len(epochs_range)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "9. **Model Comparison**:\n",
    "\n",
    "    - Evaluate the baseline model on the test set, using the optimal parameter set identified through grid search. Additionally, apply your best-performing neural network configuration to the test set.\n",
    "\n",
    "    - Quantify the performance of the baseline model (best hyperparameter configuration) and your neural network (best configuration) using precision, recall, and F1-score as metrics. How do these two models compare to the dummy model?\n",
    "\n",
    "    - Provide recommendations on which model(s) to choose for this task and justify your choices based on the analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell\n",
    "# Evaluate the best Logistic Regression model on the test set\n",
    "best_log_reg = grid_search_lr.best_estimator_\n",
    "y_pred_log_reg = best_log_reg.predict(X_test)\n",
    "\n",
    "print(\"Performance du Modèle de Référence sur l'Ensemble de Test:\")\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "\n",
    "# Evaluate the best Neural Network model on the test set\n",
    "nn_eval_test = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nPerformance du Réseau de Neurones sur l'Ensemble de Test:\")\n",
    "print(f\"Loss: {nn_eval_test[0]:.4f}\")\n",
    "print(f\"Accuracy: {nn_eval_test[1]:.4f}\")\n",
    "\n",
    "# Predict using the neural network\n",
    "y_pred_nn = model.predict(X_test)\n",
    "y_pred_nn_classes = np.argmax(y_pred_nn, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_nn_classes))\n",
    "\n",
    "# Evaluate the Dummy Classifier on the test set\n",
    "y_pred_dummy = dummy_clf.predict(X_test)\n",
    "print(\"\\nPerformance du Modèle de Base sur l'Ensemble de Test:\")\n",
    "print(classification_report(y_test, y_pred_dummy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "A3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
