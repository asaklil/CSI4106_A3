{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CSI 4106 Introduction to Artificial Intelligence** <br/>\n",
    "*Assignment 3: Neural Networks*\n",
    "\n",
    "# Identification\n",
    "\n",
    "Name: Ismail Asaklil <br/>\n",
    "Student Number: 300243534\n",
    "\n",
    "\n",
    "## 1. Exploratory Analysis\n",
    "\n",
    "### Loading the dataset\n",
    "\n",
    "A custom dataset has been created for this assignment. It has been made available on a public GitHub repository:\n",
    "\n",
    "- [github.com/turcotte/csi4106-f24/tree/main/assignments-data/a3](https://github.com/turcotte/csi4106-f24/tree/main/assignments-data/a3)\n",
    "\n",
    "Access and read the dataset directly from this GitHub repository in your Jupyter notebook.\n",
    "\n",
    "You can use this code cell for you import statements and other initializations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>453</th>\n",
       "      <th>454</th>\n",
       "      <th>455</th>\n",
       "      <th>456</th>\n",
       "      <th>457</th>\n",
       "      <th>458</th>\n",
       "      <th>459</th>\n",
       "      <th>460</th>\n",
       "      <th>461</th>\n",
       "      <th>462</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.1685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.0674</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.1573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 463 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0       1       2       3       4       5       6       7       8    \\\n",
       "0    2  0.0000  0.0556  0.0000  0.0556  0.1111  0.0000  0.0556  0.0000   \n",
       "1    2  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "2    2  0.1905  0.0000  0.3333  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "3    2  0.0225  0.0000  0.0112  0.1348  0.0000  0.0112  0.1348  0.0112   \n",
       "4    2  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "\n",
       "      9    ...     453     454     455     456     457     458  459     460  \\\n",
       "0  0.0000  ...  0.1667  0.2222  0.0000  0.0000  0.1667  0.0000  0.0  0.0000   \n",
       "1  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0  0.0000   \n",
       "2  0.2857  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0  0.1905   \n",
       "3  0.1685  ...  0.0000  0.0787  0.0674  0.0112  0.0225  0.1573  0.0  0.0225   \n",
       "4  0.0000  ...  0.0000  0.0000  0.0000  0.6667  0.0000  0.0000  0.0  0.0000   \n",
       "\n",
       "     461  462  \n",
       "0  0.000  0.0  \n",
       "1  0.000  0.0  \n",
       "2  0.381  0.0  \n",
       "3  0.000  0.0  \n",
       "4  0.000  0.0  \n",
       "\n",
       "[5 rows x 463 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code cell\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url1 = \"https://raw.githubusercontent.com/turcotte/csi4106-f24/refs/heads/main/assignments-data/a3/cb513_train.csv\"\n",
    "url2 = \"https://raw.githubusercontent.com/turcotte/csi4106-f24/refs/heads/main/assignments-data/a3/cb513_valid.csv\"\n",
    "url3 = \"https://raw.githubusercontent.com/turcotte/csi4106-f24/refs/heads/main/assignments-data/a3/cb513_test.csv\"\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(url1, sep=\",\", header=None);\n",
    "df_valid = pd.read_csv(url2, sep=\",\", header=None);\n",
    "df_test = pd.read_csv(url3, sep=\",\", header=None);\n",
    "\n",
    "df_train.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing\n",
    "\n",
    "2. **Shuffling the Rows**:\n",
    "\n",
    "    - Since examples are generated by sliding a window across each protein sequence, most adjacent examples originate from the same protein and share 20 positions. To mitigate the potential negative impact on model training, the initial step involves shuffling the **rows** of the data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>453</th>\n",
       "      <th>454</th>\n",
       "      <th>455</th>\n",
       "      <th>456</th>\n",
       "      <th>457</th>\n",
       "      <th>458</th>\n",
       "      <th>459</th>\n",
       "      <th>460</th>\n",
       "      <th>461</th>\n",
       "      <th>462</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1765</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 463 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1       2    3       4       5       6    7    8    9    ...  453  \\\n",
       "0    0  0.0  0.0000  0.0  0.0000  0.0000  1.0000  0.0  0.0  0.0  ...  0.0   \n",
       "1    2  1.0  0.0000  0.0  0.0000  0.0000  0.0000  0.0  0.0  0.0  ...  0.0   \n",
       "2    0  0.0  0.0000  0.0  0.0625  0.0312  0.0000  0.0  0.0  0.0  ...  0.0   \n",
       "3    1  0.0  0.0588  0.0  0.0000  0.1765  0.0000  0.0  0.0  0.0  ...  0.0   \n",
       "4    2  0.0  0.0000  0.0  0.0000  0.0000  0.8571  0.0  0.0  0.0  ...  0.0   \n",
       "\n",
       "      454     455     456     457   458  459  460  461  462  \n",
       "0  0.0000  0.1429  0.0714  0.2857  0.00  0.0  0.0  0.0  0.0  \n",
       "1  0.0000  0.0000  0.0000  0.0000  0.00  0.0  0.0  0.0  0.0  \n",
       "2  0.0000  0.0000  0.0000  0.0000  0.75  0.0  0.0  0.0  0.0  \n",
       "3  0.0000  0.0588  0.0000  0.0000  0.00  0.0  0.0  0.0  0.0  \n",
       "4  0.1429  0.0000  0.1429  0.0000  0.00  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 463 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code cell\n",
    "# Shuffling the rows of the train dataset\n",
    "df_train=df_train.sample(frac=1).reset_index(drop=True)\n",
    "df_test=df_test.sample(frac=1).reset_index(drop=True)\n",
    "df_valid=df_valid.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Scaling of Numerical Features**:\n",
    "\n",
    "    - Since all 462 features are proportions represented as values between 0 and 1, scaling may not be necessary. In our evaluations, using [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) actually degraded model performance. Within your pipeline, compare the effects of not scaling the data versus applying [MinMaxScaler](https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html). In the interest of time, a single experiment will suffice. It is important to note that when scaling is applied, a uniform method should be used across all columns, given their homogeneous nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of scaling the features is to enhance the performance, and this is by making the features values into a specific range so that the ML algorithms converge. In this test, we will compare the nto scaling vs MinMaxScaler which consists of using the following formula:\n",
    "\n",
    "$$\n",
    "X_{\\text{scaled}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of the regular model:  0.7154198062432723\n",
      "the accuracy of the scaled model:  0.714881593110872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Let us first split the data into features and target for both the train and test datasets\n",
    "X_train = df_train.iloc[:, 1:]\n",
    "y_train = df_train.iloc[:, 0]\n",
    "\n",
    "X_test = df_test.iloc[:, 1:]\n",
    "y_test = df_test.iloc[:, 0]\n",
    "\n",
    "\n",
    "# Here is the scaled data\n",
    "scaler = MinMaxScaler(feature_range=(0, 0.5))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# get the performance \n",
    "def get_performance(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# here we use LogisticRegression as an example\n",
    "model = LogisticRegression()\n",
    "print(\"the accuracy of the regular model: \", get_performance(model, X_train, y_train, X_test, y_test))\n",
    "print(\"the accuracy of the scaled model: \", get_performance(model, X_train_scaled, y_train, X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i have chosen the random range $(0, 0.5)$ as an input for the MinMaxScaler. \n",
    "We can still notice that the performance is quite similar where the model trained on the original dfs scored an accuracy of $0.7154$, whereas the one trained on the scaled data scored an accuracy of $0.7148$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Isolating the Target and the Data**:\n",
    "\n",
    "    - In the CSV files, the target and data are combined. To prepare for our machine learning experiments, separate the training data $X$ and the target vector $y$ for each of the three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I solating the features and the target variable\n",
    "\n",
    "X_train = df_train.iloc[:,1:]\n",
    "y_train = df_train.iloc[:,0]\n",
    "\n",
    "X_valid = df_valid.iloc[:,1:]\n",
    "y_valid = df_valid.iloc[:,0]\n",
    "\n",
    "X_test = df_test.iloc[:,1:]\n",
    "y_test = df_test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development & Evaluation\n",
    "\n",
    "5. **Model Development**:\n",
    "\n",
    "    - **Dummy Model**: Implement a model utilizing the [DummyClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html). This model disregards the input data and predicts the majority class. Such model is sometimes called a straw man model.\n",
    "\n",
    "    - **Basline Model**: As a baseline model, select one of the previously studied machine learning algorithms: Decision Trees, K-Nearest Neighbors (KNN), or Logistic Regression. Use the default parameters provided by scikit-learn to train each model as a baseline. Why did you choose this particular classifier? Why do you think it should be appropriate for this specific task?\n",
    "\n",
    "    - **Neural Network Model**: Utilizing [Keras](https://keras.io) and [TensorFlow](https://www.tensorflow.org), construct a sequential model comprising an input layer, a hidden layer, and an output layer. The input layer should consist of 462 nodes, reflecting the 462 attributes of each example. The hidden layer should include 8 nodes and employ the default activation function. The output layer should contain three nodes, corresponding to the three classes: helix (0), sheet (1), and coil (2). Apply the softmax activation function to the output layer to ensure that the outputs are treated as probabilities, with their sum equaling 1 for each training example.\n",
    "\n",
    "    We therefore have three models: dummy, baseline, and neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the dummy classifier:  0.41065662002152853\n"
     ]
    }
   ],
   "source": [
    "#DummyClassifier \n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dummy_classifier = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_classifier.fit(X_train, y_train)\n",
    "y_pred = dummy_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the dummy classifier: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose Logistic Regression for the baseline model due to its simplicity and effectiveness for classification tasks. It is computationally efficient, easy to implement, and interpretable. Additionaly, it performs well with a large number of features and provides a good baseline for comparing more complex models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the logistic regression classifier:  0.7154198062432723\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the logistic regression classifier: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6251 - loss: 0.8342 - val_accuracy: 0.6788 - val_loss: 0.7498\n",
      "Epoch 2/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7204 - loss: 0.6669 - val_accuracy: 0.6990 - val_loss: 0.7088\n",
      "Epoch 3/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7723 - loss: 0.5624 - val_accuracy: 0.7052 - val_loss: 0.6992\n",
      "Epoch 4/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8297 - loss: 0.4372 - val_accuracy: 0.7012 - val_loss: 0.7580\n",
      "Epoch 5/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8872 - loss: 0.3136 - val_accuracy: 0.7000 - val_loss: 0.8426\n",
      "Epoch 6/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.2135 - val_accuracy: 0.6843 - val_loss: 0.9891\n",
      "Epoch 7/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9501 - loss: 0.1479 - val_accuracy: 0.6782 - val_loss: 1.2546\n",
      "Epoch 8/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9676 - loss: 0.1006 - val_accuracy: 0.6762 - val_loss: 1.4488\n",
      "Epoch 9/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9747 - loss: 0.0828 - val_accuracy: 0.6704 - val_loss: 1.5993\n",
      "Epoch 10/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9799 - loss: 0.0656 - val_accuracy: 0.6738 - val_loss: 1.7748\n",
      "Epoch 11/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9822 - loss: 0.0558 - val_accuracy: 0.6619 - val_loss: 1.9044\n",
      "Epoch 12/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9833 - loss: 0.0534 - val_accuracy: 0.6560 - val_loss: 1.8937\n",
      "Epoch 13/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9869 - loss: 0.0435 - val_accuracy: 0.6643 - val_loss: 2.1404\n",
      "Epoch 14/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9868 - loss: 0.0416 - val_accuracy: 0.6554 - val_loss: 2.2506\n",
      "Epoch 15/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9848 - loss: 0.0478 - val_accuracy: 0.6624 - val_loss: 2.2348\n",
      "Epoch 16/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9889 - loss: 0.0381 - val_accuracy: 0.6638 - val_loss: 2.3459\n",
      "Epoch 17/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9894 - loss: 0.0362 - val_accuracy: 0.6642 - val_loss: 2.4385\n",
      "Epoch 18/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9900 - loss: 0.0334 - val_accuracy: 0.6654 - val_loss: 2.6764\n",
      "Epoch 19/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9886 - loss: 0.0355 - val_accuracy: 0.6680 - val_loss: 2.5340\n",
      "Epoch 20/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9912 - loss: 0.0299 - val_accuracy: 0.6610 - val_loss: 2.6292\n",
      "Epoch 21/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9898 - loss: 0.0339 - val_accuracy: 0.6549 - val_loss: 2.7325\n",
      "Epoch 22/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9913 - loss: 0.0272 - val_accuracy: 0.6597 - val_loss: 2.8632\n",
      "Epoch 23/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9922 - loss: 0.0267 - val_accuracy: 0.6599 - val_loss: 2.9183\n",
      "Epoch 24/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9905 - loss: 0.0301 - val_accuracy: 0.6612 - val_loss: 2.9696\n",
      "Epoch 25/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9918 - loss: 0.0254 - val_accuracy: 0.6655 - val_loss: 2.9226\n",
      "Epoch 26/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0173 - val_accuracy: 0.6677 - val_loss: 3.0229\n",
      "Epoch 27/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9929 - loss: 0.0228 - val_accuracy: 0.6669 - val_loss: 3.2026\n",
      "Epoch 28/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9918 - loss: 0.0274 - val_accuracy: 0.6622 - val_loss: 3.0478\n",
      "Epoch 29/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 973us/step - accuracy: 0.9937 - loss: 0.0202 - val_accuracy: 0.6666 - val_loss: 3.1114\n",
      "Epoch 30/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 987us/step - accuracy: 0.9938 - loss: 0.0197 - val_accuracy: 0.6584 - val_loss: 3.1688\n",
      "Epoch 31/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9941 - loss: 0.0196 - val_accuracy: 0.6684 - val_loss: 3.2472\n",
      "Epoch 32/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9932 - loss: 0.0212 - val_accuracy: 0.6659 - val_loss: 3.4611\n",
      "Epoch 33/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9949 - loss: 0.0174 - val_accuracy: 0.6654 - val_loss: 3.1970\n",
      "Epoch 34/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0171 - val_accuracy: 0.6615 - val_loss: 3.4334\n",
      "Epoch 35/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9950 - loss: 0.0172 - val_accuracy: 0.6641 - val_loss: 3.4525\n",
      "Epoch 36/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9936 - loss: 0.0204 - val_accuracy: 0.6622 - val_loss: 3.3086\n",
      "Epoch 37/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0180 - val_accuracy: 0.6658 - val_loss: 3.6565\n",
      "Epoch 38/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0154 - val_accuracy: 0.6659 - val_loss: 3.4536\n",
      "Epoch 39/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9956 - loss: 0.0142 - val_accuracy: 0.6539 - val_loss: 3.7510\n",
      "Epoch 40/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9947 - loss: 0.0173 - val_accuracy: 0.6610 - val_loss: 3.5738\n",
      "Epoch 41/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9954 - loss: 0.0154 - val_accuracy: 0.6614 - val_loss: 3.6950\n",
      "Epoch 42/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 973us/step - accuracy: 0.9955 - loss: 0.0164 - val_accuracy: 0.6634 - val_loss: 3.6778\n",
      "Epoch 43/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0179 - val_accuracy: 0.6638 - val_loss: 3.7212\n",
      "Epoch 44/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9969 - loss: 0.0106 - val_accuracy: 0.6627 - val_loss: 3.7633\n",
      "Epoch 45/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 935us/step - accuracy: 0.9941 - loss: 0.0178 - val_accuracy: 0.6626 - val_loss: 3.7702\n",
      "Epoch 46/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 991us/step - accuracy: 0.9966 - loss: 0.0124 - val_accuracy: 0.6641 - val_loss: 3.6818\n",
      "Epoch 47/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 993us/step - accuracy: 0.9958 - loss: 0.0130 - val_accuracy: 0.6634 - val_loss: 3.7444\n",
      "Epoch 48/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 995us/step - accuracy: 0.9955 - loss: 0.0146 - val_accuracy: 0.6597 - val_loss: 3.9095\n",
      "Epoch 49/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 908us/step - accuracy: 0.9957 - loss: 0.0144 - val_accuracy: 0.6635 - val_loss: 3.8240\n",
      "Epoch 50/50\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 951us/step - accuracy: 0.9971 - loss: 0.0100 - val_accuracy: 0.6655 - val_loss: 3.9476\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.6876 - loss: 3.7995\n"
     ]
    }
   ],
   "source": [
    "#Neural Network model \n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# Addition of the layers inot our NN model \n",
    "model.add(Dense(462, input_dim=462, activation='relu')) \n",
    "model.add(Dense(8, activation='relu'))  \n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "#Compile the NN\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# here i have chosen 50 epochs and a batch size of 32 because i want to train the model for 50 iterations and i want to use 32 samples to update the model's weights at each iteration\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_valid, y_valid))\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Model Evaluation**:\n",
    "\n",
    "    - Employ cross-validation to assess the performance of the baseline model. Select a small number of folds to prevent excessive computational demands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performed cross validation and displayed the different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: {'fit_time': array([0.76588225, 1.30321693, 0.74043226, 1.04766273, 0.60076499]), 'score_time': array([0.01094389, 0.00666475, 0.00672293, 0.00649405, 0.00656605]), 'test_accuracy': array([0.68324899, 0.68502316, 0.6903414 , 0.68553783, 0.68502316]), 'test_precision': array([0.68324899, 0.68502316, 0.6903414 , 0.68553783, 0.68502316]), 'test_recall': array([0.68324899, 0.68502316, 0.6903414 , 0.68553783, 0.68502316]), 'test_f1_score': array([0.68324899, 0.68502316, 0.6903414 , 0.68553783, 0.68502316])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "\n",
    "# We are going to use the following metrics to evaluate the models\n",
    "metrics ={\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='micro'),\n",
    "    'recall': make_scorer(recall_score, average='micro'),\n",
    "    'f1_score': make_scorer(f1_score, average='micro')\n",
    "}\n",
    "\n",
    "#creating folds for the cross validation\n",
    "k_folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# we are calling the log_reg which is our baseline model we have used ealier\n",
    "# Here im using the cross_validate because i want to use multiple metrics to evaluate the model\n",
    "log_reg_score = cross_validate(log_reg, X_train, y_train, cv=k_folds, scoring=metrics) \n",
    "\n",
    "print(\"Logistic Regression:\", log_reg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice here that the format of the output is not really intuitive. Let us fix that by creating a function that will display in a better way the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold       Accuracy   Precision  Recall     F1-score  \n",
      "1          0.683      0.683      0.683      0.683     \n",
      "2          0.685      0.685      0.685      0.685     \n",
      "3          0.690      0.690      0.690      0.690     \n",
      "4          0.686      0.686      0.686      0.686     \n",
      "5          0.685      0.685      0.685      0.685     \n",
      "\n",
      "Mean values of the metrics\n",
      "Mean       0.686      0.686      0.686      0.686     \n"
     ]
    }
   ],
   "source": [
    "def display_metrics(scores):\n",
    "    # I m using a format print to create a table of the metrics\n",
    "    print(f\"{'Fold':<10} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-score':<10}\")\n",
    "    for i, (accuracy, precision, recall, f1) in enumerate(zip(scores['test_accuracy'], scores['test_precision'], scores['test_recall'], scores['test_f1_score'])):\n",
    "        print(f\"{i+1:<10} {accuracy:<10.3f} {precision:<10.3f} {recall:<10.3f} {f1:<10.3f}\")\n",
    "    print()\n",
    "    print(\"Mean values of the metrics\")\n",
    "    print(f\"{'Mean':<10} {np.mean(scores['test_accuracy']):<10.3f} {np.mean(scores['test_precision']):<10.3f} {np.mean(scores['test_recall']):<10.3f} {np.mean(scores['test_f1_score']):<10.3f}\")\n",
    "\n",
    "display_metrics(log_reg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Neural Network on the validation set:\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.6618 - loss: 4.0092\n",
      "Validation Loss: 3.9476\n",
      "Validation Accuracy: 0.6655\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the Neural Network model\n",
    "print(\"\\nEvaluating Neural Network on the validation set:\")\n",
    "nn_eval = model.evaluate(X_valid, y_valid)\n",
    "print(f\"Validation Loss: {nn_eval[0]:.4f}\")\n",
    "print(f\"Validation Accuracy: {nn_eval[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Hyperparameter Optimization\n",
    "\n",
    "7. **Baseline Model:**\n",
    "\n",
    "    - To ensure a fair comparison for our baseline model, we will examine how varying hyperparameter values affect its performance. This prevents the erroneous conclusion that neural networks inherently perform better, when in fact, appropriate hyperparameter tuning could enhance the baseline model's performance.\n",
    "\n",
    "    - Focus on the following relevant hyperparameters for each model:\n",
    "\n",
    "        - [DecisionTreeClassifier](https://scikit-learn.org/dev/modules/generated/sklearn.tree.DecisionTreeClassifier.html): `criterion` and `max_depth`.\n",
    "  \n",
    "        - [LogisticRegression](https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html): `penalty`, `max_iter`, and `tol`.\n",
    "  \n",
    "        - [KNeighborsClassifier](https://scikit-learn.org/dev/modules/generated/sklearn.neighbors.KNeighborsClassifier.html): `n_neighbors` and `weights`.\n",
    "\n",
    "    - Employ a grid search strategy or utilize scikit-learn's built-in methods [GridSearchCV](https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.GridSearchCV.html) to thoroughly evaluate all combinations of hyperparameter values. Cross-validation should be used to assess each combination.\n",
    "\n",
    "    - Quantify the performance of each hyperparameter configuration using precision, recall, and F1-score as metrics.\n",
    "\n",
    "    - Analyze the findings and offer insights into which hyperparameter configurations achieved optimal performance for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "15 fits failed out of a total of 75.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/numpy/ma/core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.6870699  0.68708705 0.6870699  0.68708705 0.6870699  0.68708705\n",
      "        nan 0.6870699  0.68708705        nan 0.6870699  0.68708705\n",
      "        nan 0.6870699  0.68708705]\n",
      "  warnings.warn(\n",
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.69584069 0.69563911 0.69584069 0.69563911 0.69584069 0.69563911\n",
      "        nan 0.69584069 0.69563911        nan 0.69584069 0.69563911\n",
      "        nan 0.69584069 0.69563911]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=LogisticRegression(random_state=42), n_jobs=-1,\n",
       "             param_grid=[{&#x27;max_iter&#x27;: [100, 200, 500], &#x27;penalty&#x27;: [&#x27;l2&#x27;, None],\n",
       "                          &#x27;tol&#x27;: [0.0001]},\n",
       "                         {&#x27;max_iter&#x27;: [100, 200, 500],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, None], &#x27;tol&#x27;: [0.0001]}],\n",
       "             refit=&#x27;f1_score&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: make_scorer(accuracy_score, response_method=&#x27;predict&#x27;),\n",
       "                      &#x27;f1_score&#x27;: make_scorer(f1_score, response_method=&#x27;predict&#x27;, average=micro),\n",
       "                      &#x27;precision&#x27;: make_scorer(precision_score, response_method=&#x27;predict&#x27;, average=micro),\n",
       "                      &#x27;recall&#x27;: make_scorer(recall_score, response_method=&#x27;predict&#x27;, average=micro)},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=LogisticRegression(random_state=42), n_jobs=-1,\n",
       "             param_grid=[{&#x27;max_iter&#x27;: [100, 200, 500], &#x27;penalty&#x27;: [&#x27;l2&#x27;, None],\n",
       "                          &#x27;tol&#x27;: [0.0001]},\n",
       "                         {&#x27;max_iter&#x27;: [100, 200, 500],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, None], &#x27;tol&#x27;: [0.0001]}],\n",
       "             refit=&#x27;f1_score&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: make_scorer(accuracy_score, response_method=&#x27;predict&#x27;),\n",
       "                      &#x27;f1_score&#x27;: make_scorer(f1_score, response_method=&#x27;predict&#x27;, average=micro),\n",
       "                      &#x27;precision&#x27;: make_scorer(precision_score, response_method=&#x27;predict&#x27;, average=micro),\n",
       "                      &#x27;recall&#x27;: make_scorer(recall_score, response_method=&#x27;predict&#x27;, average=micro)},\n",
       "             verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: LogisticRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(penalty=None, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(penalty=None, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=LogisticRegression(random_state=42), n_jobs=-1,\n",
       "             param_grid=[{'max_iter': [100, 200, 500], 'penalty': ['l2', None],\n",
       "                          'tol': [0.0001]},\n",
       "                         {'max_iter': [100, 200, 500],\n",
       "                          'penalty': ['l1', 'l2', None], 'tol': [0.0001]}],\n",
       "             refit='f1_score', return_train_score=True,\n",
       "             scoring={'accuracy': make_scorer(accuracy_score, response_method='predict'),\n",
       "                      'f1_score': make_scorer(f1_score, response_method='predict', average=micro),\n",
       "                      'precision': make_scorer(precision_score, response_method='predict', average=micro),\n",
       "                      'recall': make_scorer(recall_score, response_method='predict', average=micro)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code cell\n",
    "# Hyperparameter grid for Logistic Regression including default values\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "\n",
    "# We are going to use the following metrics to evaluate the models\n",
    "metrics ={\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='micro'),\n",
    "    'recall': make_scorer(recall_score, average='micro'),\n",
    "    'f1_score': make_scorer(f1_score, average='micro')\n",
    "}\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'penalty': ['l2', None],       # Default is 'l2'\n",
    "        'max_iter': [100, 200, 500],  # Default is 100\n",
    "        'tol': [1e-4]                  # Default is 1e-4\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['l1', 'l2', None], # 'l2' is default\n",
    "        'max_iter': [100, 200, 500],  # Default is 100\n",
    "        'tol': [1e-4]                  # Default is 1e-4\n",
    "    }\n",
    "]\n",
    "\n",
    "# Cross-validation strategy\n",
    "cv_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Grid Search with Cross-Validation\n",
    "grid_search_lr = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=parameters,\n",
    "    cv=cv_folds,\n",
    "    scoring=metrics, # i want to use multiple metrics to evaluate the model\n",
    "    refit='f1_score',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying the GirdSearch strategy, Let us visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_iter': 100, 'penalty': None, 'tol': 0.0001}\n",
      "Best F1 Score: 0.6870870529123977\n",
      "\n",
      "Statistics for Penalty: l1\n",
      "Tolerance (tol)      Max Iterations       Mean Precision       Mean Recall          Mean F1 Score       \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0.0001               100                  nan                  nan                  nan                 \n",
      "0.0001               200                  nan                  nan                  nan                 \n",
      "0.0001               500                  nan                  nan                  nan                 \n",
      "\n",
      "Statistics for Penalty: l2\n",
      "Tolerance (tol)      Max Iterations       Mean Precision       Mean Recall          Mean F1 Score       \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0.0001               100                  0.687                0.687                0.687               \n",
      "0.0001               200                  0.687                0.687                0.687               \n",
      "0.0001               500                  0.687                0.687                0.687               \n",
      "0.0001               100                  0.687                0.687                0.687               \n",
      "0.0001               200                  0.687                0.687                0.687               \n",
      "0.0001               500                  0.687                0.687                0.687               \n",
      "\n",
      "Statistics for Penalty: none\n",
      "Tolerance (tol)      Max Iterations       Mean Precision       Mean Recall          Mean F1 Score       \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0.0001               100                  0.687                0.687                0.687               \n",
      "0.0001               200                  0.687                0.687                0.687               \n",
      "0.0001               500                  0.687                0.687                0.687               \n",
      "0.0001               100                  0.687                0.687                0.687               \n",
      "0.0001               200                  0.687                0.687                0.687               \n",
      "0.0001               500                  0.687                0.687                0.687               \n"
     ]
    }
   ],
   "source": [
    "def display_best_params(grid_search_lr):\n",
    "    \"\"\"Display the best parameters and F1 score from grid search.\"\"\"\n",
    "    print(\"Best Parameters:\", grid_search_lr.best_params_)\n",
    "    print(\"Best F1 Score:\", grid_search_lr.best_score_)\n",
    "\n",
    "def process_results(grid_search_lr):\n",
    "    \"\"\"Convert cv_results_ to a DataFrame, process and sort it.\"\"\"\n",
    "    results_df = pd.DataFrame(grid_search_lr.cv_results_)\n",
    "    results_df['param_penalty'] = results_df['param_penalty'].apply(lambda x: 'none' if x is None else x)\n",
    "    return results_df.sort_values(by='mean_test_f1_score', ascending=False)\n",
    "\n",
    "def print_grouped_results(results_df):\n",
    "    \"\"\"Group results by penalty and print detailed statistics.\"\"\"\n",
    "    for penalty, group in results_df.groupby('param_penalty'):\n",
    "        print(f\"\\nStatistics for Penalty: {penalty}\")\n",
    "        print(f\"{'Tolerance (tol)':<20} {'Max Iterations':<20} {'Mean Precision':<20} \"\n",
    "              f\"{'Mean Recall':<20} {'Mean F1 Score':<20}\")\n",
    "        print(\"-\" * 100)\n",
    "\n",
    "        # Sort by F1 score in descending order and print each row\n",
    "        for _, row in group.sort_values(by='mean_test_f1_score', ascending=False).iterrows():\n",
    "            print(f\"{row['param_tol']:<20.4f} {row['param_max_iter']:<20} \"\n",
    "                  f\"{row['mean_test_precision']:<20.3f} {row['mean_test_recall']:<20.3f} \"\n",
    "                  f\"{row['mean_test_f1_score']:<20.3f}\")\n",
    "\n",
    "# Execute the functions\n",
    "display_best_params(grid_search_lr)\n",
    "sorted_results_df = process_results(grid_search_lr)\n",
    "print_grouped_results(sorted_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **Neural Network:**\n",
    "\n",
    "    In our exploration and tuning of neural networks, we focus on the following hyperparameters:\n",
    "\n",
    "    - **Single hidden layer, varying the number of nodes**. \n",
    "\n",
    "        - Start with a single node in the hidden layer. Use a graph to depict the progression of loss and accuracy for both the training and validation sets, with the horizontal axis representing the number of training epochs and the vertical axis showing loss and accuracy. Training this network should be relatively fast, so let's conduct training for 50 epochs. Observing the graph, what do you conclude? Is the network underfitting or overfitting? Why?\n",
    "\n",
    "        - Repeat the above process using 2 and 4 nodes in the hidden layer. Use the same type of graph to document your observations regarding loss and accuracy.\n",
    "\n",
    "        - Start with 8 nodes in the hidden layer and progressively double the number of nodes until it surpasses the number of nodes in the input layer. This results in seven experiments and corresponding graphs for the following configurations: 8, 16, 32, 64, 128, 256, and 512 nodes. Document your observations throughout the process.\n",
    "        \n",
    "        - Ensure that the **number of training epochs** is adequate for **observing an increase in validation loss**. **Tip**: During model development, start with a small number of epochs, such as 5 or 10. Once the model appears to perform well, test with larger values, like 40 or 80 epochs, which proved reasonable in our tests. Based on your observations, consider conducting further experiments, if needed. How many epochs were ultimately necessary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-cba63a1b18184b25b78be097bedb767f.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-cba63a1b18184b25b78be097bedb767f.vega-embed details,\n",
       "  #altair-viz-cba63a1b18184b25b78be097bedb767f.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-cba63a1b18184b25b78be097bedb767f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-cba63a1b18184b25b78be097bedb767f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-cba63a1b18184b25b78be097bedb767f\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"vconcat\": [{\"hconcat\": [{\"data\": {\"name\": \"data-512da7e12224bb3df4c125d08a8ab69d\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"title\": \"Accuracy for Model with 1 Hidden Nodes\"}, {\"data\": {\"name\": \"data-bad50f56ba6f3e77188be7536ba40c5b\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"title\": \"Loss for Model with 1 Hidden Nodes\"}]}, {\"hconcat\": [{\"data\": {\"name\": \"data-9eb881871a18a2854d881f4acd5b20d2\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"title\": \"Accuracy for Model with 2 Hidden Nodes\"}, {\"data\": {\"name\": \"data-9e4382908b2a85197c0ebe89f7e84b7b\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"title\": \"Loss for Model with 2 Hidden Nodes\"}]}, {\"hconcat\": [{\"data\": {\"name\": \"data-cf5a63b43f1ddd8148494490a58cf102\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"title\": \"Accuracy for Model with 4 Hidden Nodes\"}, {\"data\": {\"name\": \"data-92a9c22654acbfc016c002033234566e\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"title\": \"Loss for Model with 4 Hidden Nodes\"}]}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-512da7e12224bb3df4c125d08a8ab69d\": [{\"epoch\": 1, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.5683553218841553}, {\"epoch\": 2, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6110891699790955}, {\"epoch\": 3, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6163901686668396}, {\"epoch\": 4, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6185688972473145}, {\"epoch\": 5, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6195467710494995}, {\"epoch\": 6, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6198898553848267}, {\"epoch\": 7, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6203873753547668}, {\"epoch\": 8, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6206446886062622}, {\"epoch\": 9, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6204559803009033}, {\"epoch\": 10, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6205417513847351}, {\"epoch\": 11, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.620438814163208}, {\"epoch\": 12, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6204045414924622}, {\"epoch\": 13, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6203358769416809}, {\"epoch\": 14, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6204216480255127}, {\"epoch\": 15, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6202672719955444}, {\"epoch\": 16, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6200957298278809}, {\"epoch\": 17, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6200785636901855}, {\"epoch\": 18, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199756264686584}, {\"epoch\": 19, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199584603309631}, {\"epoch\": 20, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199756264686584}, {\"epoch\": 21, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6198384165763855}, {\"epoch\": 22, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199241876602173}, {\"epoch\": 23, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199927926063538}, {\"epoch\": 24, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199584603309631}, {\"epoch\": 25, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199413537979126}, {\"epoch\": 26, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199756264686584}, {\"epoch\": 27, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6200099587440491}, {\"epoch\": 28, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199756264686584}, {\"epoch\": 29, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199756264686584}, {\"epoch\": 30, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199584603309631}, {\"epoch\": 31, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6200099587440491}, {\"epoch\": 32, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199413537979126}, {\"epoch\": 33, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6198898553848267}, {\"epoch\": 34, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6198212504386902}, {\"epoch\": 35, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.619907021522522}, {\"epoch\": 36, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.619907021522522}, {\"epoch\": 37, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199584603309631}, {\"epoch\": 38, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199584603309631}, {\"epoch\": 39, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199241876602173}, {\"epoch\": 40, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199413537979126}, {\"epoch\": 41, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199584603309631}, {\"epoch\": 42, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199927926063538}, {\"epoch\": 43, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199241876602173}, {\"epoch\": 44, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199241876602173}, {\"epoch\": 45, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199584603309631}, {\"epoch\": 46, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199927926063538}, {\"epoch\": 47, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199756264686584}, {\"epoch\": 48, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199756264686584}, {\"epoch\": 49, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6199927926063538}, {\"epoch\": 50, \"hidden_nodes\": 1, \"metric\": \"training_accuracy\", \"value\": 0.6200099587440491}, {\"epoch\": 1, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5855041146278381}, {\"epoch\": 2, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5952220559120178}, {\"epoch\": 3, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5983263850212097}, {\"epoch\": 4, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5984613299369812}, {\"epoch\": 5, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5985962748527527}, {\"epoch\": 6, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5975165367126465}, {\"epoch\": 7, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.598056435585022}, {\"epoch\": 8, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5979214310646057}, {\"epoch\": 9, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.598056435585022}, {\"epoch\": 10, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5979214310646057}, {\"epoch\": 11, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.597381591796875}, {\"epoch\": 12, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.596976637840271}, {\"epoch\": 13, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5972465872764587}, {\"epoch\": 14, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.598056435585022}, {\"epoch\": 15, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5981913805007935}, {\"epoch\": 16, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5981913805007935}, {\"epoch\": 17, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5979214310646057}, {\"epoch\": 18, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5977864861488342}, {\"epoch\": 19, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5981913805007935}, {\"epoch\": 20, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5985962748527527}, {\"epoch\": 21, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.598731279373169}, {\"epoch\": 22, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5981913805007935}, {\"epoch\": 23, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5983263850212097}, {\"epoch\": 24, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5983263850212097}, {\"epoch\": 25, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5983263850212097}, {\"epoch\": 26, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5984613299369812}, {\"epoch\": 27, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5983263850212097}, {\"epoch\": 28, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5983263850212097}, {\"epoch\": 29, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5983263850212097}, {\"epoch\": 30, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5984613299369812}, {\"epoch\": 31, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5985962748527527}, {\"epoch\": 32, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5983263850212097}, {\"epoch\": 33, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5984613299369812}, {\"epoch\": 34, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5984613299369812}, {\"epoch\": 35, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5985962748527527}, {\"epoch\": 36, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.598731279373169}, {\"epoch\": 37, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.598731279373169}, {\"epoch\": 38, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.598731279373169}, {\"epoch\": 39, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.598731279373169}, {\"epoch\": 40, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5988662242889404}, {\"epoch\": 41, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5984613299369812}, {\"epoch\": 42, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5985962748527527}, {\"epoch\": 43, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5988662242889404}, {\"epoch\": 44, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5988662242889404}, {\"epoch\": 45, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5985962748527527}, {\"epoch\": 46, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5985962748527527}, {\"epoch\": 47, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5985962748527527}, {\"epoch\": 48, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5984613299369812}, {\"epoch\": 49, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5984613299369812}, {\"epoch\": 50, \"hidden_nodes\": 1, \"metric\": \"validation_accuracy\", \"value\": 0.5984613299369812}], \"data-bad50f56ba6f3e77188be7536ba40c5b\": [{\"epoch\": 1, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.9605001211166382}, {\"epoch\": 2, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8880153894424438}, {\"epoch\": 3, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.875414252281189}, {\"epoch\": 4, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8697443008422852}, {\"epoch\": 5, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8667512536048889}, {\"epoch\": 6, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8651134371757507}, {\"epoch\": 7, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8641446828842163}, {\"epoch\": 8, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8635109663009644}, {\"epoch\": 9, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8631041646003723}, {\"epoch\": 10, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8628272414207458}, {\"epoch\": 11, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8626434206962585}, {\"epoch\": 12, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8624980449676514}, {\"epoch\": 13, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8623839020729065}, {\"epoch\": 14, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8622912168502808}, {\"epoch\": 15, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8622092008590698}, {\"epoch\": 16, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8621426820755005}, {\"epoch\": 17, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8620782494544983}, {\"epoch\": 18, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8620216250419617}, {\"epoch\": 19, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8619681596755981}, {\"epoch\": 20, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8619182705879211}, {\"epoch\": 21, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8618718981742859}, {\"epoch\": 22, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8618258237838745}, {\"epoch\": 23, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8617817759513855}, {\"epoch\": 24, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8617404103279114}, {\"epoch\": 25, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8617031574249268}, {\"epoch\": 26, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8616604804992676}, {\"epoch\": 27, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8616223931312561}, {\"epoch\": 28, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8615890145301819}, {\"epoch\": 29, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8615538477897644}, {\"epoch\": 30, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8615196943283081}, {\"epoch\": 31, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8614816069602966}, {\"epoch\": 32, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8614475727081299}, {\"epoch\": 33, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8614148497581482}, {\"epoch\": 34, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8613839149475098}, {\"epoch\": 35, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8613525629043579}, {\"epoch\": 36, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8613240718841553}, {\"epoch\": 37, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8612953424453735}, {\"epoch\": 38, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8612675070762634}, {\"epoch\": 39, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8612401485443115}, {\"epoch\": 40, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8612074851989746}, {\"epoch\": 41, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8611827492713928}, {\"epoch\": 42, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8611570000648499}, {\"epoch\": 43, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8611310124397278}, {\"epoch\": 44, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8611061573028564}, {\"epoch\": 45, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8610823154449463}, {\"epoch\": 46, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8610565066337585}, {\"epoch\": 47, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8610320687294006}, {\"epoch\": 48, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8610080480575562}, {\"epoch\": 49, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8609845042228699}, {\"epoch\": 50, \"hidden_nodes\": 1, \"metric\": \"training_loss\", \"value\": 0.8609626293182373}, {\"epoch\": 1, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.9235734343528748}, {\"epoch\": 2, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.9047434329986572}, {\"epoch\": 3, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8982570171356201}, {\"epoch\": 4, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8951236605644226}, {\"epoch\": 5, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8932976126670837}, {\"epoch\": 6, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8921393156051636}, {\"epoch\": 7, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8915533423423767}, {\"epoch\": 8, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8911345601081848}, {\"epoch\": 9, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8908498883247375}, {\"epoch\": 10, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8906134963035583}, {\"epoch\": 11, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8904777765274048}, {\"epoch\": 12, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8903735280036926}, {\"epoch\": 13, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8902924656867981}, {\"epoch\": 14, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8902073502540588}, {\"epoch\": 15, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8901205658912659}, {\"epoch\": 16, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8900460600852966}, {\"epoch\": 17, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8899853825569153}, {\"epoch\": 18, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8899223208427429}, {\"epoch\": 19, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8898828029632568}, {\"epoch\": 20, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8898621201515198}, {\"epoch\": 21, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8898112773895264}, {\"epoch\": 22, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.889772891998291}, {\"epoch\": 23, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8897491097450256}, {\"epoch\": 24, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8897230625152588}, {\"epoch\": 25, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8897002339363098}, {\"epoch\": 26, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8896754384040833}, {\"epoch\": 27, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8896281123161316}, {\"epoch\": 28, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8896005749702454}, {\"epoch\": 29, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8895674347877502}, {\"epoch\": 30, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8895465731620789}, {\"epoch\": 31, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8895355463027954}, {\"epoch\": 32, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8895087838172913}, {\"epoch\": 33, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8895012140274048}, {\"epoch\": 34, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8894867897033691}, {\"epoch\": 35, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8894820809364319}, {\"epoch\": 36, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8894728422164917}, {\"epoch\": 37, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8894601464271545}, {\"epoch\": 38, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8894487023353577}, {\"epoch\": 39, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8894369006156921}, {\"epoch\": 40, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8894280791282654}, {\"epoch\": 41, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8893872499465942}, {\"epoch\": 42, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8893841505050659}, {\"epoch\": 43, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8893735408782959}, {\"epoch\": 44, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8893609642982483}, {\"epoch\": 45, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8893520832061768}, {\"epoch\": 46, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8893402814865112}, {\"epoch\": 47, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8893308043479919}, {\"epoch\": 48, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8893185257911682}, {\"epoch\": 49, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8893091082572937}, {\"epoch\": 50, \"hidden_nodes\": 1, \"metric\": \"validation_loss\", \"value\": 0.8893011808395386}], \"data-9eb881871a18a2854d881f4acd5b20d2\": [{\"epoch\": 1, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.557461678981781}, {\"epoch\": 2, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6721963882446289}, {\"epoch\": 3, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.688614010810852}, {\"epoch\": 4, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6901065111160278}, {\"epoch\": 5, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.690655529499054}, {\"epoch\": 6, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6912730932235718}, {\"epoch\": 7, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6918735504150391}, {\"epoch\": 8, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6919935941696167}, {\"epoch\": 9, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6919249892234802}, {\"epoch\": 10, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6923367381095886}, {\"epoch\": 11, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6923195719718933}, {\"epoch\": 12, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.692010760307312}, {\"epoch\": 13, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6920279264450073}, {\"epoch\": 14, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6921823024749756}, {\"epoch\": 15, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6922166347503662}, {\"epoch\": 16, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6922166347503662}, {\"epoch\": 17, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6923195719718933}, {\"epoch\": 18, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6924396753311157}, {\"epoch\": 19, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6925426125526428}, {\"epoch\": 20, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6924396753311157}, {\"epoch\": 21, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6924225091934204}, {\"epoch\": 22, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6923881769180298}, {\"epoch\": 23, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6925254464149475}, {\"epoch\": 24, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6926798224449158}, {\"epoch\": 25, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6924911141395569}, {\"epoch\": 26, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6926626563072205}, {\"epoch\": 27, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6927655935287476}, {\"epoch\": 28, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6927655935287476}, {\"epoch\": 29, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6927655935287476}, {\"epoch\": 30, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6928170919418335}, {\"epoch\": 31, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6929028630256653}, {\"epoch\": 32, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6929714679718018}, {\"epoch\": 33, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6929543018341064}, {\"epoch\": 34, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6929714679718018}, {\"epoch\": 35, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6930229663848877}, {\"epoch\": 36, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.69312584400177}, {\"epoch\": 37, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6930572390556335}, {\"epoch\": 38, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6930915713310242}, {\"epoch\": 39, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6932116746902466}, {\"epoch\": 40, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.693177342414856}, {\"epoch\": 41, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6931945085525513}, {\"epoch\": 42, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6931945085525513}, {\"epoch\": 43, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6933145523071289}, {\"epoch\": 44, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6933832168579102}, {\"epoch\": 45, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6935204267501831}, {\"epoch\": 46, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6935375928878784}, {\"epoch\": 47, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6936405301094055}, {\"epoch\": 48, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6935890913009644}, {\"epoch\": 49, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6934689879417419}, {\"epoch\": 50, \"hidden_nodes\": 2, \"metric\": \"training_accuracy\", \"value\": 0.6935204267501831}, {\"epoch\": 1, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6095289587974548}, {\"epoch\": 2, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6666216850280762}, {\"epoch\": 3, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6705358624458313}, {\"epoch\": 4, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6732352375984192}, {\"epoch\": 5, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6725603938102722}, {\"epoch\": 6, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6725603938102722}, {\"epoch\": 7, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.67283034324646}, {\"epoch\": 8, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6725603938102722}, {\"epoch\": 9, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6724254488945007}, {\"epoch\": 10, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6722904443740845}, {\"epoch\": 11, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6724254488945007}, {\"epoch\": 12, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6724254488945007}, {\"epoch\": 13, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6725603938102722}, {\"epoch\": 14, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6733702421188354}, {\"epoch\": 15, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6737751364707947}, {\"epoch\": 16, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6737751364707947}, {\"epoch\": 17, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6740450859069824}, {\"epoch\": 18, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6740450859069824}, {\"epoch\": 19, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6744499802589417}, {\"epoch\": 20, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6745849847793579}, {\"epoch\": 21, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6744499802589417}, {\"epoch\": 22, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6741800308227539}, {\"epoch\": 23, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6745849847793579}, {\"epoch\": 24, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6745849847793579}, {\"epoch\": 25, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6743150353431702}, {\"epoch\": 26, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6743150353431702}, {\"epoch\": 27, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6747199296951294}, {\"epoch\": 28, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6745849847793579}, {\"epoch\": 29, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6743150353431702}, {\"epoch\": 30, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6741800308227539}, {\"epoch\": 31, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6741800308227539}, {\"epoch\": 32, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6737751364707947}, {\"epoch\": 33, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6739100813865662}, {\"epoch\": 34, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6741800308227539}, {\"epoch\": 35, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6739100813865662}, {\"epoch\": 36, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6739100813865662}, {\"epoch\": 37, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6744499802589417}, {\"epoch\": 38, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6743150353431702}, {\"epoch\": 39, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6744499802589417}, {\"epoch\": 40, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6748549342155457}, {\"epoch\": 41, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6743150353431702}, {\"epoch\": 42, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6743150353431702}, {\"epoch\": 43, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6741800308227539}, {\"epoch\": 44, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6740450859069824}, {\"epoch\": 45, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6744499802589417}, {\"epoch\": 46, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6744499802589417}, {\"epoch\": 47, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6748549342155457}, {\"epoch\": 48, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6752598285675049}, {\"epoch\": 49, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6749898791313171}, {\"epoch\": 50, \"hidden_nodes\": 2, \"metric\": \"validation_accuracy\", \"value\": 0.6749898791313171}], \"data-9e4382908b2a85197c0ebe89f7e84b7b\": [{\"epoch\": 1, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.9260280728340149}, {\"epoch\": 2, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7765273451805115}, {\"epoch\": 3, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7467629909515381}, {\"epoch\": 4, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7409886121749878}, {\"epoch\": 5, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7389931678771973}, {\"epoch\": 6, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7380158305168152}, {\"epoch\": 7, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7374207973480225}, {\"epoch\": 8, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7369738817214966}, {\"epoch\": 9, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7366341352462769}, {\"epoch\": 10, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7363494038581848}, {\"epoch\": 11, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7360953688621521}, {\"epoch\": 12, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7358853220939636}, {\"epoch\": 13, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7357012033462524}, {\"epoch\": 14, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7355217337608337}, {\"epoch\": 15, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.735365092754364}, {\"epoch\": 16, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7352099418640137}, {\"epoch\": 17, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7350684404373169}, {\"epoch\": 18, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7349245548248291}, {\"epoch\": 19, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7348051071166992}, {\"epoch\": 20, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7346931099891663}, {\"epoch\": 21, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7345967888832092}, {\"epoch\": 22, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7344930768013}, {\"epoch\": 23, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7343999147415161}, {\"epoch\": 24, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7343074083328247}, {\"epoch\": 25, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7342181205749512}, {\"epoch\": 26, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7341335415840149}, {\"epoch\": 27, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.73404860496521}, {\"epoch\": 28, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.733972430229187}, {\"epoch\": 29, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7338965535163879}, {\"epoch\": 30, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7338252067565918}, {\"epoch\": 31, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7337618470191956}, {\"epoch\": 32, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7336955666542053}, {\"epoch\": 33, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7336312532424927}, {\"epoch\": 34, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7335721254348755}, {\"epoch\": 35, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7335125207901001}, {\"epoch\": 36, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7334485054016113}, {\"epoch\": 37, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7333818078041077}, {\"epoch\": 38, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.733330488204956}, {\"epoch\": 39, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7332761883735657}, {\"epoch\": 40, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7332240343093872}, {\"epoch\": 41, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7331739068031311}, {\"epoch\": 42, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7331267595291138}, {\"epoch\": 43, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.733077347278595}, {\"epoch\": 44, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7330336570739746}, {\"epoch\": 45, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7329881191253662}, {\"epoch\": 46, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.732944905757904}, {\"epoch\": 47, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7329028844833374}, {\"epoch\": 48, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7328584790229797}, {\"epoch\": 49, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7328223586082458}, {\"epoch\": 50, \"hidden_nodes\": 2, \"metric\": \"training_loss\", \"value\": 0.7327840328216553}, {\"epoch\": 1, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.8482965230941772}, {\"epoch\": 2, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7833467721939087}, {\"epoch\": 3, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7744157314300537}, {\"epoch\": 4, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.77166348695755}, {\"epoch\": 5, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7705215811729431}, {\"epoch\": 6, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7698395848274231}, {\"epoch\": 7, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7692118883132935}, {\"epoch\": 8, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7687511444091797}, {\"epoch\": 9, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7684001922607422}, {\"epoch\": 10, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7680248618125916}, {\"epoch\": 11, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7678045630455017}, {\"epoch\": 12, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7676099538803101}, {\"epoch\": 13, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7674049139022827}, {\"epoch\": 14, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7672367691993713}, {\"epoch\": 15, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7670905590057373}, {\"epoch\": 16, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.767001748085022}, {\"epoch\": 17, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7668238282203674}, {\"epoch\": 18, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.766766369342804}, {\"epoch\": 19, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7667034268379211}, {\"epoch\": 20, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7666221261024475}, {\"epoch\": 21, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.766627311706543}, {\"epoch\": 22, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7665430307388306}, {\"epoch\": 23, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7664838433265686}, {\"epoch\": 24, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7664621472358704}, {\"epoch\": 25, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7664473652839661}, {\"epoch\": 26, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7664195895195007}, {\"epoch\": 27, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.76642245054245}, {\"epoch\": 28, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.766430139541626}, {\"epoch\": 29, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7664162516593933}, {\"epoch\": 30, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.76639324426651}, {\"epoch\": 31, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7663506269454956}, {\"epoch\": 32, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7663319110870361}, {\"epoch\": 33, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7663506269454956}, {\"epoch\": 34, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7663468718528748}, {\"epoch\": 35, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7664150595664978}, {\"epoch\": 36, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.766416072845459}, {\"epoch\": 37, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7664262056350708}, {\"epoch\": 38, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7664355635643005}, {\"epoch\": 39, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.766463041305542}, {\"epoch\": 40, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7664560079574585}, {\"epoch\": 41, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7664685845375061}, {\"epoch\": 42, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7664639949798584}, {\"epoch\": 43, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7664536237716675}, {\"epoch\": 44, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7664588093757629}, {\"epoch\": 45, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7664594650268555}, {\"epoch\": 46, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7664480209350586}, {\"epoch\": 47, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7665578722953796}, {\"epoch\": 48, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7665508985519409}, {\"epoch\": 49, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7665336728096008}, {\"epoch\": 50, \"hidden_nodes\": 2, \"metric\": \"validation_loss\", \"value\": 0.7665307521820068}], \"data-cf5a63b43f1ddd8148494490a58cf102\": [{\"epoch\": 1, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6108661890029907}, {\"epoch\": 2, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.688905656337738}, {\"epoch\": 3, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6927141547203064}, {\"epoch\": 4, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6955276131629944}, {\"epoch\": 5, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6978607177734375}, {\"epoch\": 6, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.6988557577133179}, {\"epoch\": 7, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7000566124916077}, {\"epoch\": 8, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7014633417129517}, {\"epoch\": 9, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7013775706291199}, {\"epoch\": 10, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7015319466590881}, {\"epoch\": 11, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7012060284614563}, {\"epoch\": 12, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.701480507850647}, {\"epoch\": 13, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7022010087966919}, {\"epoch\": 14, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7025269865989685}, {\"epoch\": 15, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7031445503234863}, {\"epoch\": 16, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7031617164611816}, {\"epoch\": 17, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7029215693473816}, {\"epoch\": 18, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7028529047966003}, {\"epoch\": 19, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7029730081558228}, {\"epoch\": 20, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7035562992095947}, {\"epoch\": 21, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7035562992095947}, {\"epoch\": 22, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.703710675239563}, {\"epoch\": 23, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7036077380180359}, {\"epoch\": 24, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7038993835449219}, {\"epoch\": 25, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7042425274848938}, {\"epoch\": 26, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7041224241256714}, {\"epoch\": 27, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7043625712394714}, {\"epoch\": 28, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.704156756401062}, {\"epoch\": 29, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7044140696525574}, {\"epoch\": 30, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7044140696525574}, {\"epoch\": 31, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7040709257125854}, {\"epoch\": 32, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7043797373771667}, {\"epoch\": 33, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7047743201255798}, {\"epoch\": 34, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7050144672393799}, {\"epoch\": 35, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7052203416824341}, {\"epoch\": 36, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7050831317901611}, {\"epoch\": 37, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7050659656524658}, {\"epoch\": 38, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7051517367362976}, {\"epoch\": 39, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7050144672393799}, {\"epoch\": 40, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.705117404460907}, {\"epoch\": 41, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7053918838500977}, {\"epoch\": 42, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7055119872093201}, {\"epoch\": 43, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7054433822631836}, {\"epoch\": 44, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7056835293769836}, {\"epoch\": 45, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7055805921554565}, {\"epoch\": 46, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7056320905685425}, {\"epoch\": 47, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7055805921554565}, {\"epoch\": 48, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7056664228439331}, {\"epoch\": 49, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7053747773170471}, {\"epoch\": 50, \"hidden_nodes\": 4, \"metric\": \"training_accuracy\", \"value\": 0.7053918838500977}, {\"epoch\": 1, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6639222502708435}, {\"epoch\": 2, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6731002926826477}, {\"epoch\": 3, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6759346723556519}, {\"epoch\": 4, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6782291531562805}, {\"epoch\": 5, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6786341071128845}, {\"epoch\": 6, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6793089509010315}, {\"epoch\": 7, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6795789003372192}, {\"epoch\": 8, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6797138452529907}, {\"epoch\": 9, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6801187992095947}, {\"epoch\": 10, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6802537441253662}, {\"epoch\": 11, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6799837946891785}, {\"epoch\": 12, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6786341071128845}, {\"epoch\": 13, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6786341071128845}, {\"epoch\": 14, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6782291531562805}, {\"epoch\": 15, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6776893138885498}, {\"epoch\": 16, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6775543093681335}, {\"epoch\": 17, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.678094208240509}, {\"epoch\": 18, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6784991025924683}, {\"epoch\": 19, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.678769052028656}, {\"epoch\": 20, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6795789003372192}, {\"epoch\": 21, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.679848849773407}, {\"epoch\": 22, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.679443895816803}, {\"epoch\": 23, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6801187992095947}, {\"epoch\": 24, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6799837946891785}, {\"epoch\": 25, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6797138452529907}, {\"epoch\": 26, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.678769052028656}, {\"epoch\": 27, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6786341071128845}, {\"epoch\": 28, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6789040565490723}, {\"epoch\": 29, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.678769052028656}, {\"epoch\": 30, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6789040565490723}, {\"epoch\": 31, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6782291531562805}, {\"epoch\": 32, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6795789003372192}, {\"epoch\": 33, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6790390014648438}, {\"epoch\": 34, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6783641576766968}, {\"epoch\": 35, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6790390014648438}, {\"epoch\": 36, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6779592633247375}, {\"epoch\": 37, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6784991025924683}, {\"epoch\": 38, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6789040565490723}, {\"epoch\": 39, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.678769052028656}, {\"epoch\": 40, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6786341071128845}, {\"epoch\": 41, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6784991025924683}, {\"epoch\": 42, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6786341071128845}, {\"epoch\": 43, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.678094208240509}, {\"epoch\": 44, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6790390014648438}, {\"epoch\": 45, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6786341071128845}, {\"epoch\": 46, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6782291531562805}, {\"epoch\": 47, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6790390014648438}, {\"epoch\": 48, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6789040565490723}, {\"epoch\": 49, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.67917400598526}, {\"epoch\": 50, \"hidden_nodes\": 4, \"metric\": \"validation_accuracy\", \"value\": 0.6790390014648438}], \"data-92a9c22654acbfc016c002033234566e\": [{\"epoch\": 1, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.8728067874908447}, {\"epoch\": 2, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7399839758872986}, {\"epoch\": 3, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7316082119941711}, {\"epoch\": 4, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.727385401725769}, {\"epoch\": 5, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7235379815101624}, {\"epoch\": 6, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7204984426498413}, {\"epoch\": 7, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7180697917938232}, {\"epoch\": 8, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7162811756134033}, {\"epoch\": 9, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7149444222450256}, {\"epoch\": 10, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7138327360153198}, {\"epoch\": 11, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7128125429153442}, {\"epoch\": 12, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7120084166526794}, {\"epoch\": 13, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7113109230995178}, {\"epoch\": 14, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7106146812438965}, {\"epoch\": 15, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7100602984428406}, {\"epoch\": 16, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7095808386802673}, {\"epoch\": 17, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.709138810634613}, {\"epoch\": 18, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.708743155002594}, {\"epoch\": 19, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.708378255367279}, {\"epoch\": 20, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7080397009849548}, {\"epoch\": 21, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7077564001083374}, {\"epoch\": 22, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7074882984161377}, {\"epoch\": 23, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7072689533233643}, {\"epoch\": 24, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7070557475090027}, {\"epoch\": 25, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7068282961845398}, {\"epoch\": 26, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7066607475280762}, {\"epoch\": 27, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7064544558525085}, {\"epoch\": 28, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.706258237361908}, {\"epoch\": 29, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7061183452606201}, {\"epoch\": 30, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7059581279754639}, {\"epoch\": 31, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.705795168876648}, {\"epoch\": 32, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7056373953819275}, {\"epoch\": 33, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7054758667945862}, {\"epoch\": 34, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7053375244140625}, {\"epoch\": 35, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7051845788955688}, {\"epoch\": 36, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7050464749336243}, {\"epoch\": 37, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7049351334571838}, {\"epoch\": 38, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7048032879829407}, {\"epoch\": 39, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7047041058540344}, {\"epoch\": 40, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.704612135887146}, {\"epoch\": 41, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7044989466667175}, {\"epoch\": 42, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7043823003768921}, {\"epoch\": 43, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7042772173881531}, {\"epoch\": 44, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7041816115379333}, {\"epoch\": 45, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.704064667224884}, {\"epoch\": 46, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7040025591850281}, {\"epoch\": 47, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7039027810096741}, {\"epoch\": 48, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7038211822509766}, {\"epoch\": 49, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7037460207939148}, {\"epoch\": 50, \"hidden_nodes\": 4, \"metric\": \"training_loss\", \"value\": 0.7036592960357666}, {\"epoch\": 1, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7787920236587524}, {\"epoch\": 2, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7642685174942017}, {\"epoch\": 3, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7610481977462769}, {\"epoch\": 4, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7581850290298462}, {\"epoch\": 5, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7564706206321716}, {\"epoch\": 6, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7553474307060242}, {\"epoch\": 7, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7542306780815125}, {\"epoch\": 8, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7537323236465454}, {\"epoch\": 9, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7531279921531677}, {\"epoch\": 10, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7532584071159363}, {\"epoch\": 11, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7532647252082825}, {\"epoch\": 12, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.753472089767456}, {\"epoch\": 13, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7532725930213928}, {\"epoch\": 14, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7530764937400818}, {\"epoch\": 15, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7530167698860168}, {\"epoch\": 16, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7527906894683838}, {\"epoch\": 17, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.752661406993866}, {\"epoch\": 18, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7527649998664856}, {\"epoch\": 19, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7526742815971375}, {\"epoch\": 20, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7526863813400269}, {\"epoch\": 21, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7526266574859619}, {\"epoch\": 22, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7524096369743347}, {\"epoch\": 23, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7523861527442932}, {\"epoch\": 24, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7523859739303589}, {\"epoch\": 25, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7525172829627991}, {\"epoch\": 26, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.752453088760376}, {\"epoch\": 27, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7524453401565552}, {\"epoch\": 28, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7523322105407715}, {\"epoch\": 29, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7524216175079346}, {\"epoch\": 30, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7523220777511597}, {\"epoch\": 31, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7524958252906799}, {\"epoch\": 32, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7523308396339417}, {\"epoch\": 33, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7523496150970459}, {\"epoch\": 34, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7523954510688782}, {\"epoch\": 35, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7523722648620605}, {\"epoch\": 36, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7524177432060242}, {\"epoch\": 37, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7525330781936646}, {\"epoch\": 38, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7524921894073486}, {\"epoch\": 39, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7522697448730469}, {\"epoch\": 40, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7524668574333191}, {\"epoch\": 41, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7524723410606384}, {\"epoch\": 42, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7523353695869446}, {\"epoch\": 43, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7524495124816895}, {\"epoch\": 44, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7524462342262268}, {\"epoch\": 45, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7524085640907288}, {\"epoch\": 46, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7524962425231934}, {\"epoch\": 47, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7526899576187134}, {\"epoch\": 48, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7527034878730774}, {\"epoch\": 49, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.752790093421936}, {\"epoch\": 50, \"hidden_nodes\": 4, \"metric\": \"validation_loss\", \"value\": 0.7527763247489929}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define the models and number of hidden nodes\n",
    "models_config = [\n",
    "    {'model_name': 'one_node', 'hidden_nodes': 1},\n",
    "    {'model_name': 'two_nodes', 'hidden_nodes': 2},\n",
    "    {'model_name': 'four_nodes', 'hidden_nodes': 4}\n",
    "]\n",
    "\n",
    "def create_and_train_model(hidden_nodes):\n",
    "    \"\"\"Create, compile, and train a model based on the number of hidden nodes.\"\"\"\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=(462,)),\n",
    "        Dense(hidden_nodes, activation='relu'),  # Hidden layer with variable nodes\n",
    "        Dense(3, activation='softmax')  # Output layer with 3 nodes\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=0  # Set to 0 to reduce verbose output during training\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def prepare(history, hidden_nodes):\n",
    "    \"\"\"Prepare the training and validation data for Altair plotting.\"\"\"\n",
    "    # Convert history to DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': range(1, 51),\n",
    "        'training_accuracy': history.history['accuracy'],\n",
    "        'validation_accuracy': history.history['val_accuracy'],\n",
    "        'training_loss': history.history['loss'],\n",
    "        'validation_loss': history.history['val_loss'],\n",
    "        'hidden_nodes': [hidden_nodes] * 50\n",
    "    })\n",
    "    \n",
    "    # Melt the dataframe for better use in Altair\n",
    "    df = df.melt(id_vars=['epoch', 'hidden_nodes'], \n",
    "                 value_vars=['training_accuracy', 'validation_accuracy', 'training_loss', 'validation_loss'],\n",
    "                 var_name='metric', value_name='value')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def plot_training_results(df):\n",
    "    \"\"\"Plot the training and validation accuracy and loss using Altair.\"\"\"\n",
    "    # Accuracy plot\n",
    "    accuracy_chart = alt.Chart(df[df['metric'].str.contains('accuracy')]).mark_line().encode(\n",
    "        x='epoch',\n",
    "        y='value',\n",
    "        color='metric',\n",
    "        column='hidden_nodes',\n",
    "        tooltip=['epoch', 'value', 'metric']\n",
    "    ).properties(title=\"Accuracy for Different Models (Hidden Nodes)\")\n",
    "\n",
    "    # Loss plot\n",
    "    loss_chart = alt.Chart(df[df['metric'].str.contains('loss')]).mark_line().encode(\n",
    "        x='epoch',\n",
    "        y='value',\n",
    "        color='metric',\n",
    "        column='hidden_nodes',\n",
    "        tooltip=['epoch', 'value', 'metric']\n",
    "    ).properties(title=\"Loss for Different Models (Hidden Nodes)\")\n",
    "    \n",
    "    return accuracy_chart, loss_chart\n",
    "\n",
    "# Loop over model configurations (1, 2, and 4 hidden nodes)\n",
    "df_all_models = pd.DataFrame()\n",
    "for config in models_config:\n",
    "    history = create_and_train_model(config['hidden_nodes'])\n",
    "    df_model = prepare(history, config['hidden_nodes'])\n",
    "    df_all_models = pd.concat([df_all_models, df_model], ignore_index=True)\n",
    "\n",
    "# Plot the results\n",
    "accuracy_chart, loss_chart = plot_training_results(df_all_models)\n",
    "\n",
    "\n",
    "# Combine accuracy and loss charts for each model configuration\n",
    "combined_charts = alt.vconcat()\n",
    "\n",
    "for hidden_nodes in df_all_models['hidden_nodes'].unique():\n",
    "    accuracy_chart = alt.Chart(df_all_models[(df_all_models['hidden_nodes'] == hidden_nodes) & (df_all_models['metric'].str.contains('accuracy'))]).mark_line().encode(\n",
    "        x='epoch',\n",
    "        y='value',\n",
    "        color='metric',\n",
    "        tooltip=['epoch', 'value', 'metric']\n",
    "    ).properties(title=f\"Accuracy for Model with {hidden_nodes} Hidden Nodes\")\n",
    "\n",
    "    loss_chart = alt.Chart(df_all_models[(df_all_models['hidden_nodes'] == hidden_nodes) & (df_all_models['metric'].str.contains('loss'))]).mark_line().encode(\n",
    "        x='epoch',\n",
    "        y='value',\n",
    "        color='metric',\n",
    "        tooltip=['epoch', 'value', 'metric']\n",
    "    ).properties(title=f\"Loss for Model with {hidden_nodes} Hidden Nodes\")\n",
    "\n",
    "    combined_charts &= (accuracy_chart | loss_chart)\n",
    "\n",
    "# Display the combined charts\n",
    "combined_charts.display()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the Plots\n",
    "Observing the graph, we can conclude that the network is overfitting. This is evident from the fact that the training accuracy continues to improve while the validation accuracy plateaus or even decreases. Additionally, the training loss decreases steadily, whereas the validation loss starts to increase after a certain number of epochs. This indicates that the model is learning the training data very well but is not generalizing to the validation data, which is a clear sign of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 8 hidden nodes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 16 hidden nodes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 32 hidden nodes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 64 hidden nodes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 128 hidden nodes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 256 hidden nodes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 512 hidden nodes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-197f923534a64230a675999e2b37b5fa.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-197f923534a64230a675999e2b37b5fa.vega-embed details,\n",
       "  #altair-viz-197f923534a64230a675999e2b37b5fa.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-197f923534a64230a675999e2b37b5fa\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-197f923534a64230a675999e2b37b5fa\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-197f923534a64230a675999e2b37b5fa\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-97d187ea92cbae9ae2858503dbe9743d\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"column\": {\"field\": \"hidden_nodes\", \"type\": \"ordinal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}, {\"field\": \"hidden_nodes\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Model Performance: Accuracy & Loss for Different Hidden Node Configurations\", \"width\": 300, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-97d187ea92cbae9ae2858503dbe9743d\": [{\"epoch\": 1, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.6536858081817627}, {\"epoch\": 2, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.6880307197570801}, {\"epoch\": 3, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.6911015510559082}, {\"epoch\": 4, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.6922166347503662}, {\"epoch\": 5, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.6942238211631775}, {\"epoch\": 6, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.6966255307197571}, {\"epoch\": 7, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.6987356543540955}, {\"epoch\": 8, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7006399035453796}, {\"epoch\": 9, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7029386758804321}, {\"epoch\": 10, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7048429250717163}, {\"epoch\": 11, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7063697576522827}, {\"epoch\": 12, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7079995274543762}, {\"epoch\": 13, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7094234228134155}, {\"epoch\": 14, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7110874652862549}, {\"epoch\": 15, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7122197151184082}, {\"epoch\": 16, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7130774855613708}, {\"epoch\": 17, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7143641114234924}, {\"epoch\": 18, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7161139845848083}, {\"epoch\": 19, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7167658805847168}, {\"epoch\": 20, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7173320055007935}, {\"epoch\": 21, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7182241082191467}, {\"epoch\": 22, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7196994423866272}, {\"epoch\": 23, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7207459211349487}, {\"epoch\": 24, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.721483588218689}, {\"epoch\": 25, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7226844429969788}, {\"epoch\": 26, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7235250473022461}, {\"epoch\": 27, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7241770029067993}, {\"epoch\": 28, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7248975038528442}, {\"epoch\": 29, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7253092527389526}, {\"epoch\": 30, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7256008386611938}, {\"epoch\": 31, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7260469198226929}, {\"epoch\": 32, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7266302108764648}, {\"epoch\": 33, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7269904613494873}, {\"epoch\": 34, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7273163795471191}, {\"epoch\": 35, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7281569838523865}, {\"epoch\": 36, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7284657955169678}, {\"epoch\": 37, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7288432121276855}, {\"epoch\": 38, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7289461493492126}, {\"epoch\": 39, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7291520237922668}, {\"epoch\": 40, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7294608354568481}, {\"epoch\": 41, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7295466065406799}, {\"epoch\": 42, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7297181487083435}, {\"epoch\": 43, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.730078399181366}, {\"epoch\": 44, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.730318546295166}, {\"epoch\": 45, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7308332324028015}, {\"epoch\": 46, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.730764627456665}, {\"epoch\": 47, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7306788563728333}, {\"epoch\": 48, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7307817935943604}, {\"epoch\": 49, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7309705018997192}, {\"epoch\": 50, \"hidden_nodes\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7310047745704651}, {\"epoch\": 1, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6682413220405579}, {\"epoch\": 2, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.671480655670166}, {\"epoch\": 3, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.672155499458313}, {\"epoch\": 4, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6748549342155457}, {\"epoch\": 5, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.678094208240509}, {\"epoch\": 6, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6772843599319458}, {\"epoch\": 7, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6771494150161743}, {\"epoch\": 8, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6784991025924683}, {\"epoch\": 9, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6784991025924683}, {\"epoch\": 10, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6806586384773254}, {\"epoch\": 11, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6829531788825989}, {\"epoch\": 12, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6844378709793091}, {\"epoch\": 13, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6834930777549744}, {\"epoch\": 14, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6829531788825989}, {\"epoch\": 15, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6829531788825989}, {\"epoch\": 16, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6844378709793091}, {\"epoch\": 17, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.685112714767456}, {\"epoch\": 18, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6856526136398315}, {\"epoch\": 19, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6859225034713745}, {\"epoch\": 20, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6852476596832275}, {\"epoch\": 21, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6883519887924194}, {\"epoch\": 22, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6892967820167542}, {\"epoch\": 23, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6898366808891296}, {\"epoch\": 24, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6903765797615051}, {\"epoch\": 25, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6910514235496521}, {\"epoch\": 26, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6933459043502808}, {\"epoch\": 27, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6930760145187378}, {\"epoch\": 28, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.693480908870697}, {\"epoch\": 29, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6933459043502808}, {\"epoch\": 30, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6936158537864685}, {\"epoch\": 31, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6946956515312195}, {\"epoch\": 32, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6944257020950317}, {\"epoch\": 33, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6951005458831787}, {\"epoch\": 34, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6953704953193665}, {\"epoch\": 35, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6953704953193665}, {\"epoch\": 36, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6953704953193665}, {\"epoch\": 37, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6953704953193665}, {\"epoch\": 38, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.695235550403595}, {\"epoch\": 39, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6956404447555542}, {\"epoch\": 40, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6959103941917419}, {\"epoch\": 41, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6963152885437012}, {\"epoch\": 42, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6955054402351379}, {\"epoch\": 43, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6953704953193665}, {\"epoch\": 44, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6953704953193665}, {\"epoch\": 45, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6949656009674072}, {\"epoch\": 46, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6951005458831787}, {\"epoch\": 47, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6944257020950317}, {\"epoch\": 48, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6960453391075134}, {\"epoch\": 49, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6963152885437012}, {\"epoch\": 50, \"hidden_nodes\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6961803436279297}, {\"epoch\": 1, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.8047601580619812}, {\"epoch\": 2, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.7396284341812134}, {\"epoch\": 3, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.7331181168556213}, {\"epoch\": 4, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.7278382778167725}, {\"epoch\": 5, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.7232663631439209}, {\"epoch\": 6, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.719054639339447}, {\"epoch\": 7, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.7151428461074829}, {\"epoch\": 8, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.7115165591239929}, {\"epoch\": 9, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.7080210447311401}, {\"epoch\": 10, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.7046467065811157}, {\"epoch\": 11, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.7012129426002502}, {\"epoch\": 12, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6977052688598633}, {\"epoch\": 13, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6940100193023682}, {\"epoch\": 14, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6905412673950195}, {\"epoch\": 15, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6873364448547363}, {\"epoch\": 16, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6843735575675964}, {\"epoch\": 17, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6817418932914734}, {\"epoch\": 18, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6792812943458557}, {\"epoch\": 19, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6769183874130249}, {\"epoch\": 20, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6747719645500183}, {\"epoch\": 21, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.672580897808075}, {\"epoch\": 22, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6703780889511108}, {\"epoch\": 23, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6683060526847839}, {\"epoch\": 24, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6663812398910522}, {\"epoch\": 25, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6646218299865723}, {\"epoch\": 26, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.663030743598938}, {\"epoch\": 27, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6615161895751953}, {\"epoch\": 28, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6601136326789856}, {\"epoch\": 29, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6588329076766968}, {\"epoch\": 30, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6576454043388367}, {\"epoch\": 31, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6565443277359009}, {\"epoch\": 32, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6555091738700867}, {\"epoch\": 33, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6546271443367004}, {\"epoch\": 34, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.653810441493988}, {\"epoch\": 35, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6530871987342834}, {\"epoch\": 36, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.65250164270401}, {\"epoch\": 37, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6518107056617737}, {\"epoch\": 38, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6512318849563599}, {\"epoch\": 39, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6506667137145996}, {\"epoch\": 40, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6501256823539734}, {\"epoch\": 41, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6496458053588867}, {\"epoch\": 42, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6491926908493042}, {\"epoch\": 43, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6486928462982178}, {\"epoch\": 44, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.648311972618103}, {\"epoch\": 45, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6478432416915894}, {\"epoch\": 46, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.647477388381958}, {\"epoch\": 47, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6470907926559448}, {\"epoch\": 48, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6466937065124512}, {\"epoch\": 49, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.646321713924408}, {\"epoch\": 50, \"hidden_nodes\": 8, \"metric\": \"Training Loss\", \"value\": 0.6459920406341553}, {\"epoch\": 1, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.769821286201477}, {\"epoch\": 2, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7635550498962402}, {\"epoch\": 3, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7609796524047852}, {\"epoch\": 4, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7589249014854431}, {\"epoch\": 5, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.757156252861023}, {\"epoch\": 6, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7558891177177429}, {\"epoch\": 7, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7547122240066528}, {\"epoch\": 8, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7536343932151794}, {\"epoch\": 9, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.752389132976532}, {\"epoch\": 10, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7509123682975769}, {\"epoch\": 11, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7489804625511169}, {\"epoch\": 12, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7474168539047241}, {\"epoch\": 13, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7455247640609741}, {\"epoch\": 14, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7437418699264526}, {\"epoch\": 15, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7425386309623718}, {\"epoch\": 16, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7410542368888855}, {\"epoch\": 17, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7402268648147583}, {\"epoch\": 18, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7389044165611267}, {\"epoch\": 19, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7385360598564148}, {\"epoch\": 20, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7376986145973206}, {\"epoch\": 21, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7359598278999329}, {\"epoch\": 22, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7343454957008362}, {\"epoch\": 23, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7328310608863831}, {\"epoch\": 24, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7315651774406433}, {\"epoch\": 25, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7303532361984253}, {\"epoch\": 26, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7296236753463745}, {\"epoch\": 27, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.728875458240509}, {\"epoch\": 28, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.728278636932373}, {\"epoch\": 29, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7278459072113037}, {\"epoch\": 30, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7275781631469727}, {\"epoch\": 31, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7273369431495667}, {\"epoch\": 32, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.726969838142395}, {\"epoch\": 33, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7267144322395325}, {\"epoch\": 34, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7264971137046814}, {\"epoch\": 35, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7263416051864624}, {\"epoch\": 36, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7264154553413391}, {\"epoch\": 37, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7261216044425964}, {\"epoch\": 38, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7261247038841248}, {\"epoch\": 39, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7262321710586548}, {\"epoch\": 40, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.726037859916687}, {\"epoch\": 41, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7263091802597046}, {\"epoch\": 42, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7264811992645264}, {\"epoch\": 43, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7266666293144226}, {\"epoch\": 44, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7268442511558533}, {\"epoch\": 45, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7265469431877136}, {\"epoch\": 46, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7267264723777771}, {\"epoch\": 47, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7267376780509949}, {\"epoch\": 48, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7265325784683228}, {\"epoch\": 49, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7267063856124878}, {\"epoch\": 50, \"hidden_nodes\": 8, \"metric\": \"Validation Loss\", \"value\": 0.7266964316368103}, {\"epoch\": 1, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.6535485982894897}, {\"epoch\": 2, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.6903467178344727}, {\"epoch\": 3, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.6961623430252075}, {\"epoch\": 4, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7012231945991516}, {\"epoch\": 5, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7063354253768921}, {\"epoch\": 6, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7107786536216736}, {\"epoch\": 7, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7164227962493896}, {\"epoch\": 8, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7203341722488403}, {\"epoch\": 9, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.72614985704422}, {\"epoch\": 10, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7312449812889099}, {\"epoch\": 11, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7352936267852783}, {\"epoch\": 12, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.738964855670929}, {\"epoch\": 13, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7418126463890076}, {\"epoch\": 14, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.744162917137146}, {\"epoch\": 15, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7460328340530396}, {\"epoch\": 16, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7467533349990845}, {\"epoch\": 17, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7481257915496826}, {\"epoch\": 18, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7499785423278809}, {\"epoch\": 19, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7518484592437744}, {\"epoch\": 20, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7528606653213501}, {\"epoch\": 21, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7532037496566772}, {\"epoch\": 22, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.754112958908081}, {\"epoch\": 23, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.754696249961853}, {\"epoch\": 24, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7555368542671204}, {\"epoch\": 25, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7561716437339783}, {\"epoch\": 26, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7568578124046326}, {\"epoch\": 27, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7571837902069092}, {\"epoch\": 28, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7580587267875671}, {\"epoch\": 29, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7583332061767578}, {\"epoch\": 30, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7582302689552307}, {\"epoch\": 31, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7591223120689392}, {\"epoch\": 32, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7596026659011841}, {\"epoch\": 33, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7597571015357971}, {\"epoch\": 34, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7598085403442383}, {\"epoch\": 35, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7603746652603149}, {\"epoch\": 36, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7604947686195374}, {\"epoch\": 37, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7607864141464233}, {\"epoch\": 38, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7611466646194458}, {\"epoch\": 39, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7611638307571411}, {\"epoch\": 40, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7615069150924683}, {\"epoch\": 41, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7619529366493225}, {\"epoch\": 42, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7622274160385132}, {\"epoch\": 43, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7627935409545898}, {\"epoch\": 44, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7632396221160889}, {\"epoch\": 45, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7634969353675842}, {\"epoch\": 46, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.763874351978302}, {\"epoch\": 47, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7638915181159973}, {\"epoch\": 48, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7640287280082703}, {\"epoch\": 49, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7642861008644104}, {\"epoch\": 50, \"hidden_nodes\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.7644919753074646}, {\"epoch\": 1, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6671615839004517}, {\"epoch\": 2, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6720204949378967}, {\"epoch\": 3, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6747199296951294}, {\"epoch\": 4, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6776893138885498}, {\"epoch\": 5, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6817384362220764}, {\"epoch\": 6, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6855176091194153}, {\"epoch\": 7, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6913213729858398}, {\"epoch\": 8, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6932109594345093}, {\"epoch\": 9, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6955054402351379}, {\"epoch\": 10, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6963152885437012}, {\"epoch\": 11, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6949656009674072}, {\"epoch\": 12, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6938858032226562}, {\"epoch\": 13, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6938858032226562}, {\"epoch\": 14, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6955054402351379}, {\"epoch\": 15, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6949656009674072}, {\"epoch\": 16, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6940208077430725}, {\"epoch\": 17, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6949656009674072}, {\"epoch\": 18, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6955054402351379}, {\"epoch\": 19, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6955054402351379}, {\"epoch\": 20, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6961803436279297}, {\"epoch\": 21, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6969901323318481}, {\"epoch\": 22, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6953704953193665}, {\"epoch\": 23, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.693480908870697}, {\"epoch\": 24, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6926710605621338}, {\"epoch\": 25, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6926710605621338}, {\"epoch\": 26, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6919962167739868}, {\"epoch\": 27, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6936158537864685}, {\"epoch\": 28, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6919962167739868}, {\"epoch\": 29, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6919962167739868}, {\"epoch\": 30, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6921312212944031}, {\"epoch\": 31, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6922661662101746}, {\"epoch\": 32, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6921312212944031}, {\"epoch\": 33, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6919962167739868}, {\"epoch\": 34, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6919962167739868}, {\"epoch\": 35, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6929410099983215}, {\"epoch\": 36, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6925361156463623}, {\"epoch\": 37, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.69280606508255}, {\"epoch\": 38, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6930760145187378}, {\"epoch\": 39, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.692401111125946}, {\"epoch\": 40, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6922661662101746}, {\"epoch\": 41, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6925361156463623}, {\"epoch\": 42, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6919962167739868}, {\"epoch\": 43, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6922661662101746}, {\"epoch\": 44, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6926710605621338}, {\"epoch\": 45, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6925361156463623}, {\"epoch\": 46, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.692401111125946}, {\"epoch\": 47, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6922661662101746}, {\"epoch\": 48, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.692401111125946}, {\"epoch\": 49, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6918612718582153}, {\"epoch\": 50, \"hidden_nodes\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6919962167739868}, {\"epoch\": 1, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.7986403107643127}, {\"epoch\": 2, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.7369272708892822}, {\"epoch\": 3, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.7213307619094849}, {\"epoch\": 4, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.7082514762878418}, {\"epoch\": 5, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6982079744338989}, {\"epoch\": 6, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6891580820083618}, {\"epoch\": 7, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6801351308822632}, {\"epoch\": 8, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6703137755393982}, {\"epoch\": 9, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6598392128944397}, {\"epoch\": 10, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6495795845985413}, {\"epoch\": 11, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6407656073570251}, {\"epoch\": 12, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6332826614379883}, {\"epoch\": 13, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6268595457077026}, {\"epoch\": 14, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6214221715927124}, {\"epoch\": 15, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6169369220733643}, {\"epoch\": 16, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6131550669670105}, {\"epoch\": 17, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6098114848136902}, {\"epoch\": 18, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6069255471229553}, {\"epoch\": 19, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.604452908039093}, {\"epoch\": 20, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6021624803543091}, {\"epoch\": 21, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.6000732183456421}, {\"epoch\": 22, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5981020927429199}, {\"epoch\": 23, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5963274240493774}, {\"epoch\": 24, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5947294235229492}, {\"epoch\": 25, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5931639671325684}, {\"epoch\": 26, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5918001532554626}, {\"epoch\": 27, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5905495285987854}, {\"epoch\": 28, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.589273989200592}, {\"epoch\": 29, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5881730914115906}, {\"epoch\": 30, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5869888663291931}, {\"epoch\": 31, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5859304070472717}, {\"epoch\": 32, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5849797129631042}, {\"epoch\": 33, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.584101140499115}, {\"epoch\": 34, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5832897424697876}, {\"epoch\": 35, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5824766755104065}, {\"epoch\": 36, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5816254615783691}, {\"epoch\": 37, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.580973744392395}, {\"epoch\": 38, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5802345871925354}, {\"epoch\": 39, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5796668529510498}, {\"epoch\": 40, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5790382623672485}, {\"epoch\": 41, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5784173607826233}, {\"epoch\": 42, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5778558254241943}, {\"epoch\": 43, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5773405432701111}, {\"epoch\": 44, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5768340229988098}, {\"epoch\": 45, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.576311469078064}, {\"epoch\": 46, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5757957100868225}, {\"epoch\": 47, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5753186941146851}, {\"epoch\": 48, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5748274326324463}, {\"epoch\": 49, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5744092464447021}, {\"epoch\": 50, \"hidden_nodes\": 16, \"metric\": \"Training Loss\", \"value\": 0.5739024877548218}, {\"epoch\": 1, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7702826261520386}, {\"epoch\": 2, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7600679993629456}, {\"epoch\": 3, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7515996694564819}, {\"epoch\": 4, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7455737590789795}, {\"epoch\": 5, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7410312294960022}, {\"epoch\": 6, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7367494106292725}, {\"epoch\": 7, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7317706942558289}, {\"epoch\": 8, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.727183997631073}, {\"epoch\": 9, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7231325507164001}, {\"epoch\": 10, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.720553457736969}, {\"epoch\": 11, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7187096476554871}, {\"epoch\": 12, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7180187106132507}, {\"epoch\": 13, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.718075692653656}, {\"epoch\": 14, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7186975479125977}, {\"epoch\": 15, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7194841504096985}, {\"epoch\": 16, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7200719118118286}, {\"epoch\": 17, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7208077311515808}, {\"epoch\": 18, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7217161059379578}, {\"epoch\": 19, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7222533822059631}, {\"epoch\": 20, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7231832146644592}, {\"epoch\": 21, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7245299220085144}, {\"epoch\": 22, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7256495356559753}, {\"epoch\": 23, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7269371747970581}, {\"epoch\": 24, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.727885901927948}, {\"epoch\": 25, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7285629510879517}, {\"epoch\": 26, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7294530272483826}, {\"epoch\": 27, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7298048734664917}, {\"epoch\": 28, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.730186402797699}, {\"epoch\": 29, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.730461835861206}, {\"epoch\": 30, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7309220433235168}, {\"epoch\": 31, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7317929267883301}, {\"epoch\": 32, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7324056029319763}, {\"epoch\": 33, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7335361242294312}, {\"epoch\": 34, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7340739369392395}, {\"epoch\": 35, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7347663640975952}, {\"epoch\": 36, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7351256608963013}, {\"epoch\": 37, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7358710169792175}, {\"epoch\": 38, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7364798784255981}, {\"epoch\": 39, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7371030449867249}, {\"epoch\": 40, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7376416921615601}, {\"epoch\": 41, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7385019063949585}, {\"epoch\": 42, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7387896180152893}, {\"epoch\": 43, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7397845983505249}, {\"epoch\": 44, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7398108243942261}, {\"epoch\": 45, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7400617003440857}, {\"epoch\": 46, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7402505874633789}, {\"epoch\": 47, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7407180666923523}, {\"epoch\": 48, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7416019439697266}, {\"epoch\": 49, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7415148615837097}, {\"epoch\": 50, \"hidden_nodes\": 16, \"metric\": \"Validation Loss\", \"value\": 0.7423528432846069}, {\"epoch\": 1, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.6630011200904846}, {\"epoch\": 2, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.6942066550254822}, {\"epoch\": 3, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7095777988433838}, {\"epoch\": 4, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7240397334098816}, {\"epoch\": 5, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7333207726478577}, {\"epoch\": 6, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7412979602813721}, {\"epoch\": 7, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7476626038551331}, {\"epoch\": 8, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7534782290458679}, {\"epoch\": 9, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7595854997634888}, {\"epoch\": 10, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7637714147567749}, {\"epoch\": 11, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7687636017799377}, {\"epoch\": 12, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7726235389709473}, {\"epoch\": 13, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7764492034912109}, {\"epoch\": 14, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7795714735984802}, {\"epoch\": 15, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7831740975379944}, {\"epoch\": 16, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7854042649269104}, {\"epoch\": 17, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7882348895072937}, {\"epoch\": 18, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7903964519500732}, {\"epoch\": 19, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7916830778121948}, {\"epoch\": 20, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7940162420272827}, {\"epoch\": 21, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7956116795539856}, {\"epoch\": 22, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7967953681945801}, {\"epoch\": 23, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7983736991882324}, {\"epoch\": 24, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.7989226579666138}, {\"epoch\": 25, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8007411360740662}, {\"epoch\": 26, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8011528253555298}, {\"epoch\": 27, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8020449280738831}, {\"epoch\": 28, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8025252819061279}, {\"epoch\": 29, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8034688234329224}, {\"epoch\": 30, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8048755526542664}, {\"epoch\": 31, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8051156997680664}, {\"epoch\": 32, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8060420751571655}, {\"epoch\": 33, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8071743249893188}, {\"epoch\": 34, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8078605532646179}, {\"epoch\": 35, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8083409070968628}, {\"epoch\": 36, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8090271353721619}, {\"epoch\": 37, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8100392818450928}, {\"epoch\": 38, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8103480935096741}, {\"epoch\": 39, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8109142184257507}, {\"epoch\": 40, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8117548227310181}, {\"epoch\": 41, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8121494054794312}, {\"epoch\": 42, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8125954270362854}, {\"epoch\": 43, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8131615519523621}, {\"epoch\": 44, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.813453197479248}, {\"epoch\": 45, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8140879273414612}, {\"epoch\": 46, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8142080307006836}, {\"epoch\": 47, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8149113655090332}, {\"epoch\": 48, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8147913217544556}, {\"epoch\": 49, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8155118227005005}, {\"epoch\": 50, \"hidden_nodes\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.8156490921974182}, {\"epoch\": 1, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6729652881622314}, {\"epoch\": 2, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6801187992095947}, {\"epoch\": 3, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6899716854095459}, {\"epoch\": 4, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6945606470108032}, {\"epoch\": 5, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6953704953193665}, {\"epoch\": 6, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6964502334594727}, {\"epoch\": 7, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6951005458831787}, {\"epoch\": 8, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6953704953193665}, {\"epoch\": 9, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6944257020950317}, {\"epoch\": 10, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6917262673377991}, {\"epoch\": 11, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6909164786338806}, {\"epoch\": 12, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6899716854095459}, {\"epoch\": 13, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.687542200088501}, {\"epoch\": 14, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.685787558555603}, {\"epoch\": 15, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6843028664588928}, {\"epoch\": 16, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6838979721069336}, {\"epoch\": 17, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6838979721069336}, {\"epoch\": 18, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6836280226707458}, {\"epoch\": 19, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6822783350944519}, {\"epoch\": 20, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.679848849773407}, {\"epoch\": 21, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6793089509010315}, {\"epoch\": 22, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6786341071128845}, {\"epoch\": 23, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6771494150161743}, {\"epoch\": 24, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.678769052028656}, {\"epoch\": 25, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6793089509010315}, {\"epoch\": 26, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6786341071128845}, {\"epoch\": 27, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6775543093681335}, {\"epoch\": 28, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6772843599319458}, {\"epoch\": 29, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.678094208240509}, {\"epoch\": 30, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6778242588043213}, {\"epoch\": 31, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6771494150161743}, {\"epoch\": 32, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6756647229194641}, {\"epoch\": 33, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6749898791313171}, {\"epoch\": 34, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6749898791313171}, {\"epoch\": 35, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6737751364707947}, {\"epoch\": 36, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6735051870346069}, {\"epoch\": 37, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6724254488945007}, {\"epoch\": 38, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6725603938102722}, {\"epoch\": 39, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6712107062339783}, {\"epoch\": 40, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6713456511497498}, {\"epoch\": 41, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.671480655670166}, {\"epoch\": 42, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.671075701713562}, {\"epoch\": 43, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.671750545501709}, {\"epoch\": 44, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.670400857925415}, {\"epoch\": 45, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.671075701713562}, {\"epoch\": 46, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6713456511497498}, {\"epoch\": 47, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6709407567977905}, {\"epoch\": 48, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6718855500221252}, {\"epoch\": 49, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6708057522773743}, {\"epoch\": 50, \"hidden_nodes\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6687812209129333}, {\"epoch\": 1, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.7821282744407654}, {\"epoch\": 2, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.7272608280181885}, {\"epoch\": 3, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.6944557428359985}, {\"epoch\": 4, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.6662548780441284}, {\"epoch\": 5, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.6453104019165039}, {\"epoch\": 6, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.6284204125404358}, {\"epoch\": 7, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.6139960885047913}, {\"epoch\": 8, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.601130485534668}, {\"epoch\": 9, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5895584225654602}, {\"epoch\": 10, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5791396498680115}, {\"epoch\": 11, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5695517659187317}, {\"epoch\": 12, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5605047345161438}, {\"epoch\": 13, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5526302456855774}, {\"epoch\": 14, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5454159379005432}, {\"epoch\": 15, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5392335057258606}, {\"epoch\": 16, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5336198210716248}, {\"epoch\": 17, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5287874341011047}, {\"epoch\": 18, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5243220329284668}, {\"epoch\": 19, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5203068852424622}, {\"epoch\": 20, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5165964365005493}, {\"epoch\": 21, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5130279660224915}, {\"epoch\": 22, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5097857117652893}, {\"epoch\": 23, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5068491697311401}, {\"epoch\": 24, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5041947960853577}, {\"epoch\": 25, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.5015438795089722}, {\"epoch\": 26, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4990616738796234}, {\"epoch\": 27, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.496895432472229}, {\"epoch\": 28, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.494672566652298}, {\"epoch\": 29, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.49271053075790405}, {\"epoch\": 30, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4907190799713135}, {\"epoch\": 31, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.48885440826416016}, {\"epoch\": 32, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.48713651299476624}, {\"epoch\": 33, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4854346811771393}, {\"epoch\": 34, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4837530553340912}, {\"epoch\": 35, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.48217374086380005}, {\"epoch\": 36, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.48073810338974}, {\"epoch\": 37, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.47928351163864136}, {\"epoch\": 38, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4779667556285858}, {\"epoch\": 39, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.47655463218688965}, {\"epoch\": 40, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4753492772579193}, {\"epoch\": 41, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4742257297039032}, {\"epoch\": 42, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4729250371456146}, {\"epoch\": 43, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4718223214149475}, {\"epoch\": 44, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.47068166732788086}, {\"epoch\": 45, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.469668447971344}, {\"epoch\": 46, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.46865180134773254}, {\"epoch\": 47, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4676790237426758}, {\"epoch\": 48, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.46682360768318176}, {\"epoch\": 49, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4658425450325012}, {\"epoch\": 50, \"hidden_nodes\": 32, \"metric\": \"Training Loss\", \"value\": 0.4649997651576996}, {\"epoch\": 1, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.765148401260376}, {\"epoch\": 2, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7460872530937195}, {\"epoch\": 3, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7265074849128723}, {\"epoch\": 4, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7161126732826233}, {\"epoch\": 5, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7115025520324707}, {\"epoch\": 6, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7099933624267578}, {\"epoch\": 7, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7113673090934753}, {\"epoch\": 8, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7141584753990173}, {\"epoch\": 9, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7189351320266724}, {\"epoch\": 10, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7235023975372314}, {\"epoch\": 11, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7298017144203186}, {\"epoch\": 12, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7352114915847778}, {\"epoch\": 13, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7423502802848816}, {\"epoch\": 14, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.74969083070755}, {\"epoch\": 15, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7571942806243896}, {\"epoch\": 16, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7635684013366699}, {\"epoch\": 17, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7702591419219971}, {\"epoch\": 18, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.776587963104248}, {\"epoch\": 19, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7822433710098267}, {\"epoch\": 20, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7876250743865967}, {\"epoch\": 21, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7933406233787537}, {\"epoch\": 22, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.7982977032661438}, {\"epoch\": 23, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8027195930480957}, {\"epoch\": 24, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8067139983177185}, {\"epoch\": 25, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8113706707954407}, {\"epoch\": 26, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8148874044418335}, {\"epoch\": 27, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8188381195068359}, {\"epoch\": 28, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8230497241020203}, {\"epoch\": 29, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8266512155532837}, {\"epoch\": 30, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8300825357437134}, {\"epoch\": 31, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8332785367965698}, {\"epoch\": 32, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8369851112365723}, {\"epoch\": 33, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8400927782058716}, {\"epoch\": 34, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8433720469474792}, {\"epoch\": 35, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8461440205574036}, {\"epoch\": 36, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8492326140403748}, {\"epoch\": 37, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8521552681922913}, {\"epoch\": 38, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8554008603096008}, {\"epoch\": 39, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8584377765655518}, {\"epoch\": 40, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8608523607254028}, {\"epoch\": 41, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8630098104476929}, {\"epoch\": 42, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8653830289840698}, {\"epoch\": 43, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8684220314025879}, {\"epoch\": 44, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8705869913101196}, {\"epoch\": 45, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8730223774909973}, {\"epoch\": 46, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8754452466964722}, {\"epoch\": 47, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.8777596950531006}, {\"epoch\": 48, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.879533588886261}, {\"epoch\": 49, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.881734311580658}, {\"epoch\": 50, \"hidden_nodes\": 32, \"metric\": \"Validation Loss\", \"value\": 0.884661078453064}, {\"epoch\": 1, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.6677531599998474}, {\"epoch\": 2, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.7018579244613647}, {\"epoch\": 3, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.7215865254402161}, {\"epoch\": 4, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.7389476895332336}, {\"epoch\": 5, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.7546104788780212}, {\"epoch\": 6, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.7663275599479675}, {\"epoch\": 7, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.7781475782394409}, {\"epoch\": 8, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.7898989319801331}, {\"epoch\": 9, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8004323244094849}, {\"epoch\": 10, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8096446990966797}, {\"epoch\": 11, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8177934885025024}, {\"epoch\": 12, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8243639469146729}, {\"epoch\": 13, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8304369449615479}, {\"epoch\": 14, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8363555073738098}, {\"epoch\": 15, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.842051088809967}, {\"epoch\": 16, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8464943170547485}, {\"epoch\": 17, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8508860468864441}, {\"epoch\": 18, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8551748991012573}, {\"epoch\": 19, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8590005040168762}, {\"epoch\": 20, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8625516891479492}, {\"epoch\": 21, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8665488958358765}, {\"epoch\": 22, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8694995641708374}, {\"epoch\": 23, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8726733326911926}, {\"epoch\": 24, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8756926655769348}, {\"epoch\": 25, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8788663744926453}, {\"epoch\": 26, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.882400393486023}, {\"epoch\": 27, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8857799768447876}, {\"epoch\": 28, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8877528309822083}, {\"epoch\": 29, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8899143934249878}, {\"epoch\": 30, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8923847675323486}, {\"epoch\": 31, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8939630389213562}, {\"epoch\": 32, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8969309329986572}, {\"epoch\": 33, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.8987322449684143}, {\"epoch\": 34, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9009795784950256}, {\"epoch\": 35, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9026779532432556}, {\"epoch\": 36, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9048223495483398}, {\"epoch\": 37, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9065550565719604}, {\"epoch\": 38, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9080818891525269}, {\"epoch\": 39, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9097973704338074}, {\"epoch\": 40, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.911238431930542}, {\"epoch\": 41, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9127309322357178}, {\"epoch\": 42, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9144122004508972}, {\"epoch\": 43, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9157331585884094}, {\"epoch\": 44, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9179804921150208}, {\"epoch\": 45, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9194901585578918}, {\"epoch\": 46, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9202964305877686}, {\"epoch\": 47, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9214115142822266}, {\"epoch\": 48, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9228354096412659}, {\"epoch\": 49, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9235902428627014}, {\"epoch\": 50, \"hidden_nodes\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9250999093055725}, {\"epoch\": 1, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6745849847793579}, {\"epoch\": 2, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6876771450042725}, {\"epoch\": 3, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.694155752658844}, {\"epoch\": 4, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.7006343603134155}, {\"epoch\": 5, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.7002294659614563}, {\"epoch\": 6, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.701849102973938}, {\"epoch\": 7, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6984748244285583}, {\"epoch\": 8, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6936158537864685}, {\"epoch\": 9, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6907814741134644}, {\"epoch\": 10, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6872722506523132}, {\"epoch\": 11, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6829531788825989}, {\"epoch\": 12, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.678769052028656}, {\"epoch\": 13, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6756647229194641}, {\"epoch\": 14, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6697260141372681}, {\"epoch\": 15, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6694560647010803}, {\"epoch\": 16, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6670265793800354}, {\"epoch\": 17, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6641921997070312}, {\"epoch\": 18, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.658523440361023}, {\"epoch\": 19, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6575786471366882}, {\"epoch\": 20, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6559589505195618}, {\"epoch\": 21, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6563639044761658}, {\"epoch\": 22, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6517748832702637}, {\"epoch\": 23, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.650155246257782}, {\"epoch\": 24, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.650425136089325}, {\"epoch\": 25, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6479957103729248}, {\"epoch\": 26, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6467809677124023}, {\"epoch\": 27, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6481306552886963}, {\"epoch\": 28, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6466459631919861}, {\"epoch\": 29, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6444864273071289}, {\"epoch\": 30, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6444864273071289}, {\"epoch\": 31, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6430017352104187}, {\"epoch\": 32, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6419219970703125}, {\"epoch\": 33, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6403023600578308}, {\"epoch\": 34, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6374679207801819}, {\"epoch\": 35, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6380078196525574}, {\"epoch\": 36, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6371980309486389}, {\"epoch\": 37, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6366581320762634}, {\"epoch\": 38, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6365231275558472}, {\"epoch\": 39, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6339586973190308}, {\"epoch\": 40, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.633688747882843}, {\"epoch\": 41, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6326090097427368}, {\"epoch\": 42, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6331488490104675}, {\"epoch\": 43, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6328789591789246}, {\"epoch\": 44, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6324740052223206}, {\"epoch\": 45, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6335538029670715}, {\"epoch\": 46, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6315292119979858}, {\"epoch\": 47, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6312592625617981}, {\"epoch\": 48, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6311243176460266}, {\"epoch\": 49, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6309893131256104}, {\"epoch\": 50, \"hidden_nodes\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6290997266769409}, {\"epoch\": 1, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.7766956090927124}, {\"epoch\": 2, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.7125499248504639}, {\"epoch\": 3, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.6713173985481262}, {\"epoch\": 4, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.6333752274513245}, {\"epoch\": 5, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.6019055247306824}, {\"epoch\": 6, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.5744836926460266}, {\"epoch\": 7, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.5494360327720642}, {\"epoch\": 8, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.525985598564148}, {\"epoch\": 9, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.5046076774597168}, {\"epoch\": 10, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.48474735021591187}, {\"epoch\": 11, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.4669078290462494}, {\"epoch\": 12, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.45081767439842224}, {\"epoch\": 13, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.43611106276512146}, {\"epoch\": 14, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.42294466495513916}, {\"epoch\": 15, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.4109584391117096}, {\"epoch\": 16, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.39986178278923035}, {\"epoch\": 17, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.389657199382782}, {\"epoch\": 18, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.38024255633354187}, {\"epoch\": 19, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.371367871761322}, {\"epoch\": 20, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.3630211651325226}, {\"epoch\": 21, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.3552910089492798}, {\"epoch\": 22, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.34808430075645447}, {\"epoch\": 23, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.3412390351295471}, {\"epoch\": 24, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.334331750869751}, {\"epoch\": 25, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.3282810151576996}, {\"epoch\": 26, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.3223381042480469}, {\"epoch\": 27, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.3168303072452545}, {\"epoch\": 28, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.31149473786354065}, {\"epoch\": 29, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.3063344657421112}, {\"epoch\": 30, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.30124416947364807}, {\"epoch\": 31, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.2965433895587921}, {\"epoch\": 32, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.2919744849205017}, {\"epoch\": 33, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.2873102128505707}, {\"epoch\": 34, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.28282830119132996}, {\"epoch\": 35, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.27832654118537903}, {\"epoch\": 36, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.2743012607097626}, {\"epoch\": 37, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.27013686299324036}, {\"epoch\": 38, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.2664358615875244}, {\"epoch\": 39, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.2626546323299408}, {\"epoch\": 40, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.2589876055717468}, {\"epoch\": 41, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.25552213191986084}, {\"epoch\": 42, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.25177812576293945}, {\"epoch\": 43, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.24837949872016907}, {\"epoch\": 44, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.244981586933136}, {\"epoch\": 45, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.24158895015716553}, {\"epoch\": 46, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.23855756223201752}, {\"epoch\": 47, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.23521707952022552}, {\"epoch\": 48, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.2321845144033432}, {\"epoch\": 49, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.2293573021888733}, {\"epoch\": 50, \"hidden_nodes\": 64, \"metric\": \"Training Loss\", \"value\": 0.22634874284267426}, {\"epoch\": 1, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7616279721260071}, {\"epoch\": 2, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7334917187690735}, {\"epoch\": 3, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.712988018989563}, {\"epoch\": 4, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7014580368995667}, {\"epoch\": 5, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7013731598854065}, {\"epoch\": 6, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7061264514923096}, {\"epoch\": 7, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7153308987617493}, {\"epoch\": 8, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7281399369239807}, {\"epoch\": 9, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7419678568840027}, {\"epoch\": 10, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7587535977363586}, {\"epoch\": 11, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7756685614585876}, {\"epoch\": 12, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.7942208051681519}, {\"epoch\": 13, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.8141418695449829}, {\"epoch\": 14, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.8344123959541321}, {\"epoch\": 15, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.8540071845054626}, {\"epoch\": 16, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.875331699848175}, {\"epoch\": 17, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.8958901762962341}, {\"epoch\": 18, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.9187065362930298}, {\"epoch\": 19, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.9387652277946472}, {\"epoch\": 20, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.9600296020507812}, {\"epoch\": 21, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 0.9810687303543091}, {\"epoch\": 22, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.003104567527771}, {\"epoch\": 23, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.0253047943115234}, {\"epoch\": 24, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.0479823350906372}, {\"epoch\": 25, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.0703880786895752}, {\"epoch\": 26, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.0943049192428589}, {\"epoch\": 27, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.1187351942062378}, {\"epoch\": 28, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.1427916288375854}, {\"epoch\": 29, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.1655207872390747}, {\"epoch\": 30, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.190499186515808}, {\"epoch\": 31, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.2142692804336548}, {\"epoch\": 32, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.2381631135940552}, {\"epoch\": 33, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.26102876663208}, {\"epoch\": 34, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.2870458364486694}, {\"epoch\": 35, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.3109111785888672}, {\"epoch\": 36, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.3361998796463013}, {\"epoch\": 37, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.3613508939743042}, {\"epoch\": 38, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.3875645399093628}, {\"epoch\": 39, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.4115941524505615}, {\"epoch\": 40, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.4365369081497192}, {\"epoch\": 41, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.4624569416046143}, {\"epoch\": 42, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.4872437715530396}, {\"epoch\": 43, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.5157136917114258}, {\"epoch\": 44, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.540893316268921}, {\"epoch\": 45, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.5654829740524292}, {\"epoch\": 46, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.5912737846374512}, {\"epoch\": 47, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.6175252199172974}, {\"epoch\": 48, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.6435469388961792}, {\"epoch\": 49, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.669816255569458}, {\"epoch\": 50, \"hidden_nodes\": 64, \"metric\": \"Validation Loss\", \"value\": 1.6968984603881836}, {\"epoch\": 1, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.6686967015266418}, {\"epoch\": 2, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.7089259028434753}, {\"epoch\": 3, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.741349458694458}, {\"epoch\": 4, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.7679916024208069}, {\"epoch\": 5, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.7905508279800415}, {\"epoch\": 6, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.8116690516471863}, {\"epoch\": 7, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.8327872157096863}, {\"epoch\": 8, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.8522928357124329}, {\"epoch\": 9, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.8692936897277832}, {\"epoch\": 10, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.8839958310127258}, {\"epoch\": 11, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.8984405994415283}, {\"epoch\": 12, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9102948904037476}, {\"epoch\": 13, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9215144515037537}, {\"epoch\": 14, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9321507811546326}, {\"epoch\": 15, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.940711259841919}, {\"epoch\": 16, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9491001963615417}, {\"epoch\": 17, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9564255475997925}, {\"epoch\": 18, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9624298810958862}, {\"epoch\": 19, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9687430262565613}, {\"epoch\": 20, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9734607338905334}, {\"epoch\": 21, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9777495861053467}, {\"epoch\": 22, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9812835454940796}, {\"epoch\": 23, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9829819202423096}, {\"epoch\": 24, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9845430850982666}, {\"epoch\": 25, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9848175644874573}, {\"epoch\": 26, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9865502119064331}, {\"epoch\": 27, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9863615036010742}, {\"epoch\": 28, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9862414598464966}, {\"epoch\": 29, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9854694604873657}, {\"epoch\": 30, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9875966906547546}, {\"epoch\": 31, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9886431694030762}, {\"epoch\": 32, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9883686900138855}, {\"epoch\": 33, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9874594807624817}, {\"epoch\": 34, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9901185631752014}, {\"epoch\": 35, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9893637299537659}, {\"epoch\": 36, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.989020586013794}, {\"epoch\": 37, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9898097515106201}, {\"epoch\": 38, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9909076690673828}, {\"epoch\": 39, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9902557730674744}, {\"epoch\": 40, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9907189607620239}, {\"epoch\": 41, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9910621047019958}, {\"epoch\": 42, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9915938973426819}, {\"epoch\": 43, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9929834604263306}, {\"epoch\": 44, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9936182498931885}, {\"epoch\": 45, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9937726259231567}, {\"epoch\": 46, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.992520272731781}, {\"epoch\": 47, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9930006265640259}, {\"epoch\": 48, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9943901896476746}, {\"epoch\": 49, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9934981465339661}, {\"epoch\": 50, \"hidden_nodes\": 128, \"metric\": \"Training Accuracy\", \"value\": 0.9950078129768372}, {\"epoch\": 1, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6737751364707947}, {\"epoch\": 2, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6977999806404114}, {\"epoch\": 3, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.7040086388587952}, {\"epoch\": 4, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.7067080736160278}, {\"epoch\": 5, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.7045485377311707}, {\"epoch\": 6, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.7029288411140442}, {\"epoch\": 7, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.7002294659614563}, {\"epoch\": 8, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6949656009674072}, {\"epoch\": 9, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6922661662101746}, {\"epoch\": 10, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6852476596832275}, {\"epoch\": 11, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6806586384773254}, {\"epoch\": 12, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6763395667076111}, {\"epoch\": 13, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.671075701713562}, {\"epoch\": 14, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6664866805076599}, {\"epoch\": 15, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6621676087379456}, {\"epoch\": 16, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6583884358406067}, {\"epoch\": 17, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6542043685913086}, {\"epoch\": 18, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6539344191551208}, {\"epoch\": 19, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6520448327064514}, {\"epoch\": 20, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6539344191551208}, {\"epoch\": 21, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6512349843978882}, {\"epoch\": 22, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6479957103729248}, {\"epoch\": 23, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6466459631919861}, {\"epoch\": 24, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6442164778709412}, {\"epoch\": 25, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6465110182762146}, {\"epoch\": 26, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6439465284347534}, {\"epoch\": 27, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6474558115005493}, {\"epoch\": 28, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6400324106216431}, {\"epoch\": 29, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6398974061012268}, {\"epoch\": 30, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6401673555374146}, {\"epoch\": 31, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6417869925498962}, {\"epoch\": 32, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6461060643196106}, {\"epoch\": 33, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6439465284347534}, {\"epoch\": 34, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6421919465065002}, {\"epoch\": 35, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6443514823913574}, {\"epoch\": 36, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.643136739730835}, {\"epoch\": 37, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6455662250518799}, {\"epoch\": 38, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6394925117492676}, {\"epoch\": 39, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6394925117492676}, {\"epoch\": 40, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6440815329551697}, {\"epoch\": 41, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6382777690887451}, {\"epoch\": 42, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.64070725440979}, {\"epoch\": 43, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6411121487617493}, {\"epoch\": 44, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6361182332038879}, {\"epoch\": 45, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6412471532821655}, {\"epoch\": 46, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.642461895942688}, {\"epoch\": 47, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.642731785774231}, {\"epoch\": 48, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6444864273071289}, {\"epoch\": 49, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6446214318275452}, {\"epoch\": 50, \"hidden_nodes\": 128, \"metric\": \"Validation Accuracy\", \"value\": 0.6462410688400269}, {\"epoch\": 1, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.7721516489982605}, {\"epoch\": 2, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.6971368789672852}, {\"epoch\": 3, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.6301904320716858}, {\"epoch\": 4, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.5751895904541016}, {\"epoch\": 5, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.5256977081298828}, {\"epoch\": 6, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.4792643189430237}, {\"epoch\": 7, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.43588465452194214}, {\"epoch\": 8, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.3956453204154968}, {\"epoch\": 9, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.35875824093818665}, {\"epoch\": 10, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.3253140151500702}, {\"epoch\": 11, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.29425179958343506}, {\"epoch\": 12, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.26628249883651733}, {\"epoch\": 13, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.24097250401973724}, {\"epoch\": 14, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.21732261776924133}, {\"epoch\": 15, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.19588714838027954}, {\"epoch\": 16, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.17629723250865936}, {\"epoch\": 17, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.1581408530473709}, {\"epoch\": 18, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.1410670280456543}, {\"epoch\": 19, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.12576396763324738}, {\"epoch\": 20, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.11200220882892609}, {\"epoch\": 21, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.10011011362075806}, {\"epoch\": 22, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.08924255520105362}, {\"epoch\": 23, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.08146388828754425}, {\"epoch\": 24, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.07492301613092422}, {\"epoch\": 25, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.06956159323453903}, {\"epoch\": 26, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.06284762173891068}, {\"epoch\": 27, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.06180449202656746}, {\"epoch\": 28, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.058580897748470306}, {\"epoch\": 29, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.05688410624861717}, {\"epoch\": 30, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.05224305018782616}, {\"epoch\": 31, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.04905548691749573}, {\"epoch\": 32, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.047087691724300385}, {\"epoch\": 33, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.047602150589227676}, {\"epoch\": 34, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.041222404688596725}, {\"epoch\": 35, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.04266706109046936}, {\"epoch\": 36, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.04127197340130806}, {\"epoch\": 37, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.03851122781634331}, {\"epoch\": 38, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.03651830181479454}, {\"epoch\": 39, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.03683635964989662}, {\"epoch\": 40, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.0354316420853138}, {\"epoch\": 41, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.03317883238196373}, {\"epoch\": 42, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.0313938744366169}, {\"epoch\": 43, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.028213417157530785}, {\"epoch\": 44, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.026934023946523666}, {\"epoch\": 45, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.025929419323801994}, {\"epoch\": 46, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.02844565361738205}, {\"epoch\": 47, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.026675043627619743}, {\"epoch\": 48, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.023333225399255753}, {\"epoch\": 49, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.024543123319745064}, {\"epoch\": 50, \"hidden_nodes\": 128, \"metric\": \"Training Loss\", \"value\": 0.02158191427588463}, {\"epoch\": 1, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.7583159804344177}, {\"epoch\": 2, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.713728666305542}, {\"epoch\": 3, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.6949225664138794}, {\"epoch\": 4, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.6959702968597412}, {\"epoch\": 5, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.7071030735969543}, {\"epoch\": 6, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.7259210348129272}, {\"epoch\": 7, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.7507133483886719}, {\"epoch\": 8, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.7832032442092896}, {\"epoch\": 9, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.8186306953430176}, {\"epoch\": 10, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.8632842302322388}, {\"epoch\": 11, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.912045955657959}, {\"epoch\": 12, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 0.96836256980896}, {\"epoch\": 13, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.0286163091659546}, {\"epoch\": 14, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.0904059410095215}, {\"epoch\": 15, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.163507103919983}, {\"epoch\": 16, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.23127281665802}, {\"epoch\": 17, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.3058054447174072}, {\"epoch\": 18, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.3863179683685303}, {\"epoch\": 19, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.4688749313354492}, {\"epoch\": 20, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.553312063217163}, {\"epoch\": 21, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.6512361764907837}, {\"epoch\": 22, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.727603793144226}, {\"epoch\": 23, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.8334838151931763}, {\"epoch\": 24, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 1.9567668437957764}, {\"epoch\": 25, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.027272939682007}, {\"epoch\": 26, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.120375633239746}, {\"epoch\": 27, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.1626241207122803}, {\"epoch\": 28, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.2463486194610596}, {\"epoch\": 29, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.3326358795166016}, {\"epoch\": 30, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.38527512550354}, {\"epoch\": 31, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.4336366653442383}, {\"epoch\": 32, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.454629421234131}, {\"epoch\": 33, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.534090518951416}, {\"epoch\": 34, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.6000938415527344}, {\"epoch\": 35, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.630399703979492}, {\"epoch\": 36, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.6959266662597656}, {\"epoch\": 37, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.748018503189087}, {\"epoch\": 38, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.8178391456604004}, {\"epoch\": 39, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.841348171234131}, {\"epoch\": 40, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.851717948913574}, {\"epoch\": 41, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.945047616958618}, {\"epoch\": 42, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.95611572265625}, {\"epoch\": 43, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 2.9947543144226074}, {\"epoch\": 44, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 3.0489745140075684}, {\"epoch\": 45, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 3.0760281085968018}, {\"epoch\": 46, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 3.134887456893921}, {\"epoch\": 47, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 3.1801340579986572}, {\"epoch\": 48, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 3.243941068649292}, {\"epoch\": 49, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 3.2370798587799072}, {\"epoch\": 50, \"hidden_nodes\": 128, \"metric\": \"Validation Loss\", \"value\": 3.28098726272583}, {\"epoch\": 1, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.6732257008552551}, {\"epoch\": 2, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.723181962966919}, {\"epoch\": 3, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.7581101655960083}, {\"epoch\": 4, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.7943936586380005}, {\"epoch\": 5, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.8314319252967834}, {\"epoch\": 6, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.8661199808120728}, {\"epoch\": 7, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.8967764973640442}, {\"epoch\": 8, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9222006797790527}, {\"epoch\": 9, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.943095862865448}, {\"epoch\": 10, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9609888195991516}, {\"epoch\": 11, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9737695455551147}, {\"epoch\": 12, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9837195873260498}, {\"epoch\": 13, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9879398345947266}, {\"epoch\": 14, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9854522943496704}, {\"epoch\": 15, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9834280014038086}, {\"epoch\": 16, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9850234389305115}, {\"epoch\": 17, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9863443970680237}, {\"epoch\": 18, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9871335029602051}, {\"epoch\": 19, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9885573983192444}, {\"epoch\": 20, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9901185631752014}, {\"epoch\": 21, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9897239804267883}, {\"epoch\": 22, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9906846880912781}, {\"epoch\": 23, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.990290105342865}, {\"epoch\": 24, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9927089810371399}, {\"epoch\": 25, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9936525225639343}, {\"epoch\": 26, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9929491877555847}, {\"epoch\": 27, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9931378960609436}, {\"epoch\": 28, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9930177927017212}, {\"epoch\": 29, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9949734807014465}, {\"epoch\": 30, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9951107501983643}, {\"epoch\": 31, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9941843748092651}, {\"epoch\": 32, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9953852295875549}, {\"epoch\": 33, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9951621890068054}, {\"epoch\": 34, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9941328763961792}, {\"epoch\": 35, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9958484172821045}, {\"epoch\": 36, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9954195618629456}, {\"epoch\": 37, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9960885643959045}, {\"epoch\": 38, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9967405200004578}, {\"epoch\": 39, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.99466472864151}, {\"epoch\": 40, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9961400628089905}, {\"epoch\": 41, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9959341883659363}, {\"epoch\": 42, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9952822923660278}, {\"epoch\": 43, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9967576265335083}, {\"epoch\": 44, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9965689182281494}, {\"epoch\": 45, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9967233538627625}, {\"epoch\": 46, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9957111477851868}, {\"epoch\": 47, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9956768751144409}, {\"epoch\": 48, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9964831471443176}, {\"epoch\": 49, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9965860843658447}, {\"epoch\": 50, \"hidden_nodes\": 256, \"metric\": \"Training Accuracy\", \"value\": 0.9966890215873718}, {\"epoch\": 1, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6809285879135132}, {\"epoch\": 2, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6975300312042236}, {\"epoch\": 3, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6975300312042236}, {\"epoch\": 4, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6995546221733093}, {\"epoch\": 5, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.69280606508255}, {\"epoch\": 6, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.685787558555603}, {\"epoch\": 7, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6806586384773254}, {\"epoch\": 8, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6760696172714233}, {\"epoch\": 9, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6740450859069824}, {\"epoch\": 10, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6693211197853088}, {\"epoch\": 11, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6631124019622803}, {\"epoch\": 12, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6600080728530884}, {\"epoch\": 13, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6533945202827454}, {\"epoch\": 14, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6540693640708923}, {\"epoch\": 15, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6571736931800842}, {\"epoch\": 16, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6551491618156433}, {\"epoch\": 17, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.649075448513031}, {\"epoch\": 18, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6523147225379944}, {\"epoch\": 19, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6516398787498474}, {\"epoch\": 20, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6532595753669739}, {\"epoch\": 21, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6525846719741821}, {\"epoch\": 22, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6551491618156433}, {\"epoch\": 23, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6493453979492188}, {\"epoch\": 24, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6564988493919373}, {\"epoch\": 25, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.648400604724884}, {\"epoch\": 26, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.656768798828125}, {\"epoch\": 27, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6521797776222229}, {\"epoch\": 28, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6529896259307861}, {\"epoch\": 29, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6521797776222229}, {\"epoch\": 30, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6570387482643127}, {\"epoch\": 31, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6569037437438965}, {\"epoch\": 32, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6479957103729248}, {\"epoch\": 33, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.658118486404419}, {\"epoch\": 34, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6537994146347046}, {\"epoch\": 35, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6543393135070801}, {\"epoch\": 36, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6516398787498474}, {\"epoch\": 37, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6521797776222229}, {\"epoch\": 38, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6598731279373169}, {\"epoch\": 39, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6531245708465576}, {\"epoch\": 40, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6621676087379456}, {\"epoch\": 41, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6606829762458801}, {\"epoch\": 42, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.656768798828125}, {\"epoch\": 43, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6531245708465576}, {\"epoch\": 44, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.655014157295227}, {\"epoch\": 45, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.655689001083374}, {\"epoch\": 46, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6552841067314148}, {\"epoch\": 47, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6516398787498474}, {\"epoch\": 48, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6573086977005005}, {\"epoch\": 49, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6461060643196106}, {\"epoch\": 50, \"hidden_nodes\": 256, \"metric\": \"Validation Accuracy\", \"value\": 0.6543393135070801}, {\"epoch\": 1, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.7646252512931824}, {\"epoch\": 2, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.6694421172142029}, {\"epoch\": 3, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.5951830744743347}, {\"epoch\": 4, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.5195274353027344}, {\"epoch\": 5, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.44180500507354736}, {\"epoch\": 6, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.36787471175193787}, {\"epoch\": 7, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.3018374741077423}, {\"epoch\": 8, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.24397890269756317}, {\"epoch\": 9, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.19423575699329376}, {\"epoch\": 10, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.15114884078502655}, {\"epoch\": 11, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.11516904085874557}, {\"epoch\": 12, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.08685636520385742}, {\"epoch\": 13, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.07039156556129456}, {\"epoch\": 14, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.0668143779039383}, {\"epoch\": 15, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.06412232667207718}, {\"epoch\": 16, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.058777324855327606}, {\"epoch\": 17, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.05251515656709671}, {\"epoch\": 18, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.04914667457342148}, {\"epoch\": 19, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.044747497886419296}, {\"epoch\": 20, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.039500005543231964}, {\"epoch\": 21, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.03928644210100174}, {\"epoch\": 22, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.03668239712715149}, {\"epoch\": 23, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.03659730404615402}, {\"epoch\": 24, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.029814552515745163}, {\"epoch\": 25, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.026221390813589096}, {\"epoch\": 26, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.02775328978896141}, {\"epoch\": 27, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.026109572499990463}, {\"epoch\": 28, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.026986481621861458}, {\"epoch\": 29, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.02064182423055172}, {\"epoch\": 30, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.01988275535404682}, {\"epoch\": 31, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.021075991913676262}, {\"epoch\": 32, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.017689896747469902}, {\"epoch\": 33, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.01879301108419895}, {\"epoch\": 34, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.020344872027635574}, {\"epoch\": 35, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.01696443371474743}, {\"epoch\": 36, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.017423776909708977}, {\"epoch\": 37, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.015560884959995747}, {\"epoch\": 38, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.013258778490126133}, {\"epoch\": 39, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.018034160137176514}, {\"epoch\": 40, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.014336527325212955}, {\"epoch\": 41, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.01486795861274004}, {\"epoch\": 42, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.016722092404961586}, {\"epoch\": 43, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.012573257088661194}, {\"epoch\": 44, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.012883873656392097}, {\"epoch\": 45, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.012285864911973476}, {\"epoch\": 46, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.015385213308036327}, {\"epoch\": 47, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.015170115046203136}, {\"epoch\": 48, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.01193479634821415}, {\"epoch\": 49, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.012771595269441605}, {\"epoch\": 50, \"hidden_nodes\": 256, \"metric\": \"Training Loss\", \"value\": 0.011829840950667858}, {\"epoch\": 1, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 0.7422112822532654}, {\"epoch\": 2, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 0.7025901675224304}, {\"epoch\": 3, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 0.6977611184120178}, {\"epoch\": 4, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 0.7125062346458435}, {\"epoch\": 5, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 0.7474100589752197}, {\"epoch\": 6, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 0.8027748465538025}, {\"epoch\": 7, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 0.8642343282699585}, {\"epoch\": 8, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 0.9393346905708313}, {\"epoch\": 9, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.0289556980133057}, {\"epoch\": 10, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.1413357257843018}, {\"epoch\": 11, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.2549036741256714}, {\"epoch\": 12, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.3847373723983765}, {\"epoch\": 13, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.5605878829956055}, {\"epoch\": 14, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.636232614517212}, {\"epoch\": 15, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.689483880996704}, {\"epoch\": 16, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.7313158512115479}, {\"epoch\": 17, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.8314335346221924}, {\"epoch\": 18, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.8555032014846802}, {\"epoch\": 19, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.895051121711731}, {\"epoch\": 20, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 1.9545406103134155}, {\"epoch\": 21, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.0202412605285645}, {\"epoch\": 22, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.131643533706665}, {\"epoch\": 23, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.1371920108795166}, {\"epoch\": 24, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.2148842811584473}, {\"epoch\": 25, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.2363975048065186}, {\"epoch\": 26, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.2797586917877197}, {\"epoch\": 27, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.3762495517730713}, {\"epoch\": 28, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.4164421558380127}, {\"epoch\": 29, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.4158987998962402}, {\"epoch\": 30, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.4627785682678223}, {\"epoch\": 31, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.5512025356292725}, {\"epoch\": 32, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.5496647357940674}, {\"epoch\": 33, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.6188666820526123}, {\"epoch\": 34, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.6778149604797363}, {\"epoch\": 35, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.6449780464172363}, {\"epoch\": 36, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.7525553703308105}, {\"epoch\": 37, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.8655121326446533}, {\"epoch\": 38, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.856489419937134}, {\"epoch\": 39, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.8987061977386475}, {\"epoch\": 40, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.904024600982666}, {\"epoch\": 41, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.9795186519622803}, {\"epoch\": 42, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.9508790969848633}, {\"epoch\": 43, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 2.991986036300659}, {\"epoch\": 44, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 3.081747531890869}, {\"epoch\": 45, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 3.0769150257110596}, {\"epoch\": 46, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 3.128983736038208}, {\"epoch\": 47, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 3.149599313735962}, {\"epoch\": 48, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 3.1627395153045654}, {\"epoch\": 49, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 3.3426523208618164}, {\"epoch\": 50, \"hidden_nodes\": 256, \"metric\": \"Validation Loss\", \"value\": 3.275512456893921}, {\"epoch\": 1, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.6770513653755188}, {\"epoch\": 2, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.7318625450134277}, {\"epoch\": 3, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.7780618071556091}, {\"epoch\": 4, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.83321613073349}, {\"epoch\": 5, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.8837899565696716}, {\"epoch\": 6, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9254430532455444}, {\"epoch\": 7, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9569573402404785}, {\"epoch\": 8, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9778867959976196}, {\"epoch\": 9, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9861041903495789}, {\"epoch\": 10, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9820041060447693}, {\"epoch\": 11, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9828961491584778}, {\"epoch\": 12, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9869619607925415}, {\"epoch\": 13, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9885402321815491}, {\"epoch\": 14, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9884201884269714}, {\"epoch\": 15, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9904788136482239}, {\"epoch\": 16, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9914737939834595}, {\"epoch\": 17, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9916282296180725}, {\"epoch\": 18, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.992674708366394}, {\"epoch\": 19, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9938583970069885}, {\"epoch\": 20, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9931550621986389}, {\"epoch\": 21, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9925546050071716}, {\"epoch\": 22, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9940127730369568}, {\"epoch\": 23, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9943901896476746}, {\"epoch\": 24, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9943559169769287}, {\"epoch\": 25, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.995196521282196}, {\"epoch\": 26, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9953852295875549}, {\"epoch\": 27, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9950078129768372}, {\"epoch\": 28, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9955396056175232}, {\"epoch\": 29, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9959856867790222}, {\"epoch\": 30, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9959685206413269}, {\"epoch\": 31, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9958484172821045}, {\"epoch\": 32, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9958827495574951}, {\"epoch\": 33, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9965518116950989}, {\"epoch\": 34, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9968262910842896}, {\"epoch\": 35, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9954710006713867}, {\"epoch\": 36, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9972379803657532}, {\"epoch\": 37, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9965518116950989}, {\"epoch\": 38, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9962772727012634}, {\"epoch\": 39, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9972723126411438}, {\"epoch\": 40, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.996894896030426}, {\"epoch\": 41, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9969120621681213}, {\"epoch\": 42, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9967919588088989}, {\"epoch\": 43, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.996208667755127}, {\"epoch\": 44, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9980271458625793}, {\"epoch\": 45, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9969463348388672}, {\"epoch\": 46, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9973924160003662}, {\"epoch\": 47, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9975982308387756}, {\"epoch\": 48, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9984731674194336}, {\"epoch\": 49, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9968777298927307}, {\"epoch\": 50, \"hidden_nodes\": 512, \"metric\": \"Training Accuracy\", \"value\": 0.9975296258926392}, {\"epoch\": 1, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6906465291976929}, {\"epoch\": 2, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.7002294659614563}, {\"epoch\": 3, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.7022539973258972}, {\"epoch\": 4, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6957753896713257}, {\"epoch\": 5, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6905115246772766}, {\"epoch\": 6, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6833580732345581}, {\"epoch\": 7, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.67917400598526}, {\"epoch\": 8, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6731002926826477}, {\"epoch\": 9, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6670265793800354}, {\"epoch\": 10, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6643271446228027}, {\"epoch\": 11, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.665136992931366}, {\"epoch\": 12, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6640572547912598}, {\"epoch\": 13, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6697260141372681}, {\"epoch\": 14, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6618977189064026}, {\"epoch\": 15, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6681063771247864}, {\"epoch\": 16, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6624375581741333}, {\"epoch\": 17, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6618977189064026}, {\"epoch\": 18, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6624375581741333}, {\"epoch\": 19, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6629774570465088}, {\"epoch\": 20, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6652719378471375}, {\"epoch\": 21, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6640572547912598}, {\"epoch\": 22, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6566337943077087}, {\"epoch\": 23, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6529896259307861}, {\"epoch\": 24, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6496153473854065}, {\"epoch\": 25, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6656768918037415}, {\"epoch\": 26, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6571736931800842}, {\"epoch\": 27, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6605479717254639}, {\"epoch\": 28, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6594682335853577}, {\"epoch\": 29, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6658118367195129}, {\"epoch\": 30, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6591982841491699}, {\"epoch\": 31, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.662707507610321}, {\"epoch\": 32, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6671615839004517}, {\"epoch\": 33, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.658118486404419}, {\"epoch\": 34, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6667566299438477}, {\"epoch\": 35, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6621676087379456}, {\"epoch\": 36, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6652719378471375}, {\"epoch\": 37, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.663787305355072}, {\"epoch\": 38, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6602780222892761}, {\"epoch\": 39, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6586583852767944}, {\"epoch\": 40, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6583884358406067}, {\"epoch\": 41, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.658118486404419}, {\"epoch\": 42, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6555540561676025}, {\"epoch\": 43, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.665136992931366}, {\"epoch\": 44, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6617627143859863}, {\"epoch\": 45, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6555540561676025}, {\"epoch\": 46, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6610878705978394}, {\"epoch\": 47, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6597381830215454}, {\"epoch\": 48, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6667566299438477}, {\"epoch\": 49, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6636523008346558}, {\"epoch\": 50, \"hidden_nodes\": 512, \"metric\": \"Validation Accuracy\", \"value\": 0.6636523008346558}, {\"epoch\": 1, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.7594045400619507}, {\"epoch\": 2, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.6503360271453857}, {\"epoch\": 3, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.5521649122238159}, {\"epoch\": 4, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.4379585087299347}, {\"epoch\": 5, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.32784056663513184}, {\"epoch\": 6, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.2335691601037979}, {\"epoch\": 7, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.15726184844970703}, {\"epoch\": 8, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.10121989995241165}, {\"epoch\": 9, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.07222694158554077}, {\"epoch\": 10, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.07121457904577255}, {\"epoch\": 11, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.06331762671470642}, {\"epoch\": 12, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.05109528824687004}, {\"epoch\": 13, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.046328622847795486}, {\"epoch\": 14, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.04345254972577095}, {\"epoch\": 15, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.03735773265361786}, {\"epoch\": 16, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.03462617099285126}, {\"epoch\": 17, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.03155355900526047}, {\"epoch\": 18, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.028191018849611282}, {\"epoch\": 19, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.02510366030037403}, {\"epoch\": 20, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.026934897527098656}, {\"epoch\": 21, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.026940204203128815}, {\"epoch\": 22, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.02345561422407627}, {\"epoch\": 23, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.02159281261265278}, {\"epoch\": 24, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.021799780428409576}, {\"epoch\": 25, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.01859184354543686}, {\"epoch\": 26, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.0176762193441391}, {\"epoch\": 27, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.018309827893972397}, {\"epoch\": 28, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.01711449585855007}, {\"epoch\": 29, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.016276946291327477}, {\"epoch\": 30, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.015507722273468971}, {\"epoch\": 31, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.015295127406716347}, {\"epoch\": 32, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.015369383618235588}, {\"epoch\": 33, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.013314541429281235}, {\"epoch\": 34, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.012286121025681496}, {\"epoch\": 35, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.015911424532532692}, {\"epoch\": 36, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.011165070347487926}, {\"epoch\": 37, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.012475456111133099}, {\"epoch\": 38, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.012902569025754929}, {\"epoch\": 39, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.010571013204753399}, {\"epoch\": 40, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.010959647595882416}, {\"epoch\": 41, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.01104798074811697}, {\"epoch\": 42, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.011311889626085758}, {\"epoch\": 43, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.01187147106975317}, {\"epoch\": 44, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.007397700101137161}, {\"epoch\": 45, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.010800046846270561}, {\"epoch\": 46, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.009994971565902233}, {\"epoch\": 47, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.008560891263186932}, {\"epoch\": 48, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.0059838374145329}, {\"epoch\": 49, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.010377219878137112}, {\"epoch\": 50, \"hidden_nodes\": 512, \"metric\": \"Training Loss\", \"value\": 0.009090300649404526}, {\"epoch\": 1, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 0.7277725338935852}, {\"epoch\": 2, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 0.6946316361427307}, {\"epoch\": 3, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 0.7006565928459167}, {\"epoch\": 4, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 0.7365196347236633}, {\"epoch\": 5, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 0.8052339553833008}, {\"epoch\": 6, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 0.900431752204895}, {\"epoch\": 7, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.0206611156463623}, {\"epoch\": 8, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.1626626253128052}, {\"epoch\": 9, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.3447576761245728}, {\"epoch\": 10, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.4647787809371948}, {\"epoch\": 11, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.5475958585739136}, {\"epoch\": 12, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.6223876476287842}, {\"epoch\": 13, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.6439015865325928}, {\"epoch\": 14, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.7725175619125366}, {\"epoch\": 15, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.7910228967666626}, {\"epoch\": 16, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.860826015472412}, {\"epoch\": 17, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.8733857870101929}, {\"epoch\": 18, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 1.9931877851486206}, {\"epoch\": 19, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.071056365966797}, {\"epoch\": 20, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.12674617767334}, {\"epoch\": 21, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.134641170501709}, {\"epoch\": 22, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.2462263107299805}, {\"epoch\": 23, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.2583181858062744}, {\"epoch\": 24, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.3278698921203613}, {\"epoch\": 25, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.2755284309387207}, {\"epoch\": 26, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.339644432067871}, {\"epoch\": 27, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.3904361724853516}, {\"epoch\": 28, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.400322437286377}, {\"epoch\": 29, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.4407169818878174}, {\"epoch\": 30, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.5055854320526123}, {\"epoch\": 31, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.576942205429077}, {\"epoch\": 32, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.602173328399658}, {\"epoch\": 33, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.6677372455596924}, {\"epoch\": 34, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.6885693073272705}, {\"epoch\": 35, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.763108015060425}, {\"epoch\": 36, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.839164972305298}, {\"epoch\": 37, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.8580410480499268}, {\"epoch\": 38, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.8700640201568604}, {\"epoch\": 39, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.958585023880005}, {\"epoch\": 40, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.9293837547302246}, {\"epoch\": 41, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.9642934799194336}, {\"epoch\": 42, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 3.006643056869507}, {\"epoch\": 43, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.9742417335510254}, {\"epoch\": 44, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 2.969259262084961}, {\"epoch\": 45, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 3.025883674621582}, {\"epoch\": 46, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 3.118079423904419}, {\"epoch\": 47, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 3.2023839950561523}, {\"epoch\": 48, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 3.182852268218994}, {\"epoch\": 49, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 3.208178758621216}, {\"epoch\": 50, \"hidden_nodes\": 512, \"metric\": \"Validation Loss\", \"value\": 3.2646918296813965}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# List of node counts to test\n",
    "nodes_list = [8, 16, 32, 64, 128, 256, 512]\n",
    "\n",
    "# Prepare a DataFrame to collect all metrics for plotting\n",
    "df_all_models = pd.DataFrame()\n",
    "\n",
    "for nodes in nodes_list:\n",
    "    print(f\"\\nTraining model with {nodes} hidden nodes:\")\n",
    "    \n",
    "    # Define the model architecture\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=(462,)),\n",
    "        Dense(nodes, activation='relu'),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': range(1, 51),\n",
    "        'training_accuracy': history.history['accuracy'],\n",
    "        'validation_accuracy': history.history['val_accuracy'],\n",
    "        'training_loss': history.history['loss'],\n",
    "        'validation_loss': history.history['val_loss'],\n",
    "        'hidden_nodes': [nodes] * 50\n",
    "    })\n",
    "    \n",
    "    # Melt the dataframe for long format\n",
    "    df_long = df.melt(id_vars=['epoch', 'hidden_nodes'], \n",
    "                      value_vars=['training_accuracy', 'validation_accuracy', 'training_loss', 'validation_loss'],\n",
    "                      var_name='metric', value_name='value')\n",
    "    \n",
    "    # Concatenate all data\n",
    "    df_all_models = pd.concat([df_all_models, df_long], ignore_index=True)\n",
    "\n",
    "# Plotting with Altair\n",
    "\n",
    "# Define the color mapping for metrics\n",
    "color_mapping = {\n",
    "    'training_accuracy': 'Training Accuracy',\n",
    "    'validation_accuracy': 'Validation Accuracy',\n",
    "    'training_loss': 'Training Loss',\n",
    "    'validation_loss': 'Validation Loss'\n",
    "}\n",
    "\n",
    "df_all_models['metric'] = df_all_models['metric'].map(color_mapping)\n",
    "\n",
    "# Altair plot: Interactive plot for all models\n",
    "chart = alt.Chart(df_all_models).mark_line().encode(\n",
    "    x='epoch',\n",
    "    y='value',\n",
    "    color='metric',\n",
    "    column='hidden_nodes:O',  # Separate charts for each node configuration\n",
    "    tooltip=['epoch', 'value', 'metric', 'hidden_nodes']\n",
    ").properties(\n",
    "    title=\"Model Performance: Accuracy & Loss for Different Hidden Node Configurations\",\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "chart.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the graphs provided in the cells above, we can determine the optimal number of epochs by observing the point at which the validation loss starts to increase while the training loss continues to decrease. This is an indication of overfitting, where the model is learning the training data too well but is not generalizing to the validation data.\n",
    "\n",
    "\n",
    "### Optimal Number of Epochs:\n",
    "From the graphs, we can observe that the validation loss starts to increase around epoch 20-25, while the training loss continues to decrease. This indicates that the model begins to overfit the training data after this point. Therefore, the optimal number of epochs for this network configuration is around **20-25 epochs**. \n",
    "\n",
    "Training the model for more than 25 epochs would likely result in overfitting, where the model performs well on the training data but poorly on the validation data. Hence, stopping the training around 20-25 epochs would provide a good balance between underfitting and overfitting, ensuring better generalization to unseen data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - **Varying the number of layers**.\n",
    "\n",
    "        - Conduct similar experiments as described above, but this time vary the number of layers from 1 to 4. Document your findings.\n",
    "\n",
    "        - How many nodes should each layer contain? Test at least two scenarios. Traditionally, a common strategy involved decreasing the number of nodes from the input layer to the output layer, often by halving, to create a pyramid-like structure. However, recent experience suggests that maintaining a constant number of nodes across all layers can perform equally well. Describe your observations. It is acceptable if both strategies yield similar performance results.\n",
    "\n",
    "        - Select one your models that exemplifies overfitting. In our experiments, we easily constructed a model achieving nearly 100% accuracy on the training data, yet showing no similar improvement on the validation set. Present this neural network along with its accuracy and loss graphs. Explain the reasoning for concluding that the model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 1 hidden layers:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 2 hidden layers:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 3 hidden layers:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 4 hidden layers:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-72a43bb13ad24121ac0bbeb7ca8ed92c.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-72a43bb13ad24121ac0bbeb7ca8ed92c.vega-embed details,\n",
       "  #altair-viz-72a43bb13ad24121ac0bbeb7ca8ed92c.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-72a43bb13ad24121ac0bbeb7ca8ed92c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-72a43bb13ad24121ac0bbeb7ca8ed92c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-72a43bb13ad24121ac0bbeb7ca8ed92c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-05c44f8305ed92a3c53fcc3df68f62cd\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"column\": {\"field\": \"num_layers\", \"type\": \"ordinal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}, {\"field\": \"num_layers\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Model Performance: Accuracy & Loss for Different Layer Configurations\", \"width\": 300, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-05c44f8305ed92a3c53fcc3df68f62cd\": [{\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.6669811606407166}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7041052579879761}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7324458360671997}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7581273317337036}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7808409333229065}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8026968240737915}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8245012164115906}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8438009023666382}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8609047532081604}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8759328126907349}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8906177878379822}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9030210375785828}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9139661192893982}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.924207866191864}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9333173036575317}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9410200715065002}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.949700653553009}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9566828608512878}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9634420275688171}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9697723388671875}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9743699431419373}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9789847731590271}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9817810654640198}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9832049608230591}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9850577116012573}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9857611060142517}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9855895638465881}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9857611060142517}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9860012531280518}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9855037927627563}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9869276285171509}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9853836894035339}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9878883361816406}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9880427718162537}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9878883361816406}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9882143139839172}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9904788136482239}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9888147115707397}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.989466667175293}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9907704591751099}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9917997717857361}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9906503558158875}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9894495010375977}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9906675219535828}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9927775859832764}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9899812936782837}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9920914173126221}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.991936981678009}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9930863976478577}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9921771883964539}, {\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6725603938102722}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6884869933128357}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6967201828956604}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6964502334594727}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6945606470108032}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6945606470108032}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.69280606508255}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6892967820167542}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6840329170227051}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6809285879135132}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6756647229194641}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6683763265609741}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6613578200340271}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6559589505195618}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6527196764945984}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6506950855255127}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6500202417373657}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6447563767433167}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6411121487617493}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6378728747367859}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6386826634407043}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6363881826400757}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6359832882881165}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6385477185249329}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6374679207801819}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6357133388519287}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6363881826400757}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6357133388519287}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6377378702163696}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6332838535308838}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6293696761131287}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6362531781196594}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6358482837677002}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6334187984466553}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6323390603065491}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6335538029670715}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6317991614341736}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6320691108703613}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6323390603065491}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6326090097427368}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6362531781196594}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6397624611854553}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6398974061012268}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6355783343315125}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6367930769920349}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6361182332038879}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6370630264282227}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6322040557861328}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6273451447486877}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6313942670822144}, {\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.7737741470336914}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.7073349952697754}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.6477581262588501}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.5941464900970459}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.5464853048324585}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.5003571510314941}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.45644792914390564}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.4154726266860962}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.37753862142562866}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.34300997853279114}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.31174683570861816}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2836190462112427}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2581466734409332}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.23461785912513733}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2128930538892746}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.1929132044315338}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.17412075400352478}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.156961590051651}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.14097583293914795}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.1255445033311844}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.11198679357767105}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.09966567903757095}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.09038028866052628}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.08197140693664551}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.07487547397613525}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.06919419765472412}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.06639141589403152}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.06325171887874603}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.05924138054251671}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.05787402391433716}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.05358821153640747}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.055583346635103226}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.04891030862927437}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.04755863547325134}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.04586705192923546}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.04445522278547287}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.03920723497867584}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.042593516409397125}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.040538299828767776}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.03689854219555855}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.03313547372817993}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.03553707152605057}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.03708368539810181}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.03351626917719841}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.02947012148797512}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.03350909799337387}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.029461167752742767}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.029442816972732544}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.026187937706708908}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.02787499874830246}, {\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7615562677383423}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7260918617248535}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.703908383846283}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7003594040870667}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7087894678115845}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7263199090957642}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7522754073143005}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7858427166938782}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.8248685598373413}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.8699976205825806}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.9208089113235474}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.9823970794677734}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.0469145774841309}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.1162405014038086}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.187188982963562}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.254825234413147}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.3261746168136597}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.4012876749038696}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.480433702468872}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.5627477169036865}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.6352521181106567}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.7285321950912476}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.8227260112762451}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.8768559694290161}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.9682984352111816}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.0428478717803955}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.1334173679351807}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.208115816116333}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.3216700553894043}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.3488054275512695}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.4139175415039062}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.4028584957122803}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.4882473945617676}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.520723819732666}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.587817907333374}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.6587743759155273}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.6960501670837402}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.7312848567962646}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.7889673709869385}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.8278164863586426}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.9254119396209717}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.0066747665405273}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.022803544998169}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.050104856491089}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.0836422443389893}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.1495823860168457}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.178532123565674}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.2123301029205322}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.3026206493377686}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.3555450439453125}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.6693485975265503}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7188588380813599}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7566348314285278}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7904307842254639}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8220823407173157}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8481583595275879}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8710092306137085}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8902060389518738}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9046679735183716}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9136916399002075}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9245166778564453}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9330256581306458}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9380521774291992}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9455490708351135}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.951536238193512}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9544869661331177}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9567686319351196}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9604912996292114}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9669074416160583}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9672333598136902}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9673534631729126}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.973048985004425}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9724314212799072}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9727059006690979}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9769775867462158}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9778181910514832}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9779554009437561}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9793450236320496}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9796195030212402}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9801856279373169}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9814894199371338}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9798082113265991}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9819526076316833}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9828618764877319}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9842342734336853}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.982810378074646}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9847317934036255}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.984800398349762}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9858640432357788}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9844573140144348}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9847317934036255}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9875452518463135}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9869619607925415}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9861556887626648}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9874251484870911}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.988008439540863}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.987322211265564}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9875280857086182}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9885745644569397}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9878368973731995}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6830881237983704}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.7002294659614563}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6999595165252686}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6899716854095459}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6834930777549744}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6708057522773743}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6602780222892761}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6540693640708923}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6470508575439453}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6457011699676514}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6405722498893738}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6359832882881165}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6350384950637817}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.635443389415741}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6247806549072266}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6254554986953735}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6308543682098389}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6285598874092102}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6278849840164185}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6268052458763123}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6309893131256104}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6292347311973572}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6288297772407532}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6289647817611694}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6295046806335449}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.63436359167099}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.63436359167099}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.633688747882843}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6288297772407532}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6326090097427368}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6322040557861328}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6339586973190308}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6371980309486389}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6285598874092102}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6355783343315125}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6339586973190308}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6307194232940674}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6349034905433655}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6366581320762634}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6346335411071777}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6385477185249329}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6339586973190308}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6389526128768921}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6392225623130798}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6403023600578308}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6403023600578308}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6335538029670715}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6261304020881653}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6295046806335449}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6300445199012756}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.7683777809143066}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.6730860471725464}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.5896040201187134}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.518327534198761}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.4528004825115204}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.3926074206829071}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.3398726284503937}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.29252728819847107}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.2543375492095947}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.2293446809053421}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.20260296761989594}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.18126343190670013}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.16481338441371918}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.14632157981395721}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.1308431774377823}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.12364502996206284}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.11458288878202438}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.10901413857936859}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.09189525991678238}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.09157925844192505}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.09024889022111893}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.07705654948949814}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.07558972388505936}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.07584106922149658}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.06501848250627518}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.06229836121201515}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.06282387673854828}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.06058682128787041}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.058055583387613297}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.05532949045300484}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.05301540344953537}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.05732778087258339}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.05078091844916344}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.05009860545396805}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.04676136001944542}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.050993066281080246}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.04554131627082825}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.04444490745663643}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.03983232006430626}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.04502606764435768}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.043809741735458374}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.03630068525671959}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.03884505480527878}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.04105006530880928}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.036992672830820084}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.0342656709253788}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.037391118705272675}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.037768129259347916}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.03462415188550949}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.035931967198848724}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7467659711837769}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7050533294677734}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7173893451690674}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7571790218353271}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.8183013796806335}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.9091962575912476}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.032072901725769}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.1517705917358398}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.2718948125839233}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.4045792818069458}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.4998531341552734}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.5904890298843384}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.679990530014038}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.7835482358932495}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.915513515472412}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.0459978580474854}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.1380789279937744}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.151412010192871}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.2568137645721436}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.4129409790039062}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.496654987335205}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.5960288047790527}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.6527888774871826}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.716108560562134}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.8097121715545654}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.8690361976623535}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.861954689025879}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.060051202774048}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.1643526554107666}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.1698031425476074}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.3069632053375244}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.299884796142578}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.276113510131836}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.3850791454315186}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.508960008621216}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.594029664993286}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.5863001346588135}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.568760871887207}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.710500478744507}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.7861790657043457}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.7621634006500244}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.9269402027130127}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.8941564559936523}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.8917572498321533}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 4.056540489196777}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 4.043506145477295}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.99741268157959}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 4.074660778045654}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 4.214831829071045}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 4.167027950286865}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.6678904294967651}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7216379642486572}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7584018111228943}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7947195768356323}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8265770077705383}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8539740443229675}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8744059801101685}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8884904980659485}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9030382037162781}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9130740761756897}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9226124286651611}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9305724501609802}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9342436790466309}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9423410296440125}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9469043016433716}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.950421154499054}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9529086947441101}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9581239223480225}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9603712558746338}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9629102349281311}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9660153388977051}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9690690040588379}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.969703733921051}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9714364409446716}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9718138575553894}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9738038182258606}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9760854840278625}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9740611910820007}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9776466488838196}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9787960648536682}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9774922132492065}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9796195030212402}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9803057312965393}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9809747934341431}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9808546900749207}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9823986291885376}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9821756482124329}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9835652112960815}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9832392930984497}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9835652112960815}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9840455651283264}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9852979183197021}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9854008555412292}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.985194981098175}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9860870242118835}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.986207127571106}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9876653552055359}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9864644408226013}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9863615036010742}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.988437294960022}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.687137246131897}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6994196176528931}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6960453391075134}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6870023012161255}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6776893138885498}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6722904443740845}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6667566299438477}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6609528660774231}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6525846719741821}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6493453979492188}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6439465284347534}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6386826634407043}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.634768545627594}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6416520476341248}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.63436359167099}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6362531781196594}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6309893131256104}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6235659122467041}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.635443389415741}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6311243176460266}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6255905032157898}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.634768545627594}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6290997266769409}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6188419461250305}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6199217438697815}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6257254481315613}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6296396255493164}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6237009167671204}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6322040557861328}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6285598874092102}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6320691108703613}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6299095749855042}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6304494738578796}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6230260729789734}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6249156594276428}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6270751953125}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6328789591789246}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.626670241355896}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6280199885368347}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6258604526519775}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6285598874092102}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6274800896644592}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6288297772407532}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6282899379730225}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6386826634407043}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6385477185249329}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6397624611854553}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6324740052223206}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6363881826400757}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6411121487617493}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.7672404646873474}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.6654812693595886}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.5841350555419922}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.5063485503196716}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.435070276260376}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.3729412257671356}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.3240203857421875}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.2882672846317291}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.24952548742294312}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.22615621984004974}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.20347802340984344}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.18316152691841125}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.17100024223327637}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.15218649804592133}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.13888312876224518}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.12836581468582153}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.12375450134277344}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.11262425780296326}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.10596975684165955}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.09876493364572525}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.09224053472280502}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.08593607693910599}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.0832267627120018}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.07712545990943909}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.07777556777000427}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.07335272431373596}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.06819681078195572}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.07105148583650589}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.06177757307887077}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.05832831189036369}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.06131434440612793}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.05695373937487602}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.05547719821333885}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.05294344201683998}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.0524173341691494}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.04904764145612717}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.04928780719637871}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.046391334384679794}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.04823870584368706}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.045542825013399124}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.045555438846349716}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.04257280007004738}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.04261918365955353}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.041003838181495667}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.040278978645801544}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.04040322080254555}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.036075737327337265}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.04020491614937782}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.03816909343004227}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.03277217224240303}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7382075786590576}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7075186967849731}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7210858464241028}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7821958661079407}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.8669819831848145}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.9915844202041626}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.1219381093978882}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.232477068901062}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.3698190450668335}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.4753530025482178}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.6361757516860962}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.7982370853424072}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.8229215145111084}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.9230538606643677}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.013411521911621}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.164606809616089}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.259782075881958}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.378319025039673}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.4163320064544678}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.523270845413208}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.58528995513916}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.6947312355041504}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.8558645248413086}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.8211770057678223}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.8389065265655518}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.81843900680542}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.948789358139038}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.911371946334839}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.0604281425476074}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.214564323425293}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.060042142868042}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.221067190170288}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.3174264430999756}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.265615940093994}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.3531434535980225}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.5378808975219727}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.5241432189941406}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.6550772190093994}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.434319496154785}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.623065710067749}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.5722436904907227}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.5907459259033203}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.668025493621826}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.7285594940185547}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.793323516845703}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.9630260467529297}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.916503667831421}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.8525795936584473}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.813915729522705}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.964139699935913}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.6686967015266418}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7220668792724609}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7582302689552307}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7915802001953125}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8205897808074951}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8460825681686401}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8661543130874634}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.880942165851593}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8933454751968384}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9037758708000183}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9127309322357178}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9211542010307312}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9288226366043091}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9353073239326477}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9394932389259338}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9444682598114014}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9499408006668091}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9524626731872559}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9569401741027832}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9593076109886169}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9620181322097778}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9641454219818115}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9655006527900696}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9696522355079651}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9706987142562866}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9712305665016174}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9727402329444885}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9741641283035278}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9755365252494812}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9766859412193298}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9772005677223206}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9776294827461243}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9794822335243225}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9784529209136963}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9799111485481262}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.980134129524231}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9809918999671936}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.981695294380188}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9826216697692871}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9832049608230591}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9837195873260498}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.983685314655304}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9838911890983582}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9844058156013489}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9857267737388611}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9860870242118835}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9857096076011658}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9861899614334106}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9861385226249695}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9867732524871826}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6901066303253174}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6980699300765991}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6977999806404114}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6872722506523132}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6803886890411377}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6752598285675049}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6662167906761169}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6654069423675537}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6552841067314148}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6535294651985168}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.656093955039978}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6528546214103699}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6517748832702637}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6524497270584106}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6428667902946472}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6362531781196594}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6417869925498962}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6342286467552185}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.633013904094696}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6273451447486877}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6351734399795532}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6219462752342224}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6303144693374634}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6242408156394958}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6304494738578796}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6374679207801819}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6359832882881165}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.635443389415741}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6288297772407532}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6296396255493164}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6371980309486389}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6312592625617981}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6290997266769409}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6346335411071777}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.633688747882843}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6319341063499451}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6258604526519775}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6327439546585083}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6305844187736511}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6365231275558472}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6303144693374634}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6323390603065491}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.625320553779602}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6285598874092102}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6257254481315613}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6320691108703613}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6274800896644592}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6295046806335449}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6367930769920349}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.633688747882843}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.7703508138656616}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.6680019497871399}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.5875831246376038}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.5135584473609924}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.44937920570373535}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.39446908235549927}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.34748342633247375}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.31114134192466736}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.27759498357772827}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.2527403235435486}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.229141503572464}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.21024172008037567}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.18873952329158783}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.174233078956604}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.15958566963672638}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.14763402938842773}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.13566750288009644}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.12848380208015442}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.11750226467847824}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.10928899794816971}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.10273517668247223}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.09741302579641342}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.09327175468206406}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.08495815843343735}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.08168063312768936}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.07840470224618912}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.07326164096593857}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.07226920872926712}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.06677639484405518}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.06635499745607376}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.06172683835029602}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.060881663113832474}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.05720217898488045}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.05852712318301201}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.05490930750966072}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.055807940661907196}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.05327688157558441}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.05140596255660057}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04929475113749504}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.048784106969833374}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04653867334127426}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04597558081150055}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.045716848224401474}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04502217844128609}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.041377533227205276}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.03991017863154411}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04170684888958931}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.039681531488895416}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04039648920297623}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.0389028862118721}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7440981864929199}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7116943001747131}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7283316254615784}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7811347246170044}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.8410692811012268}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.9180079698562622}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.027114987373352}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.0781201124191284}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.1829231977462769}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.2725447416305542}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.3966821432113647}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.4605069160461426}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.5501151084899902}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.583695411682129}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.8462228775024414}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.8576922416687012}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.9525398015975952}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.174635410308838}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.144367218017578}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.292349338531494}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.434978485107422}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.434119462966919}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.5136327743530273}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.6414177417755127}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.683717727661133}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.688960313796997}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.7522871494293213}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.751446485519409}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.9515042304992676}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.8754379749298096}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.991161823272705}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.932603597640991}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.136481285095215}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.1458847522735596}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.2047927379608154}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.2747936248779297}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.3306961059570312}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.194099187850952}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.3469507694244385}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.19091796875}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.4494435787200928}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.252746105194092}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.2357521057128906}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.369717836380005}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.5733346939086914}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.586698055267334}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.520002603530884}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.5732100009918213}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.4090116024017334}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.498236656188965}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to build model with a given number of layers and nodes\n",
    "def build_model(num_layers, nodes_per_layer):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(462,)))\n",
    "    for _ in range(num_layers):\n",
    "        model.add(Dense(nodes_per_layer, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Number of layers to test\n",
    "layers_list = [1, 2, 3, 4]\n",
    "nodes_per_layer = 128  # You can adjust this value\n",
    "\n",
    "# Prepare a DataFrame to collect all metrics for plotting\n",
    "df_all_models = pd.DataFrame()\n",
    "\n",
    "for num_layers in layers_list:\n",
    "    print(f\"\\nTraining model with {num_layers} hidden layers:\")\n",
    "    model = build_model(num_layers, nodes_per_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': range(1, 51),\n",
    "        'training_accuracy': history.history['accuracy'],\n",
    "        'validation_accuracy': history.history['val_accuracy'],\n",
    "        'training_loss': history.history['loss'],\n",
    "        'validation_loss': history.history['val_loss'],\n",
    "        'num_layers': [num_layers] * 50\n",
    "    })\n",
    "    \n",
    "    # Melt the dataframe for long format\n",
    "    df_long = df.melt(id_vars=['epoch', 'num_layers'], \n",
    "                      value_vars=['training_accuracy', 'validation_accuracy', 'training_loss', 'validation_loss'],\n",
    "                      var_name='metric', value_name='value')\n",
    "    \n",
    "    # Concatenate all data\n",
    "    df_all_models = pd.concat([df_all_models, df_long], ignore_index=True)\n",
    "\n",
    "# Plotting with Altair\n",
    "\n",
    "# Define the color mapping for metrics\n",
    "color_mapping = {\n",
    "    'training_accuracy': 'Training Accuracy',\n",
    "    'validation_accuracy': 'Validation Accuracy',\n",
    "    'training_loss': 'Training Loss',\n",
    "    'validation_loss': 'Validation Loss'\n",
    "}\n",
    "\n",
    "df_all_models['metric'] = df_all_models['metric'].map(color_mapping)\n",
    "\n",
    "# Altair plot: Interactive plot for all models\n",
    "chart = alt.Chart(df_all_models).mark_line().encode(\n",
    "    x='epoch',\n",
    "    y='value',\n",
    "    color='metric',\n",
    "    column='num_layers:O',  # Separate charts for each layer configuration\n",
    "    tooltip=['epoch', 'value', 'metric', 'num_layers']\n",
    ").properties(\n",
    "    title=\"Model Performance: Accuracy & Loss for Different Layer Configurations\",\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "chart.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we explore the impact of varying the number of nodes in the hidden layer on the performance of our neural network model. We start with a single node and progressively increase the number of nodes till 4 to observe how it affects the training and validation accuracy and loss.\n",
    "\n",
    "From the graphs, we can clearly notice that increasing the number of hidden nodes to 2 and 4 improves the model's ability to learn the relationships in the data, leading to better accuracy on both the training and validation sets. This indicates that a more complex model with more hidden nodes can capture the underlying patterns in the data more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the scenario where we have constant nodes per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Constant Nodes per Layer:\n",
      "\n",
      "Training model with 1 layers of 64 nodes each\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 2 layers of 64 nodes each\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 3 layers of 64 nodes each\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 4 layers of 64 nodes each\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d4c684d3aa1943b4972a63cd8e033fec.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d4c684d3aa1943b4972a63cd8e033fec.vega-embed details,\n",
       "  #altair-viz-d4c684d3aa1943b4972a63cd8e033fec.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d4c684d3aa1943b4972a63cd8e033fec\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d4c684d3aa1943b4972a63cd8e033fec\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d4c684d3aa1943b4972a63cd8e033fec\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-c09366a31f81fba97a3c120005672055\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"column\": {\"field\": \"num_layers\", \"type\": \"ordinal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}, {\"field\": \"num_layers\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Model Performance: Accuracy & Loss for Different Layer Configurations\", \"width\": 300, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-c09366a31f81fba97a3c120005672055\": [{\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.6648882627487183}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.6973289251327515}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7210375666618347}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7429448962211609}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7583674788475037}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7697071433067322}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7823505997657776}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7942907214164734}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8038976788520813}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8128527402877808}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8206755518913269}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8275719881057739}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8336278200149536}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8389803171157837}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8445042967796326}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8494278788566589}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8540769815444946}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8586059808731079}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8625001907348633}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8651936054229736}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8689677715301514}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8712494373321533}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8749035000801086}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8778542280197144}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8805647492408752}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8831894993782043}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.886328935623169}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8884733319282532}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8911152482032776}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8934826850891113}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8948208093643188}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8963990807533264}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8984748721122742}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9006707668304443}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9023348093032837}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9039645791053772}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9063835144042969}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9085279107093811}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9104321599006653}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9119074940681458}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9132456183433533}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9150983691215515}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.916144847869873}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.917019784450531}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9181692004203796}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.919541597366333}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9208453893661499}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9217889308929443}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9234873056411743}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9241220951080322}, {\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6695910096168518}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6865974068641663}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6973950862884521}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.7040086388587952}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.7057632803916931}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.7048184871673584}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.7019840478897095}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.7010392546653748}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6965852379798889}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.692401111125946}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6886219382286072}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.687542200088501}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6814684867858887}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6814684867858887}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6802537441253662}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.678769052028656}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6736401915550232}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6699959635734558}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6674314737319946}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6662167906761169}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.664462149143219}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6609528660774231}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.658118486404419}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6566337943077087}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6555540561676025}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6547442078590393}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.655419111251831}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6525846719741821}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6525846719741821}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6512349843978882}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6512349843978882}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6488054990768433}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6481306552886963}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6457011699676514}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6455662250518799}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6439465284347534}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6451612710952759}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6434066891670227}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6412471532821655}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6415171027183533}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6409772038459778}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6401673555374146}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6385477185249329}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6393575668334961}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6388176679611206}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6382777690887451}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6381428241729736}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6376029253005981}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6393575668334961}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6392225623130798}, {\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.7789497375488281}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.7195788025856018}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.6717644929885864}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.6292609572410583}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.5965563058853149}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.5687807202339172}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.5432043075561523}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.5194015502929688}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.49772778153419495}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.4778365194797516}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.459911972284317}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.44404515624046326}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.42918410897254944}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.415968120098114}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.40385565161705017}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.3930025100708008}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.38292965292930603}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.37356090545654297}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.3648415803909302}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.35683590173721313}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.3492167592048645}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.3422660529613495}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.3354198932647705}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.3289877474308014}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.322826623916626}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.3169987201690674}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.3114047050476074}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.30622392892837524}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.3010219633579254}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2958751320838928}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2911665141582489}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.28659582138061523}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.28219181299209595}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.27794522047042847}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2737607955932617}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.26992473006248474}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.26600706577301025}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2624795436859131}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.25873228907585144}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.25526052713394165}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2519901394844055}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.24850283563137054}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.24513891339302063}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2417488992214203}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2389402538537979}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2355910837650299}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2326074242591858}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.22959782183170319}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2265874296426773}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2239844799041748}, {\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7665110230445862}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7386471033096313}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.713250994682312}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7012457251548767}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7001247406005859}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7045597434043884}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7131474018096924}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7237776517868042}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.737869143486023}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.753731906414032}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.770656406879425}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7905839085578918}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.8125678896903992}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.8340858221054077}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.8544954657554626}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.8768554925918579}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.8992214798927307}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.922339141368866}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.9448603391647339}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.9668652415275574}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.9899076223373413}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.0137606859207153}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.0362268686294556}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.0592138767242432}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.0809279680252075}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.1053837537765503}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.1300711631774902}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.1535513401031494}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.1792248487472534}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.204280138015747}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.2283310890197754}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.253651738166809}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.2772252559661865}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.3039301633834839}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.3282544612884521}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.3527979850769043}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.3778795003890991}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.4029028415679932}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.4288215637207031}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.4531301259994507}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.4767804145812988}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.5009733438491821}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.528048038482666}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.5527487993240356}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.5789302587509155}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.6035665273666382}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.629749059677124}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.6548619270324707}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.678971767425537}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.7067331075668335}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.6662778258323669}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7032303214073181}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7342128157615662}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7556569576263428}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7733269333839417}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7865365147590637}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7994887828826904}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8110343217849731}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8221509456634521}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8318951725959778}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.839666485786438}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8470261096954346}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8548489212989807}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8622085452079773}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8691736459732056}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.87351393699646}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8799471855163574}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8852310180664062}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8900344967842102}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8945119976997375}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8980288505554199}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9025406837463379}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9046679735183716}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9079789519309998}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9114099740982056}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9155615568161011}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9162306189537048}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9202621579170227}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9222006797790527}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.924345076084137}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9269698858261108}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9284108877182007}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.932219386100769}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9350671768188477}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9340206980705261}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9358906149864197}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9395790100097656}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9386698007583618}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.941826343536377}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9439707398414612}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9440394043922424}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9431816339492798}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9461838006973267}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9484997391700745}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9501123428344727}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9488943219184875}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9506098628044128}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.952273964881897}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9529944658279419}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9520680904388428}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6755297780036926}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6925361156463623}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6987447738647461}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6982048749923706}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6957753896713257}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6907814741134644}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6868672966957092}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6844378709793091}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6820083856582642}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.679443895816803}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6779592633247375}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6731002926826477}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.670400857925415}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6675664782524109}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6624375581741333}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6610878705978394}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6566337943077087}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6492103934288025}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6512349843978882}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6505601406097412}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.650830090045929}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6496153473854065}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6454312205314636}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6435416340827942}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6435416340827942}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6409772038459778}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6440815329551697}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.643136739730835}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6366581320762634}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6400324106216431}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6397624611854553}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6390876173973083}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6392225623130798}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6361182332038879}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6377378702163696}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6338237524032593}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6361182332038879}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6315292119979858}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6280199885368347}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6296396255493164}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6245107054710388}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6315292119979858}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6285598874092102}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.626670241355896}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6241058111190796}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6274800896644592}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.628424882888794}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6218113303184509}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6249156594276428}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6208665370941162}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.7743121385574341}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.7054935097694397}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.6416778564453125}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.5944865345954895}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.5581560730934143}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.5275866985321045}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.49991971254348755}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.4753510355949402}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.4518837630748749}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.43071430921554565}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.4112154543399811}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.39287370443344116}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.3760983943939209}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.3598157465457916}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.3453454375267029}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.33184173703193665}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.31857848167419434}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.3071741759777069}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.29483065009117126}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.2843261659145355}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.2745073139667511}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.2630385458469391}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.25554388761520386}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.24612438678741455}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.23910391330718994}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.2302783876657486}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.22569821774959564}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.21550379693508148}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.20977725088596344}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.20282739400863647}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.19595547020435333}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.19280566275119781}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.1837971955537796}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.17688459157943726}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.1760949343442917}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.17294742166996002}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.16394712030887604}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.16545532643795013}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.15862110257148743}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.15317174792289734}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.1499495804309845}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.1494186669588089}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.1450774073600769}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.13893656432628632}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.1349998414516449}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.13747474551200867}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.1332763284444809}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.1298653483390808}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.12786979973316193}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.1288420557975769}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7590844631195068}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7203254699707031}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.707843542098999}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7155762910842896}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7316405177116394}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7539727687835693}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7788384556770325}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.8108360767364502}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.8467414975166321}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.8845194578170776}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.9257502555847168}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.9686313271522522}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.0071790218353271}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.0453671216964722}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.0914969444274902}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.1377735137939453}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.1810661554336548}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.228133201599121}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.2893433570861816}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.3319487571716309}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.3903656005859375}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.4570715427398682}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.5110054016113281}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.5662882328033447}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.6144042015075684}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.6847894191741943}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.7510050535202026}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.776234745979309}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.8078540563583374}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.8933920860290527}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.954297423362732}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.981319546699524}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.0471408367156982}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.0814948081970215}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.1911849975585938}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.2222607135772705}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.276407480239868}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.3324897289276123}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.3801116943359375}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.456512928009033}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.5325145721435547}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.5697405338287354}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.5995917320251465}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.663672924041748}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.7616846561431885}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.8448398113250732}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.8493826389312744}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.927739143371582}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.964585781097412}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.0272305011749268}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.66667240858078}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7167830467224121}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7438026666641235}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7636856436729431}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7815443277359009}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7959719300270081}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8090099692344666}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8221509456634521}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8322554230690002}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.84024977684021}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8486902117729187}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8537853360176086}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8611792325973511}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8665145635604858}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8719871044158936}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8781973123550415}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8809764981269836}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.886860728263855}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8906692266464233}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8935856223106384}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9000360369682312}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9019402861595154}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9049424529075623}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.907841682434082}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9112041592597961}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9144464731216431}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9155444502830505}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9174143671989441}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9199361801147461}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.922646701335907}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9237446784973145}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9282393455505371}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9296118021011353}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9307783246040344}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9312758445739746}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9332658648490906}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9356675744056702}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9363195300102234}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9381894469261169}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9378634691238403}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9405225515365601}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9413631558418274}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9422037601470947}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.945085883140564}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9463039040565491}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9459264874458313}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9469729661941528}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9484654664993286}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9506956338882446}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9519994258880615}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6876771450042725}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6959103941917419}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.7002294659614563}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6994196176528931}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6938858032226562}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6909164786338806}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6878121495246887}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.67917400598526}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6720204949378967}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6698609590530396}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6672965288162231}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.663382351398468}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6596031785011292}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6559589505195618}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6558240056037903}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6479957103729248}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6566337943077087}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6513699293136597}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6511000394821167}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6475907564163208}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6505601406097412}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6400324106216431}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6434066891670227}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6400324106216431}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6452962756156921}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6390876173973083}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6361182332038879}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6376029253005981}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6382777690887451}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6385477185249329}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6423268914222717}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6392225623130798}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6331488490104675}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6374679207801819}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.63436359167099}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6299095749855042}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6280199885368347}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6237009167671204}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6309893131256104}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6276150345802307}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6211364269256592}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6210014820098877}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6205965876579285}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6227561235427856}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6250506043434143}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6222162246704102}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6224861741065979}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6243757605552673}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6172223091125488}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6176272034645081}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.7704646587371826}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.6748775243759155}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.6171572804450989}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.573368489742279}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.5357596278190613}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.5025739073753357}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.4738837480545044}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.4466319978237152}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.4240269064903259}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.40391653776168823}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.38483816385269165}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.36655786633491516}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.3496522903442383}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.3361503779888153}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.3233323097229004}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.30731701850891113}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.2987947463989258}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.2849293053150177}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.2755934000015259}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.267061322927475}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.25513049960136414}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.24890436232089996}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.2407768815755844}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.23285816609859467}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.22534695267677307}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.21733130514621735}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.21186508238315582}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.20913295447826385}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.2016129046678543}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.197183296084404}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.1930685043334961}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.18343861401081085}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.17922767996788025}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.17490842938423157}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.17390741407871246}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.1683516949415207}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.16295358538627625}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.1600649654865265}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.1560158133506775}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.15629278123378754}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.15138165652751923}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.14971263706684113}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.14751183986663818}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.14056383073329926}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.1381852626800537}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.13644710183143616}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.1363828480243683}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.13148783147335052}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.12894514203071594}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.12741732597351074}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.737956166267395}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7106653451919556}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7134868502616882}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7339807748794556}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7651282548904419}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7986113429069519}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.8366721272468567}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.8838412165641785}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.9454548954963684}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.9866638779640198}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.042780876159668}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.09292471408844}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.1775959730148315}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.2104524374008179}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.2949035167694092}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.3789596557617188}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.3952206373214722}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.4740370512008667}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.5280095338821411}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.5885238647460938}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.65424644947052}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.8114988803863525}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.839915156364441}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.8705873489379883}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.9431370496749878}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.007345199584961}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.0318427085876465}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.0944406986236572}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.1944847106933594}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.1962649822235107}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.2383010387420654}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.2857930660247803}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.477173089981079}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.5501151084899902}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.5384867191314697}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.5841758251190186}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.6181769371032715}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.668229579925537}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.7843809127807617}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.8775839805603027}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.8427305221557617}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.933750867843628}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.924746036529541}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.013683557510376}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.1193459033966064}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.0562005043029785}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.1255743503570557}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.261979818344116}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.226327419281006}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.3331544399261475}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.6659690141677856}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7113447785377502}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7360312938690186}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7579729557037354}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7787651419639587}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7949769496917725}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8084266781806946}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.820246696472168}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.830248236656189}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8394777774810791}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8469403386116028}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8535966277122498}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8590863347053528}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8652622103691101}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8701000213623047}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8758470416069031}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8825204372406006}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8859343528747559}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8887821435928345}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8930366635322571}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8970681428909302}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9000017046928406}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9025750160217285}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9052855372428894}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9087852239608765}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9110840559005737}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9138460755348206}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9165565967559814}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9194901585578918}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9183407425880432}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9207939505577087}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9247053861618042}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9263008236885071}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.927261471748352}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9288054704666138}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.930812656879425}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9317733645439148}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9332658648490906}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.934054970741272}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9370743632316589}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.936439573764801}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9393388628959656}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9397333860397339}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9423753023147583}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9427184462547302}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9452402591705322}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9458407163619995}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.94537752866745}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.947024405002594}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9460465312004089}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6834930777549744}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6955054402351379}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6983398795127869}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6933459043502808}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6870023012161255}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6826832294464111}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6760696172714233}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6774193644523621}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6724254488945007}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6701309084892273}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6671615839004517}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6605479717254639}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6598731279373169}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6533945202827454}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6596031785011292}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6598731279373169}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6539344191551208}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6486705541610718}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6489405035972595}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6470508575439453}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6428667902946472}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6478607058525085}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6443514823913574}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6444864273071289}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.64070725440979}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.642461895942688}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6376029253005981}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6439465284347534}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6435416340827942}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6327439546585083}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6358482837677002}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6380078196525574}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6400324106216431}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.63436359167099}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.642731785774231}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.641382098197937}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6392225623130798}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6390876173973083}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6411121487617493}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6380078196525574}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6351734399795532}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6316642165184021}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6323390603065491}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6326090097427368}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6304494738578796}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6316642165184021}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6304494738578796}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6315292119979858}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6326090097427368}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6276150345802307}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.7747976779937744}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.6908460259437561}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.6318251490592957}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.585148274898529}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.5455952882766724}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.5112875699996948}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.4823838472366333}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.4567824900150299}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.4355076849460602}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.4133613109588623}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.3948560655117035}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.37909770011901855}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.36574095487594604}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.350980281829834}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.33793723583221436}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.32671183347702026}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.3106101155281067}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.30143845081329346}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.293740451335907}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.28365930914878845}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.2726127505302429}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.26554495096206665}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.2566549479961395}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.24851681292057037}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.23993192613124847}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.2353827804327011}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.22871527075767517}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.21918626129627228}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.2136523723602295}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.21677513420581818}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.20974986255168915}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.19942232966423035}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.19632598757743835}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.189693883061409}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.18635351955890656}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.18254855275154114}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.18196147680282593}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.17602236568927765}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.17484429478645325}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.16603857278823853}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.166727676987648}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.16112740337848663}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.15983140468597412}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.15618352591991425}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.15380972623825073}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.14649894833564758}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.14494316279888153}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.14646533131599426}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.14014549553394318}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.1424756944179535}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7484829425811768}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7166368365287781}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7103780508041382}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7259607911109924}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7542709112167358}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7908024787902832}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.8317097425460815}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.8648132085800171}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.9182752966880798}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.9770146608352661}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.0360207557678223}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.0781627893447876}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.1276034116744995}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.1374093294143677}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.1710304021835327}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.2031372785568237}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.2747572660446167}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.2902264595031738}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.3449634313583374}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.390108585357666}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.4509730339050293}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.4637014865875244}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.4947470426559448}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.5038411617279053}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.6201978921890259}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.558693289756775}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.6445313692092896}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.7160221338272095}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.7902599573135376}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.794447898864746}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.8210707902908325}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.868208885192871}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.8876898288726807}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.9511510133743286}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.94608736038208}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.0060582160949707}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.9867775440216064}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.0682179927825928}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.0819430351257324}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.2267611026763916}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.1749794483184814}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.2093288898468018}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.312493085861206}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.3398077487945557}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.2674169540405273}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.388279914855957}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.51320481300354}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.4482433795928955}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.437028169631958}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.4449429512023926}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "nodes_per_layer = 64  # Adjust as needed\n",
    "layers_list = [1, 2, 3, 4]\n",
    "\n",
    "print(\"\\nTesting Constant Nodes per Layer:\")\n",
    "df_all_models = pd.DataFrame()\n",
    "\n",
    "for num_layers in layers_list:\n",
    "    print(f\"\\nTraining model with {num_layers} layers of {nodes_per_layer} nodes each\")\n",
    "    model = build_model(num_layers, nodes_per_layer)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': range(1, 51),\n",
    "        'training_accuracy': history.history['accuracy'],\n",
    "        'validation_accuracy': history.history['val_accuracy'],\n",
    "        'training_loss': history.history['loss'],\n",
    "        'validation_loss': history.history['val_loss'],\n",
    "        'num_layers': [num_layers] * 50\n",
    "    })\n",
    "    \n",
    "    # Melt the dataframe for long format\n",
    "    df_long = df.melt(id_vars=['epoch', 'num_layers'], \n",
    "                      value_vars=['training_accuracy', 'validation_accuracy', 'training_loss', 'validation_loss'],\n",
    "                      var_name='metric', value_name='value')\n",
    "    \n",
    "    # Concatenate all data\n",
    "    df_all_models = pd.concat([df_all_models, df_long], ignore_index=True)\n",
    "\n",
    "# Define the color mapping for metrics\n",
    "color_mapping = {\n",
    "    'training_accuracy': 'Training Accuracy',\n",
    "    'validation_accuracy': 'Validation Accuracy',\n",
    "    'training_loss': 'Training Loss',\n",
    "    'validation_loss': 'Validation Loss'\n",
    "}\n",
    "\n",
    "df_all_models['metric'] = df_all_models['metric'].map(color_mapping)\n",
    "\n",
    "# Altair plot: Interactive plot for all models\n",
    "chart = alt.Chart(df_all_models).mark_line().encode(\n",
    "    x='epoch',\n",
    "    y='value',\n",
    "    color='metric',\n",
    "    column='num_layers:O',  # Separate charts for each layer configuration\n",
    "    tooltip=['epoch', 'value', 'metric', 'num_layers']\n",
    ").properties(\n",
    "    title=\"Model Performance: Accuracy & Loss for Different Layer Configurations\",\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "chart.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and Loss in Training and Validation:\n",
    "\n",
    "- Training precision increases with the number of epochs, while validation precision remains low and relatively stable. This suggests an overfitting issue, where the model learns the training data well without improving generalization.\n",
    "- Training loss decreases, but validation loss remains high, confirming overfitting.\n",
    "\n",
    "Impact of Adding More Layers:\n",
    "\n",
    "- Adding extra layers (from 1 to 4) does not improve validation precision and even worsens overfitting by increasing the gap between training and validation loss.\n",
    "- Increased complexity with more layers does not appear to help the model generalize better in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to see the scenario of decreasing nodes per layer that forms a Pyramid Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Pyramid Structure:\n",
      "\n",
      "Training model with layers: [128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with layers: [128, 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with layers: [128, 64, 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with layers: [128, 64, 32, 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-52bac83268ad4fcfa62fdf66bacc86d0.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-52bac83268ad4fcfa62fdf66bacc86d0.vega-embed details,\n",
       "  #altair-viz-52bac83268ad4fcfa62fdf66bacc86d0.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-52bac83268ad4fcfa62fdf66bacc86d0\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-52bac83268ad4fcfa62fdf66bacc86d0\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-52bac83268ad4fcfa62fdf66bacc86d0\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-893579be991d2b42f5cae72b48ae078f\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"column\": {\"field\": \"num_layers\", \"type\": \"ordinal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}, {\"field\": \"num_layers\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Model Performance: Accuracy & Loss for Different Layer Configurations\", \"width\": 300, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-893579be991d2b42f5cae72b48ae078f\": [{\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.6699662208557129}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7134549021720886}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7405946254730225}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7631709575653076}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.7844778895378113}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8055102825164795}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8264912366867065}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.845156192779541}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8615566492080688}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.878128707408905}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.8916471004486084}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9040160775184631}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9156302213668823}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9262493252754211}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9351014494895935}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9439364671707153}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.951244592666626}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9587758183479309}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9651404023170471}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9709217548370361}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9758967757225037}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9795508980751038}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9821756482124329}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9829133152961731}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9828618764877319}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9823815226554871}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9831363558769226}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9847660660743713}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9857439398765564}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9863272309303284}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9832221269607544}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9856753349304199}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9875452518463135}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9878197312355042}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9863272309303284}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9889863133430481}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9886946678161621}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9877853989601135}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9890892505645752}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9901700019836426}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9908390641212463}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9895352721214294}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9901871681213379}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9893808364868164}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9920399188995361}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9931378960609436}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9915081262588501}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9917311668395996}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9931893348693848}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.9943044185638428}, {\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6779592633247375}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6959103941917419}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.7009043097496033}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.7023890018463135}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.7015791535377502}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6996895670890808}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6907814741134644}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6891618371009827}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6840329170227051}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6774193644523621}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.672155499458313}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6675664782524109}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6640572547912598}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6598731279373169}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6546092629432678}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6531245708465576}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6502901911735535}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6461060643196106}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6412471532821655}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.641382098197937}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6403023600578308}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6349034905433655}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6338237524032593}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6349034905433655}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6334187984466553}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6295046806335449}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6320691108703613}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6315292119979858}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6313942670822144}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6315292119979858}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6359832882881165}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6362531781196594}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6338237524032593}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6366581320762634}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6380078196525574}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6362531781196594}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6350384950637817}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6285598874092102}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6322040557861328}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.626670241355896}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6261304020881653}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6371980309486389}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6340936422348022}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6258604526519775}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6261304020881653}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6227561235427856}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6251856088638306}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.626400351524353}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6304494738578796}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6304494738578796}, {\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.7706623077392578}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.6916772127151489}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.6320076584815979}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.5845053195953369}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.5393056273460388}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.494935542345047}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.4518528878688812}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.4112626314163208}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.37387627363204956}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.33990368247032166}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.3084534704685211}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2802889943122864}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.2543638050556183}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.23052938282489777}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.20872586965560913}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.18820889294147491}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.16929155588150024}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.1519673764705658}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.13645830750465393}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.12187618762254715}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.10880441963672638}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.09707063436508179}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.08809025585651398}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.08094208687543869}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.07682425528764725}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.07333094626665115}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.06872622668743134}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.06379996240139008}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.05930975452065468}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.05689592286944389}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.06002742797136307}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.05493593215942383}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.049504633992910385}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.04835624620318413}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.04943452030420303}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.04445301741361618}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.043306801468133926}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.04389284551143646}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.039674632251262665}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.03880959004163742}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.03609495609998703}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.036257304251194}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.03571861982345581}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.03626032918691635}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.030554238706827164}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.02855564095079899}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.031156539916992188}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.0293803121894598}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.02653963677585125}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Training Loss\", \"value\": 0.024243636056780815}, {\"epoch\": 1, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7531933784484863}, {\"epoch\": 2, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7118025422096252}, {\"epoch\": 3, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7005253434181213}, {\"epoch\": 4, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.70063316822052}, {\"epoch\": 5, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7104536890983582}, {\"epoch\": 6, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.72708660364151}, {\"epoch\": 7, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.753376841545105}, {\"epoch\": 8, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7841007709503174}, {\"epoch\": 9, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.8231033682823181}, {\"epoch\": 10, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.867420494556427}, {\"epoch\": 11, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.9150608777999878}, {\"epoch\": 12, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 0.9670044779777527}, {\"epoch\": 13, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.0219181776046753}, {\"epoch\": 14, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.0806576013565063}, {\"epoch\": 15, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.1442832946777344}, {\"epoch\": 16, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.2131540775299072}, {\"epoch\": 17, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.2854928970336914}, {\"epoch\": 18, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.3660435676574707}, {\"epoch\": 19, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.4498106241226196}, {\"epoch\": 20, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.531948208808899}, {\"epoch\": 21, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.6139376163482666}, {\"epoch\": 22, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.7033504247665405}, {\"epoch\": 23, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.8024200201034546}, {\"epoch\": 24, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.8813647031784058}, {\"epoch\": 25, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 1.9789097309112549}, {\"epoch\": 26, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.0682291984558105}, {\"epoch\": 27, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.1162898540496826}, {\"epoch\": 28, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.176274538040161}, {\"epoch\": 29, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.2616846561431885}, {\"epoch\": 30, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.3141181468963623}, {\"epoch\": 31, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.3837835788726807}, {\"epoch\": 32, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.490852117538452}, {\"epoch\": 33, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.490959644317627}, {\"epoch\": 34, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.568302631378174}, {\"epoch\": 35, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.606887102127075}, {\"epoch\": 36, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.679332971572876}, {\"epoch\": 37, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.7057127952575684}, {\"epoch\": 38, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.7591209411621094}, {\"epoch\": 39, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.8257694244384766}, {\"epoch\": 40, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.8677971363067627}, {\"epoch\": 41, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.9215853214263916}, {\"epoch\": 42, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.92354679107666}, {\"epoch\": 43, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 2.993703842163086}, {\"epoch\": 44, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.0869925022125244}, {\"epoch\": 45, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.069912910461426}, {\"epoch\": 46, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.1639959812164307}, {\"epoch\": 47, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.203763008117676}, {\"epoch\": 48, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.2493903636932373}, {\"epoch\": 49, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.2680835723876953}, {\"epoch\": 50, \"num_layers\": 1, \"metric\": \"Validation Loss\", \"value\": 3.301722288131714}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.6674615144729614}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7163026928901672}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7521229982376099}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.783637285232544}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.813058614730835}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8380024433135986}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8623629808425903}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8819200396537781}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.8988522887229919}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9118560552597046}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9210512638092041}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9286510944366455}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.936731219291687}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9450687170028687}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9483453631401062}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9507471323013306}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9566828608512878}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9601482152938843}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9618637561798096}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9656035900115967}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9676622748374939}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.968297004699707}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9710761308670044}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9716594219207764}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9735980033874512}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9753821492195129}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9779725670814514}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9748331904411316}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9789332747459412}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9785044193267822}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9793278574943542}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9783843159675598}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9813178777694702}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9818496704101562}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9821413159370422}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9814379811286926}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9834794402122498}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9831706285476685}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9843372106552124}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9852292537689209}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9836509823799133}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.98591548204422}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9860870242118835}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9876653552055359}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9865159392356873}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9862414598464966}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9871335029602051}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.9862242937088013}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.988437294960022}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.988591730594635}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6776893138885498}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6990147233009338}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6982048749923706}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6942907571792603}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6849777102470398}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6752598285675049}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6671615839004517}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6558240056037903}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6519098281860352}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6457011699676514}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6451612710952759}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6362531781196594}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6361182332038879}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6305844187736511}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6362531781196594}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6296396255493164}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6342286467552185}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6316642165184021}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6311243176460266}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6251856088638306}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6261304020881653}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6228910684585571}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6227561235427856}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6245107054710388}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6162775158882141}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.627750039100647}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6219462752342224}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.626400351524353}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6297745704650879}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6254554986953735}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6207315325737}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6268052458763123}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6273451447486877}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6317991614341736}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6286948323249817}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.627750039100647}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6289647817611694}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6276150345802307}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6292347311973572}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6293696761131287}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6295046806335449}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6328789591789246}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6274800896644592}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6315292119979858}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6273451447486877}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6328789591789246}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6327439546585083}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.633013904094696}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6324740052223206}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6338237524032593}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.7688635587692261}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.6774678826332092}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.5993828177452087}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.5299950242042542}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.4663354456424713}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.4097305238246918}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.3583311438560486}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.31183314323425293}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.27190813422203064}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.23939096927642822}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.21307618916034698}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.1917942613363266}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.17373567819595337}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.15266446769237518}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.140903040766716}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.13261060416698456}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.1181522086262703}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.11019822210073471}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.10334721952676773}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.09415378421545029}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.09075546264648438}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.08694517612457275}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.07970128953456879}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.07777991145849228}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.07584027945995331}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.06877678632736206}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.06409820914268494}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.06865637749433517}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.05925767868757248}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.05966293811798096}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.05883878841996193}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.06134682521224022}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.0536266565322876}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.05120072513818741}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.053494956344366074}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.05214200168848038}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.04786773398518562}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.0475844144821167}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.04562966153025627}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.0442189946770668}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.04656829312443733}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.04169503226876259}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.04104144126176834}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.03591826558113098}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.03903169929981232}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.04100760072469711}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.03682013228535652}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.04110298305749893}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.03362632915377617}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Training Loss\", \"value\": 0.03355874866247177}, {\"epoch\": 1, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7488693594932556}, {\"epoch\": 2, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7071102261543274}, {\"epoch\": 3, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7123491168022156}, {\"epoch\": 4, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7436770796775818}, {\"epoch\": 5, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.800541341304779}, {\"epoch\": 6, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.874673068523407}, {\"epoch\": 7, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 0.9657390117645264}, {\"epoch\": 8, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.0706753730773926}, {\"epoch\": 9, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.1819634437561035}, {\"epoch\": 10, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.3109151124954224}, {\"epoch\": 11, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.4239012002944946}, {\"epoch\": 12, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.5238525867462158}, {\"epoch\": 13, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.6821954250335693}, {\"epoch\": 14, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.845507025718689}, {\"epoch\": 15, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 1.9837814569473267}, {\"epoch\": 16, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.064359426498413}, {\"epoch\": 17, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.212702989578247}, {\"epoch\": 18, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.3316073417663574}, {\"epoch\": 19, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.4366393089294434}, {\"epoch\": 20, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.520293712615967}, {\"epoch\": 21, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.6226143836975098}, {\"epoch\": 22, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.7113430500030518}, {\"epoch\": 23, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.774991512298584}, {\"epoch\": 24, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.8615851402282715}, {\"epoch\": 25, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 2.961413860321045}, {\"epoch\": 26, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.0155723094940186}, {\"epoch\": 27, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.1776061058044434}, {\"epoch\": 28, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.1584904193878174}, {\"epoch\": 29, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.328843593597412}, {\"epoch\": 30, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.2841858863830566}, {\"epoch\": 31, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.3178656101226807}, {\"epoch\": 32, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.471796751022339}, {\"epoch\": 33, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.537776470184326}, {\"epoch\": 34, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.5074450969696045}, {\"epoch\": 35, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.5790305137634277}, {\"epoch\": 36, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.6872360706329346}, {\"epoch\": 37, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.701380491256714}, {\"epoch\": 38, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.884974956512451}, {\"epoch\": 39, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.9577090740203857}, {\"epoch\": 40, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.96034574508667}, {\"epoch\": 41, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 3.9408833980560303}, {\"epoch\": 42, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 4.044652938842773}, {\"epoch\": 43, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 4.1817240715026855}, {\"epoch\": 44, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 4.118797779083252}, {\"epoch\": 45, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 4.1906280517578125}, {\"epoch\": 46, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 4.299443244934082}, {\"epoch\": 47, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 4.329112529754639}, {\"epoch\": 48, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 4.332386493682861}, {\"epoch\": 49, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 4.403409957885742}, {\"epoch\": 50, \"num_layers\": 2, \"metric\": \"Validation Loss\", \"value\": 4.446373462677002}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.6660719513893127}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7188760042190552}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7563774585723877}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7896931171417236}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8193203210830688}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8446072340011597}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.864627480506897}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8794153332710266}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8922303318977356}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9051139950752258}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9120447635650635}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9202964305877686}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9276560544967651}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9321678876876831}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9382237195968628}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.942512571811676}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.946492612361908}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9507128000259399}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9533547163009644}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9549329876899719}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9602683186531067}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9595134854316711}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9635964632034302}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9639395475387573}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9675421714782715}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9682798385620117}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9687601923942566}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9714878797531128}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9708359837532043}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9715736508369446}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9752792119979858}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9755708575248718}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9745243787765503}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9783328175544739}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9762570261955261}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9789676070213318}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9798939824104309}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9789847731590271}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9807174205780029}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9812149405479431}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.981403648853302}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9805973768234253}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9819183349609375}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9832563996315002}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9833593368530273}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9851434826850891}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9834966063499451}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.983633816242218}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9858297109603882}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.9846116900444031}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6834930777549744}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.7030638456344604}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.7029288411140442}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.694155752658844}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.687137246131897}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.67917400598526}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6775543093681335}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6678364276885986}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6609528660774231}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6602780222892761}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6513699293136597}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6543393135070801}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6509650349617004}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6544742584228516}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6474558115005493}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.649750292301178}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6432716846466064}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6389526128768921}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6376029253005981}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.64070725440979}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6388176679611206}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6369280815124512}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6320691108703613}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6349034905433655}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6311243176460266}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6242408156394958}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.626670241355896}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6339586973190308}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6377378702163696}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6392225623130798}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6297745704650879}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6308543682098389}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6386826634407043}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.635443389415741}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6289647817611694}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6403023600578308}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6340936422348022}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6380078196525574}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6362531781196594}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6443514823913574}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6380078196525574}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6404373049736023}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6338237524032593}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.64070725440979}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6386826634407043}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6393575668334961}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6358482837677002}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6349034905433655}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6313942670822144}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6380078196525574}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.7718194127082825}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.6716555953025818}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.5906788110733032}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.5210472941398621}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.45806437730789185}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.40292856097221375}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.3559696078300476}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.3146449029445648}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.2838379442691803}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.2518559694290161}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.2319210171699524}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.21025912463665009}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.19352157413959503}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.18062429130077362}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.16520538926124573}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.15502946078777313}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.14418965578079224}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.1348342001438141}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.1259097456932068}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.1242283433675766}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.10865966975688934}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.1103234589099884}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.0998208150267601}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.09936120361089706}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.08775075525045395}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.08786218613386154}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.08706241101026535}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.07934939116239548}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.08346056938171387}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.07881075888872147}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.06974014639854431}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.06955064088106155}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.07370536774396896}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.06260629743337631}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.06826312839984894}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.05966944247484207}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.05797275900840759}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.05909082666039467}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.05611695349216461}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.053574539721012115}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.05359781160950661}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.055155206471681595}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.051745034754276276}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.049069005995988846}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.04852753505110741}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.04230668023228645}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.04638111591339111}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.048914771527051926}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.041038427501916885}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Training Loss\", \"value\": 0.04567623510956764}, {\"epoch\": 1, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7452392578125}, {\"epoch\": 2, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7024080157279968}, {\"epoch\": 3, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7087166905403137}, {\"epoch\": 4, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7478872537612915}, {\"epoch\": 5, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7949554920196533}, {\"epoch\": 6, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.8803870677947998}, {\"epoch\": 7, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 0.9603498578071594}, {\"epoch\": 8, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.0594971179962158}, {\"epoch\": 9, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.1702390909194946}, {\"epoch\": 10, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.269092321395874}, {\"epoch\": 11, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.3173714876174927}, {\"epoch\": 12, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.470406174659729}, {\"epoch\": 13, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.59402334690094}, {\"epoch\": 14, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.582124948501587}, {\"epoch\": 15, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.7612119913101196}, {\"epoch\": 16, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.8784306049346924}, {\"epoch\": 17, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 1.946260690689087}, {\"epoch\": 18, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.0067176818847656}, {\"epoch\": 19, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.175417900085449}, {\"epoch\": 20, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.2928411960601807}, {\"epoch\": 21, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.2952942848205566}, {\"epoch\": 22, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.3604650497436523}, {\"epoch\": 23, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.445094108581543}, {\"epoch\": 24, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.5907912254333496}, {\"epoch\": 25, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.662890672683716}, {\"epoch\": 26, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.745821237564087}, {\"epoch\": 27, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.676107406616211}, {\"epoch\": 28, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.764058828353882}, {\"epoch\": 29, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.8177976608276367}, {\"epoch\": 30, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.851120948791504}, {\"epoch\": 31, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.982609272003174}, {\"epoch\": 32, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.0055158138275146}, {\"epoch\": 33, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 2.98406982421875}, {\"epoch\": 34, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.2858917713165283}, {\"epoch\": 35, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.0521225929260254}, {\"epoch\": 36, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.1464898586273193}, {\"epoch\": 37, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.3370110988616943}, {\"epoch\": 38, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.348749876022339}, {\"epoch\": 39, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.484804630279541}, {\"epoch\": 40, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.541621208190918}, {\"epoch\": 41, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.446141242980957}, {\"epoch\": 42, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.532437324523926}, {\"epoch\": 43, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.43294358253479}, {\"epoch\": 44, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.533257484436035}, {\"epoch\": 45, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.6133854389190674}, {\"epoch\": 46, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.7556557655334473}, {\"epoch\": 47, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.7598557472229004}, {\"epoch\": 48, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.561872959136963}, {\"epoch\": 49, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.8065788745880127}, {\"epoch\": 50, \"num_layers\": 3, \"metric\": \"Validation Loss\", \"value\": 3.6344854831695557}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.6650769710540771}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.720076858997345}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.753632664680481}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7862105369567871}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8142938017845154}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8369731307029724}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8548489212989807}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.870940625667572}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8855226635932922}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8949923515319824}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9042562246322632}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9124050140380859}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9184951186180115}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9250999093055725}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.930949866771698}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9376233220100403}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9405911564826965}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9457892179489136}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9480194449424744}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9513475298881531}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9533718824386597}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9569230079650879}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9606457352638245}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9615035057067871}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.964505672454834}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9660496711730957}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9663927555084229}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9689660668373108}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9709731936454773}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.971642255783081}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9735980033874512}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.973975419998169}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9735980033874512}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9772348999977112}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9776294827461243}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.977475106716156}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9778353571891785}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9795851707458496}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9798939824104309}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9800998568534851}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9799797534942627}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9822957515716553}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9815409183502197}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9822614192962646}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9835308790206909}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9835652112960815}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9842686057090759}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9845430850982666}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9858983159065247}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.9850062727928162}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.685112714767456}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.7026589512825012}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6972600817680359}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6969901323318481}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6888918876647949}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6814684867858887}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6784991025924683}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6726953983306885}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6698609590530396}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6640572547912598}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6577135920524597}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6546092629432678}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6650020480155945}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6481306552886963}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6462410688400269}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6389526128768921}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6409772038459778}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.633688747882843}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6430017352104187}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6346335411071777}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6367930769920349}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6324740052223206}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.633688747882843}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6331488490104675}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6309893131256104}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6316642165184021}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6334187984466553}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6327439546585083}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6319341063499451}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6331488490104675}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6295046806335449}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6311243176460266}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6215413808822632}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6299095749855042}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6201916337013245}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6270751953125}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6239708662033081}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6358482837677002}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6281549334526062}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6285598874092102}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6319341063499451}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6335538029670715}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6378728747367859}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6304494738578796}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6313942670822144}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6371980309486389}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6231610178947449}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6385477185249329}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6316642165184021}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6366581320762634}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.7719985842704773}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.6701802611351013}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.5946339964866638}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.526055097579956}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.4640915095806122}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.4118516147136688}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.3705383241176605}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.33555084466934204}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.30179351568222046}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.27716436982154846}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.2528262734413147}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.2355099320411682}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.21617108583450317}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.19965870678424835}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.18327969312667847}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.16927027702331543}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.16207529604434967}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.14576838910579681}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.14126086235046387}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.13307321071624756}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.12516461312770844}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.11808952689170837}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.10758768767118454}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.10574992746114731}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.0994311049580574}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.0926351249217987}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.09126242995262146}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.08662614226341248}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.07928188890218735}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.0790664404630661}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.07337883859872818}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.07164279371500015}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.07264130562543869}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.06308390200138092}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.0629291832447052}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.06263073533773422}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.06226356327533722}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.05751805752515793}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.05685199797153473}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.05466436967253685}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.05650389939546585}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.05027696490287781}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.051720552146434784}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.050558269023895264}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04706497862935066}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04679431393742561}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.045534662902355194}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04473615437746048}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04083794727921486}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Training Loss\", \"value\": 0.04261307418346405}, {\"epoch\": 1, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7351764440536499}, {\"epoch\": 2, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.70407634973526}, {\"epoch\": 3, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7250908017158508}, {\"epoch\": 4, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7629016041755676}, {\"epoch\": 5, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.8214811086654663}, {\"epoch\": 6, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 0.8962151408195496}, {\"epoch\": 7, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.0092747211456299}, {\"epoch\": 8, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.106673002243042}, {\"epoch\": 9, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.187186598777771}, {\"epoch\": 10, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.246442198753357}, {\"epoch\": 11, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.3269602060317993}, {\"epoch\": 12, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.4091655015945435}, {\"epoch\": 13, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.4513424634933472}, {\"epoch\": 14, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.5171183347702026}, {\"epoch\": 15, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.6851333379745483}, {\"epoch\": 16, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.7156376838684082}, {\"epoch\": 17, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.7541565895080566}, {\"epoch\": 18, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.785600185394287}, {\"epoch\": 19, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.8989124298095703}, {\"epoch\": 20, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 1.9881350994110107}, {\"epoch\": 21, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.041295289993286}, {\"epoch\": 22, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.1006581783294678}, {\"epoch\": 23, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.1489665508270264}, {\"epoch\": 24, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.22426438331604}, {\"epoch\": 25, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.3204190731048584}, {\"epoch\": 26, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.4737207889556885}, {\"epoch\": 27, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.3642661571502686}, {\"epoch\": 28, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.4564037322998047}, {\"epoch\": 29, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.4334518909454346}, {\"epoch\": 30, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.5831196308135986}, {\"epoch\": 31, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.5942728519439697}, {\"epoch\": 32, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.644542932510376}, {\"epoch\": 33, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.6733388900756836}, {\"epoch\": 34, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.885748863220215}, {\"epoch\": 35, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.850973606109619}, {\"epoch\": 36, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.8612871170043945}, {\"epoch\": 37, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.7917845249176025}, {\"epoch\": 38, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.8094890117645264}, {\"epoch\": 39, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.811553716659546}, {\"epoch\": 40, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.005221366882324}, {\"epoch\": 41, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 2.9486172199249268}, {\"epoch\": 42, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.020232677459717}, {\"epoch\": 43, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.075144052505493}, {\"epoch\": 44, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.227524995803833}, {\"epoch\": 45, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.238415002822876}, {\"epoch\": 46, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.2380261421203613}, {\"epoch\": 47, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.27685809135437}, {\"epoch\": 48, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.226919651031494}, {\"epoch\": 49, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.2693119049072266}, {\"epoch\": 50, \"num_layers\": 4, \"metric\": \"Validation Loss\", \"value\": 3.3182735443115234}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "layers_list = [1, 2, 3, 4]\n",
    "\n",
    "print(\"Testing Pyramid Structure:\")\n",
    "df_all_models = pd.DataFrame()\n",
    "\n",
    "for num_layers in layers_list:\n",
    "    nodes = [128 // (2 ** i) for i in range(num_layers)]  # Decrease nodes per layer\n",
    "    print(f\"\\nTraining model with layers: {nodes}\")\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(462,)))\n",
    "    for n in nodes:\n",
    "        model.add(Dense(n, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': range(1, 51),\n",
    "        'training_accuracy': history.history['accuracy'],\n",
    "        'validation_accuracy': history.history['val_accuracy'],\n",
    "        'training_loss': history.history['loss'],\n",
    "        'validation_loss': history.history['val_loss'],\n",
    "        'num_layers': [num_layers] * 50\n",
    "    })\n",
    "    \n",
    "    # Melt the dataframe for long format\n",
    "    df_long = df.melt(id_vars=['epoch', 'num_layers'], \n",
    "                      value_vars=['training_accuracy', 'validation_accuracy', 'training_loss', 'validation_loss'],\n",
    "                      var_name='metric', value_name='value')\n",
    "    \n",
    "    # Concatenate all data\n",
    "    df_all_models = pd.concat([df_all_models, df_long], ignore_index=True)\n",
    "\n",
    "# Define the color mapping for metrics\n",
    "color_mapping = {\n",
    "    'training_accuracy': 'Training Accuracy',\n",
    "    'validation_accuracy': 'Validation Accuracy',\n",
    "    'training_loss': 'Training Loss',\n",
    "    'validation_loss': 'Validation Loss'\n",
    "}\n",
    "\n",
    "df_all_models['metric'] = df_all_models['metric'].map(color_mapping)\n",
    "\n",
    "# Altair plot: Interactive plot for all models\n",
    "chart = alt.Chart(df_all_models).mark_line().encode(\n",
    "    x='epoch',\n",
    "    y='value',\n",
    "    color='metric',\n",
    "    column='num_layers:O',  # Separate charts for each layer configuration\n",
    "    tooltip=['epoch', 'value', 'metric', 'num_layers']\n",
    ").properties(\n",
    "    title=\"Model Performance: Accuracy & Loss for Different Layer Configurations\",\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "chart.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and Loss in Training and Validation:\n",
    "- As in previous configurations, training precision increases with epochs, while validation precision remains low and stable, suggesting an ongoing overfitting issue.\n",
    "- Training loss consistently decreases, but validation loss remains stable and high, confirming that the model is not generalizing well.\n",
    "\n",
    "Effect of Pyramid Structure:\n",
    "- The gradual reduction in the number of nodes per layer (pyramid structure) does not seem to significantly improve validation performance compared to other tested architectures.\n",
    "- Despite the decrease in the number of nodes per layer, the model continues to overfit, with no notable improvement in generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6437 - loss: 0.8075 - val_accuracy: 0.6866 - val_loss: 0.7382\n",
      "Epoch 2/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.6421 - val_accuracy: 0.6982 - val_loss: 0.7201\n",
      "Epoch 3/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7955 - loss: 0.5036 - val_accuracy: 0.6896 - val_loss: 0.8073\n",
      "Epoch 4/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8601 - loss: 0.3537 - val_accuracy: 0.6778 - val_loss: 0.9401\n",
      "Epoch 5/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.2438 - val_accuracy: 0.6697 - val_loss: 1.2046\n",
      "Epoch 6/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9317 - loss: 0.1828 - val_accuracy: 0.6641 - val_loss: 1.4386\n",
      "Epoch 7/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.1387 - val_accuracy: 0.6649 - val_loss: 1.5346\n",
      "Epoch 8/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9592 - loss: 0.1104 - val_accuracy: 0.6662 - val_loss: 1.8328\n",
      "Epoch 9/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9655 - loss: 0.0941 - val_accuracy: 0.6600 - val_loss: 1.8719\n",
      "Epoch 10/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.0819 - val_accuracy: 0.6604 - val_loss: 1.8184\n",
      "Epoch 11/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9748 - loss: 0.0709 - val_accuracy: 0.6628 - val_loss: 2.1962\n",
      "Epoch 12/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9777 - loss: 0.0617 - val_accuracy: 0.6612 - val_loss: 2.2395\n",
      "Epoch 13/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 0.0580 - val_accuracy: 0.6553 - val_loss: 2.2536\n",
      "Epoch 14/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9817 - loss: 0.0503 - val_accuracy: 0.6572 - val_loss: 2.2684\n",
      "Epoch 15/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0454 - val_accuracy: 0.6475 - val_loss: 2.2686\n",
      "Epoch 16/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0444 - val_accuracy: 0.6473 - val_loss: 2.2647\n",
      "Epoch 17/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0411 - val_accuracy: 0.6530 - val_loss: 2.4509\n",
      "Epoch 18/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0363 - val_accuracy: 0.6476 - val_loss: 2.4414\n",
      "Epoch 19/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0364 - val_accuracy: 0.6612 - val_loss: 2.5333\n",
      "Epoch 20/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0324 - val_accuracy: 0.6578 - val_loss: 2.6525\n",
      "Epoch 21/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0339 - val_accuracy: 0.6651 - val_loss: 2.5401\n",
      "Epoch 22/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0320 - val_accuracy: 0.6620 - val_loss: 2.5780\n",
      "Epoch 23/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0273 - val_accuracy: 0.6686 - val_loss: 2.7435\n",
      "Epoch 24/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0281 - val_accuracy: 0.6695 - val_loss: 2.7446\n",
      "Epoch 25/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0289 - val_accuracy: 0.6635 - val_loss: 2.5850\n",
      "Epoch 26/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0227 - val_accuracy: 0.6610 - val_loss: 2.8889\n",
      "Epoch 27/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0215 - val_accuracy: 0.6626 - val_loss: 2.9700\n",
      "Epoch 28/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0226 - val_accuracy: 0.6610 - val_loss: 2.7091\n",
      "Epoch 29/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0241 - val_accuracy: 0.6634 - val_loss: 2.8049\n",
      "Epoch 30/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0188 - val_accuracy: 0.6715 - val_loss: 2.8587\n",
      "Epoch 31/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0216 - val_accuracy: 0.6665 - val_loss: 2.8091\n",
      "Epoch 32/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0213 - val_accuracy: 0.6611 - val_loss: 3.1748\n",
      "Epoch 33/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9939 - loss: 0.0182 - val_accuracy: 0.6642 - val_loss: 2.7395\n",
      "Epoch 34/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0182 - val_accuracy: 0.6661 - val_loss: 3.2156\n",
      "Epoch 35/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0182 - val_accuracy: 0.6723 - val_loss: 3.0568\n",
      "Epoch 36/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0182 - val_accuracy: 0.6735 - val_loss: 3.2151\n",
      "Epoch 37/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0151 - val_accuracy: 0.6689 - val_loss: 3.3664\n",
      "Epoch 38/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9945 - loss: 0.0167 - val_accuracy: 0.6653 - val_loss: 3.5439\n",
      "Epoch 39/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0150 - val_accuracy: 0.6708 - val_loss: 3.1660\n",
      "Epoch 40/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0152 - val_accuracy: 0.6651 - val_loss: 3.1369\n",
      "Epoch 41/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9948 - loss: 0.0152 - val_accuracy: 0.6588 - val_loss: 3.6045\n",
      "Epoch 42/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9947 - loss: 0.0162 - val_accuracy: 0.6619 - val_loss: 3.2332\n",
      "Epoch 43/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9951 - loss: 0.0150 - val_accuracy: 0.6707 - val_loss: 3.1993\n",
      "Epoch 44/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0131 - val_accuracy: 0.6685 - val_loss: 3.1068\n",
      "Epoch 45/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0125 - val_accuracy: 0.6715 - val_loss: 3.7293\n",
      "Epoch 46/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0140 - val_accuracy: 0.6685 - val_loss: 2.8652\n",
      "Epoch 47/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0130 - val_accuracy: 0.6674 - val_loss: 3.2989\n",
      "Epoch 48/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0133 - val_accuracy: 0.6669 - val_loss: 3.3579\n",
      "Epoch 49/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0130 - val_accuracy: 0.6635 - val_loss: 3.9792\n",
      "Epoch 50/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9964 - loss: 0.0133 - val_accuracy: 0.6614 - val_loss: 3.5942\n",
      "Epoch 51/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0102 - val_accuracy: 0.6624 - val_loss: 3.8241\n",
      "Epoch 52/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9964 - loss: 0.0108 - val_accuracy: 0.6642 - val_loss: 4.2992\n",
      "Epoch 53/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9961 - loss: 0.0129 - val_accuracy: 0.6591 - val_loss: 3.7541\n",
      "Epoch 54/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0101 - val_accuracy: 0.6589 - val_loss: 3.8278\n",
      "Epoch 55/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0114 - val_accuracy: 0.6615 - val_loss: 4.0512\n",
      "Epoch 56/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9967 - loss: 0.0094 - val_accuracy: 0.6692 - val_loss: 3.6758\n",
      "Epoch 57/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9965 - loss: 0.0112 - val_accuracy: 0.6727 - val_loss: 4.1963\n",
      "Epoch 58/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9960 - loss: 0.0116 - val_accuracy: 0.6624 - val_loss: 4.2007\n",
      "Epoch 59/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0095 - val_accuracy: 0.6626 - val_loss: 4.5872\n",
      "Epoch 60/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9965 - loss: 0.0120 - val_accuracy: 0.6647 - val_loss: 3.7093\n",
      "Epoch 61/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9967 - loss: 0.0097 - val_accuracy: 0.6641 - val_loss: 3.6087\n",
      "Epoch 62/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0097 - val_accuracy: 0.6666 - val_loss: 3.6557\n",
      "Epoch 63/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0100 - val_accuracy: 0.6649 - val_loss: 4.1722\n",
      "Epoch 64/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0077 - val_accuracy: 0.6624 - val_loss: 4.6376\n",
      "Epoch 65/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0077 - val_accuracy: 0.6634 - val_loss: 4.2184\n",
      "Epoch 66/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9969 - loss: 0.0091 - val_accuracy: 0.6566 - val_loss: 5.1014\n",
      "Epoch 67/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0106 - val_accuracy: 0.6630 - val_loss: 4.0218\n",
      "Epoch 68/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9976 - loss: 0.0069 - val_accuracy: 0.6623 - val_loss: 4.1067\n",
      "Epoch 69/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0083 - val_accuracy: 0.6622 - val_loss: 4.4844\n",
      "Epoch 70/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0089 - val_accuracy: 0.6664 - val_loss: 4.4156\n",
      "Epoch 71/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0087 - val_accuracy: 0.6637 - val_loss: 4.5153\n",
      "Epoch 72/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0077 - val_accuracy: 0.6658 - val_loss: 4.6868\n",
      "Epoch 73/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0066 - val_accuracy: 0.6628 - val_loss: 4.2200\n",
      "Epoch 74/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9976 - loss: 0.0075 - val_accuracy: 0.6668 - val_loss: 4.5057\n",
      "Epoch 75/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0084 - val_accuracy: 0.6601 - val_loss: 5.6385\n",
      "Epoch 76/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9976 - loss: 0.0085 - val_accuracy: 0.6595 - val_loss: 5.4119\n",
      "Epoch 77/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0107 - val_accuracy: 0.6580 - val_loss: 4.7684\n",
      "Epoch 78/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0068 - val_accuracy: 0.6607 - val_loss: 4.5381\n",
      "Epoch 79/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9976 - loss: 0.0082 - val_accuracy: 0.6622 - val_loss: 4.2540\n",
      "Epoch 80/80\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0061 - val_accuracy: 0.6605 - val_loss: 5.0823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-48ab90f3ef5d4758a18805f7d34f67a2.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-48ab90f3ef5d4758a18805f7d34f67a2.vega-embed details,\n",
       "  #altair-viz-48ab90f3ef5d4758a18805f7d34f67a2.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-48ab90f3ef5d4758a18805f7d34f67a2\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-48ab90f3ef5d4758a18805f7d34f67a2\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-48ab90f3ef5d4758a18805f7d34f67a2\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"vconcat\": [{\"data\": {\"name\": \"data-62fd7b63e9fb8823c83981527587e5c0\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Model Accuracy Illustrating Overfitting\", \"width\": 400}, {\"data\": {\"name\": \"data-09a91faa9431661e4dcee6af23283a38\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Model Loss Illustrating Overfitting\", \"width\": 400}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-62fd7b63e9fb8823c83981527587e5c0\": [{\"epoch\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.6749412417411804}, {\"epoch\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7394452095031738}, {\"epoch\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.8039491772651672}, {\"epoch\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.8680756688117981}, {\"epoch\": 5, \"metric\": \"Training Accuracy\", \"value\": 0.9105007648468018}, {\"epoch\": 6, \"metric\": \"Training Accuracy\", \"value\": 0.9325796365737915}, {\"epoch\": 7, \"metric\": \"Training Accuracy\", \"value\": 0.9488428831100464}, {\"epoch\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.9589645266532898}, {\"epoch\": 9, \"metric\": \"Training Accuracy\", \"value\": 0.9659810066223145}, {\"epoch\": 10, \"metric\": \"Training Accuracy\", \"value\": 0.9711790680885315}, {\"epoch\": 11, \"metric\": \"Training Accuracy\", \"value\": 0.9752277135848999}, {\"epoch\": 12, \"metric\": \"Training Accuracy\", \"value\": 0.9776638150215149}, {\"epoch\": 13, \"metric\": \"Training Accuracy\", \"value\": 0.9795851707458496}, {\"epoch\": 14, \"metric\": \"Training Accuracy\", \"value\": 0.9821413159370422}, {\"epoch\": 15, \"metric\": \"Training Accuracy\", \"value\": 0.9835652112960815}, {\"epoch\": 16, \"metric\": \"Training Accuracy\", \"value\": 0.9839769601821899}, {\"epoch\": 17, \"metric\": \"Training Accuracy\", \"value\": 0.9853150844573975}, {\"epoch\": 18, \"metric\": \"Training Accuracy\", \"value\": 0.9865502119064331}, {\"epoch\": 19, \"metric\": \"Training Accuracy\", \"value\": 0.9870477318763733}, {\"epoch\": 20, \"metric\": \"Training Accuracy\", \"value\": 0.9887632727622986}, {\"epoch\": 21, \"metric\": \"Training Accuracy\", \"value\": 0.9879912734031677}, {\"epoch\": 22, \"metric\": \"Training Accuracy\", \"value\": 0.9884201884269714}, {\"epoch\": 23, \"metric\": \"Training Accuracy\", \"value\": 0.9907704591751099}, {\"epoch\": 24, \"metric\": \"Training Accuracy\", \"value\": 0.9901528358459473}, {\"epoch\": 25, \"metric\": \"Training Accuracy\", \"value\": 0.9909934401512146}, {\"epoch\": 26, \"metric\": \"Training Accuracy\", \"value\": 0.9917997717857361}, {\"epoch\": 27, \"metric\": \"Training Accuracy\", \"value\": 0.9921085834503174}, {\"epoch\": 28, \"metric\": \"Training Accuracy\", \"value\": 0.9920914173126221}, {\"epoch\": 29, \"metric\": \"Training Accuracy\", \"value\": 0.9927433133125305}, {\"epoch\": 30, \"metric\": \"Training Accuracy\", \"value\": 0.9932065010070801}, {\"epoch\": 31, \"metric\": \"Training Accuracy\", \"value\": 0.99296635389328}, {\"epoch\": 32, \"metric\": \"Training Accuracy\", \"value\": 0.9928805232048035}, {\"epoch\": 33, \"metric\": \"Training Accuracy\", \"value\": 0.9930863976478577}, {\"epoch\": 34, \"metric\": \"Training Accuracy\", \"value\": 0.9938755631446838}, {\"epoch\": 35, \"metric\": \"Training Accuracy\", \"value\": 0.9938069581985474}, {\"epoch\": 36, \"metric\": \"Training Accuracy\", \"value\": 0.9941672086715698}, {\"epoch\": 37, \"metric\": \"Training Accuracy\", \"value\": 0.9947676062583923}, {\"epoch\": 38, \"metric\": \"Training Accuracy\", \"value\": 0.9945274591445923}, {\"epoch\": 39, \"metric\": \"Training Accuracy\", \"value\": 0.9946475625038147}, {\"epoch\": 40, \"metric\": \"Training Accuracy\", \"value\": 0.9949048757553101}, {\"epoch\": 41, \"metric\": \"Training Accuracy\", \"value\": 0.9948534369468689}, {\"epoch\": 42, \"metric\": \"Training Accuracy\", \"value\": 0.9950592517852783}, {\"epoch\": 43, \"metric\": \"Training Accuracy\", \"value\": 0.9953852295875549}, {\"epoch\": 44, \"metric\": \"Training Accuracy\", \"value\": 0.9953852295875549}, {\"epoch\": 45, \"metric\": \"Training Accuracy\", \"value\": 0.9954195618629456}, {\"epoch\": 46, \"metric\": \"Training Accuracy\", \"value\": 0.995093584060669}, {\"epoch\": 47, \"metric\": \"Training Accuracy\", \"value\": 0.9958140850067139}, {\"epoch\": 48, \"metric\": \"Training Accuracy\", \"value\": 0.9960027933120728}, {\"epoch\": 49, \"metric\": \"Training Accuracy\", \"value\": 0.9956597089767456}, {\"epoch\": 50, \"metric\": \"Training Accuracy\", \"value\": 0.9962601661682129}, {\"epoch\": 51, \"metric\": \"Training Accuracy\", \"value\": 0.9968777298927307}, {\"epoch\": 52, \"metric\": \"Training Accuracy\", \"value\": 0.9964317083358765}, {\"epoch\": 53, \"metric\": \"Training Accuracy\", \"value\": 0.9962258338928223}, {\"epoch\": 54, \"metric\": \"Training Accuracy\", \"value\": 0.996311604976654}, {\"epoch\": 55, \"metric\": \"Training Accuracy\", \"value\": 0.9965689182281494}, {\"epoch\": 56, \"metric\": \"Training Accuracy\", \"value\": 0.9964317083358765}, {\"epoch\": 57, \"metric\": \"Training Accuracy\", \"value\": 0.9967919588088989}, {\"epoch\": 58, \"metric\": \"Training Accuracy\", \"value\": 0.9965346455574036}, {\"epoch\": 59, \"metric\": \"Training Accuracy\", \"value\": 0.9971350431442261}, {\"epoch\": 60, \"metric\": \"Training Accuracy\", \"value\": 0.9969806671142578}, {\"epoch\": 61, \"metric\": \"Training Accuracy\", \"value\": 0.99660325050354}, {\"epoch\": 62, \"metric\": \"Training Accuracy\", \"value\": 0.9973066449165344}, {\"epoch\": 63, \"metric\": \"Training Accuracy\", \"value\": 0.9967919588088989}, {\"epoch\": 64, \"metric\": \"Training Accuracy\", \"value\": 0.9974953532218933}, {\"epoch\": 65, \"metric\": \"Training Accuracy\", \"value\": 0.9974953532218933}, {\"epoch\": 66, \"metric\": \"Training Accuracy\", \"value\": 0.9972379803657532}, {\"epoch\": 67, \"metric\": \"Training Accuracy\", \"value\": 0.9967405200004578}, {\"epoch\": 68, \"metric\": \"Training Accuracy\", \"value\": 0.9973924160003662}, {\"epoch\": 69, \"metric\": \"Training Accuracy\", \"value\": 0.9976497292518616}, {\"epoch\": 70, \"metric\": \"Training Accuracy\", \"value\": 0.9975296258926392}, {\"epoch\": 71, \"metric\": \"Training Accuracy\", \"value\": 0.9972551465034485}, {\"epoch\": 72, \"metric\": \"Training Accuracy\", \"value\": 0.9976325631141663}, {\"epoch\": 73, \"metric\": \"Training Accuracy\", \"value\": 0.9978556036949158}, {\"epoch\": 74, \"metric\": \"Training Accuracy\", \"value\": 0.9977355003356934}, {\"epoch\": 75, \"metric\": \"Training Accuracy\", \"value\": 0.9974610209465027}, {\"epoch\": 76, \"metric\": \"Training Accuracy\", \"value\": 0.9978041052818298}, {\"epoch\": 77, \"metric\": \"Training Accuracy\", \"value\": 0.9976497292518616}, {\"epoch\": 78, \"metric\": \"Training Accuracy\", \"value\": 0.9975639581680298}, {\"epoch\": 79, \"metric\": \"Training Accuracy\", \"value\": 0.9977011680603027}, {\"epoch\": 80, \"metric\": \"Training Accuracy\", \"value\": 0.9980443120002747}, {\"epoch\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6865974068641663}, {\"epoch\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6982048749923706}, {\"epoch\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.6895667314529419}, {\"epoch\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.6778242588043213}, {\"epoch\": 5, \"metric\": \"Validation Accuracy\", \"value\": 0.6697260141372681}, {\"epoch\": 6, \"metric\": \"Validation Accuracy\", \"value\": 0.6640572547912598}, {\"epoch\": 7, \"metric\": \"Validation Accuracy\", \"value\": 0.6648670434951782}, {\"epoch\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6662167906761169}, {\"epoch\": 9, \"metric\": \"Validation Accuracy\", \"value\": 0.6600080728530884}, {\"epoch\": 10, \"metric\": \"Validation Accuracy\", \"value\": 0.6604130268096924}, {\"epoch\": 11, \"metric\": \"Validation Accuracy\", \"value\": 0.6628425121307373}, {\"epoch\": 12, \"metric\": \"Validation Accuracy\", \"value\": 0.6612228155136108}, {\"epoch\": 13, \"metric\": \"Validation Accuracy\", \"value\": 0.6552841067314148}, {\"epoch\": 14, \"metric\": \"Validation Accuracy\", \"value\": 0.6571736931800842}, {\"epoch\": 15, \"metric\": \"Validation Accuracy\", \"value\": 0.6474558115005493}, {\"epoch\": 16, \"metric\": \"Validation Accuracy\", \"value\": 0.6473208069801331}, {\"epoch\": 17, \"metric\": \"Validation Accuracy\", \"value\": 0.6529896259307861}, {\"epoch\": 18, \"metric\": \"Validation Accuracy\", \"value\": 0.6475907564163208}, {\"epoch\": 19, \"metric\": \"Validation Accuracy\", \"value\": 0.6612228155136108}, {\"epoch\": 20, \"metric\": \"Validation Accuracy\", \"value\": 0.6578485369682312}, {\"epoch\": 21, \"metric\": \"Validation Accuracy\", \"value\": 0.665136992931366}, {\"epoch\": 22, \"metric\": \"Validation Accuracy\", \"value\": 0.6620326638221741}, {\"epoch\": 23, \"metric\": \"Validation Accuracy\", \"value\": 0.6686462163925171}, {\"epoch\": 24, \"metric\": \"Validation Accuracy\", \"value\": 0.6694560647010803}, {\"epoch\": 25, \"metric\": \"Validation Accuracy\", \"value\": 0.6635173559188843}, {\"epoch\": 26, \"metric\": \"Validation Accuracy\", \"value\": 0.6609528660774231}, {\"epoch\": 27, \"metric\": \"Validation Accuracy\", \"value\": 0.6625725626945496}, {\"epoch\": 28, \"metric\": \"Validation Accuracy\", \"value\": 0.6609528660774231}, {\"epoch\": 29, \"metric\": \"Validation Accuracy\", \"value\": 0.663382351398468}, {\"epoch\": 30, \"metric\": \"Validation Accuracy\", \"value\": 0.671480655670166}, {\"epoch\": 31, \"metric\": \"Validation Accuracy\", \"value\": 0.6664866805076599}, {\"epoch\": 32, \"metric\": \"Validation Accuracy\", \"value\": 0.6610878705978394}, {\"epoch\": 33, \"metric\": \"Validation Accuracy\", \"value\": 0.6641921997070312}, {\"epoch\": 34, \"metric\": \"Validation Accuracy\", \"value\": 0.6660817861557007}, {\"epoch\": 35, \"metric\": \"Validation Accuracy\", \"value\": 0.6722904443740845}, {\"epoch\": 36, \"metric\": \"Validation Accuracy\", \"value\": 0.6735051870346069}, {\"epoch\": 37, \"metric\": \"Validation Accuracy\", \"value\": 0.6689161658287048}, {\"epoch\": 38, \"metric\": \"Validation Accuracy\", \"value\": 0.6652719378471375}, {\"epoch\": 39, \"metric\": \"Validation Accuracy\", \"value\": 0.6708057522773743}, {\"epoch\": 40, \"metric\": \"Validation Accuracy\", \"value\": 0.665136992931366}, {\"epoch\": 41, \"metric\": \"Validation Accuracy\", \"value\": 0.6587933301925659}, {\"epoch\": 42, \"metric\": \"Validation Accuracy\", \"value\": 0.6618977189064026}, {\"epoch\": 43, \"metric\": \"Validation Accuracy\", \"value\": 0.6706708073616028}, {\"epoch\": 44, \"metric\": \"Validation Accuracy\", \"value\": 0.6685112714767456}, {\"epoch\": 45, \"metric\": \"Validation Accuracy\", \"value\": 0.671480655670166}, {\"epoch\": 46, \"metric\": \"Validation Accuracy\", \"value\": 0.6685112714767456}, {\"epoch\": 47, \"metric\": \"Validation Accuracy\", \"value\": 0.6674314737319946}, {\"epoch\": 48, \"metric\": \"Validation Accuracy\", \"value\": 0.6668916344642639}, {\"epoch\": 49, \"metric\": \"Validation Accuracy\", \"value\": 0.6635173559188843}, {\"epoch\": 50, \"metric\": \"Validation Accuracy\", \"value\": 0.6613578200340271}, {\"epoch\": 51, \"metric\": \"Validation Accuracy\", \"value\": 0.6624375581741333}, {\"epoch\": 52, \"metric\": \"Validation Accuracy\", \"value\": 0.6641921997070312}, {\"epoch\": 53, \"metric\": \"Validation Accuracy\", \"value\": 0.6590632796287537}, {\"epoch\": 54, \"metric\": \"Validation Accuracy\", \"value\": 0.6589283347129822}, {\"epoch\": 55, \"metric\": \"Validation Accuracy\", \"value\": 0.6614927649497986}, {\"epoch\": 56, \"metric\": \"Validation Accuracy\", \"value\": 0.6691861152648926}, {\"epoch\": 57, \"metric\": \"Validation Accuracy\", \"value\": 0.6726953983306885}, {\"epoch\": 58, \"metric\": \"Validation Accuracy\", \"value\": 0.6624375581741333}, {\"epoch\": 59, \"metric\": \"Validation Accuracy\", \"value\": 0.6625725626945496}, {\"epoch\": 60, \"metric\": \"Validation Accuracy\", \"value\": 0.6647320985794067}, {\"epoch\": 61, \"metric\": \"Validation Accuracy\", \"value\": 0.6640572547912598}, {\"epoch\": 62, \"metric\": \"Validation Accuracy\", \"value\": 0.6666216850280762}, {\"epoch\": 63, \"metric\": \"Validation Accuracy\", \"value\": 0.6648670434951782}, {\"epoch\": 64, \"metric\": \"Validation Accuracy\", \"value\": 0.6624375581741333}, {\"epoch\": 65, \"metric\": \"Validation Accuracy\", \"value\": 0.663382351398468}, {\"epoch\": 66, \"metric\": \"Validation Accuracy\", \"value\": 0.6566337943077087}, {\"epoch\": 67, \"metric\": \"Validation Accuracy\", \"value\": 0.6629774570465088}, {\"epoch\": 68, \"metric\": \"Validation Accuracy\", \"value\": 0.6623026132583618}, {\"epoch\": 69, \"metric\": \"Validation Accuracy\", \"value\": 0.6621676087379456}, {\"epoch\": 70, \"metric\": \"Validation Accuracy\", \"value\": 0.6663517355918884}, {\"epoch\": 71, \"metric\": \"Validation Accuracy\", \"value\": 0.6636523008346558}, {\"epoch\": 72, \"metric\": \"Validation Accuracy\", \"value\": 0.6658118367195129}, {\"epoch\": 73, \"metric\": \"Validation Accuracy\", \"value\": 0.6628425121307373}, {\"epoch\": 74, \"metric\": \"Validation Accuracy\", \"value\": 0.6667566299438477}, {\"epoch\": 75, \"metric\": \"Validation Accuracy\", \"value\": 0.6601430773735046}, {\"epoch\": 76, \"metric\": \"Validation Accuracy\", \"value\": 0.6594682335853577}, {\"epoch\": 77, \"metric\": \"Validation Accuracy\", \"value\": 0.6579835414886475}, {\"epoch\": 78, \"metric\": \"Validation Accuracy\", \"value\": 0.6606829762458801}, {\"epoch\": 79, \"metric\": \"Validation Accuracy\", \"value\": 0.6621676087379456}, {\"epoch\": 80, \"metric\": \"Validation Accuracy\", \"value\": 0.6605479717254639}], \"data-09a91faa9431661e4dcee6af23283a38\": [{\"epoch\": 1, \"metric\": \"Training Loss\", \"value\": 0.7581524848937988}, {\"epoch\": 2, \"metric\": \"Training Loss\", \"value\": 0.6252113580703735}, {\"epoch\": 3, \"metric\": \"Training Loss\", \"value\": 0.4802745580673218}, {\"epoch\": 4, \"metric\": \"Training Loss\", \"value\": 0.3345939517021179}, {\"epoch\": 5, \"metric\": \"Training Loss\", \"value\": 0.23520611226558685}, {\"epoch\": 6, \"metric\": \"Training Loss\", \"value\": 0.17934584617614746}, {\"epoch\": 7, \"metric\": \"Training Loss\", \"value\": 0.13595181703567505}, {\"epoch\": 8, \"metric\": \"Training Loss\", \"value\": 0.11018867790699005}, {\"epoch\": 9, \"metric\": \"Training Loss\", \"value\": 0.09152988344430923}, {\"epoch\": 10, \"metric\": \"Training Loss\", \"value\": 0.08131565898656845}, {\"epoch\": 11, \"metric\": \"Training Loss\", \"value\": 0.06909508258104324}, {\"epoch\": 12, \"metric\": \"Training Loss\", \"value\": 0.06245880201458931}, {\"epoch\": 13, \"metric\": \"Training Loss\", \"value\": 0.05652933195233345}, {\"epoch\": 14, \"metric\": \"Training Loss\", \"value\": 0.05060673505067825}, {\"epoch\": 15, \"metric\": \"Training Loss\", \"value\": 0.04670022055506706}, {\"epoch\": 16, \"metric\": \"Training Loss\", \"value\": 0.04537181183695793}, {\"epoch\": 17, \"metric\": \"Training Loss\", \"value\": 0.04089296609163284}, {\"epoch\": 18, \"metric\": \"Training Loss\", \"value\": 0.03746962547302246}, {\"epoch\": 19, \"metric\": \"Training Loss\", \"value\": 0.036366648972034454}, {\"epoch\": 20, \"metric\": \"Training Loss\", \"value\": 0.031672403216362}, {\"epoch\": 21, \"metric\": \"Training Loss\", \"value\": 0.034616921097040176}, {\"epoch\": 22, \"metric\": \"Training Loss\", \"value\": 0.03211880102753639}, {\"epoch\": 23, \"metric\": \"Training Loss\", \"value\": 0.02703312784433365}, {\"epoch\": 24, \"metric\": \"Training Loss\", \"value\": 0.028335152193903923}, {\"epoch\": 25, \"metric\": \"Training Loss\", \"value\": 0.02691144309937954}, {\"epoch\": 26, \"metric\": \"Training Loss\", \"value\": 0.023148247972130775}, {\"epoch\": 27, \"metric\": \"Training Loss\", \"value\": 0.02258305810391903}, {\"epoch\": 28, \"metric\": \"Training Loss\", \"value\": 0.022781554609537125}, {\"epoch\": 29, \"metric\": \"Training Loss\", \"value\": 0.022755231708288193}, {\"epoch\": 30, \"metric\": \"Training Loss\", \"value\": 0.0197935551404953}, {\"epoch\": 31, \"metric\": \"Training Loss\", \"value\": 0.02138410694897175}, {\"epoch\": 32, \"metric\": \"Training Loss\", \"value\": 0.020734619349241257}, {\"epoch\": 33, \"metric\": \"Training Loss\", \"value\": 0.02050372213125229}, {\"epoch\": 34, \"metric\": \"Training Loss\", \"value\": 0.01848636195063591}, {\"epoch\": 35, \"metric\": \"Training Loss\", \"value\": 0.018363244831562042}, {\"epoch\": 36, \"metric\": \"Training Loss\", \"value\": 0.017915984615683556}, {\"epoch\": 37, \"metric\": \"Training Loss\", \"value\": 0.015937745571136475}, {\"epoch\": 38, \"metric\": \"Training Loss\", \"value\": 0.01580338552594185}, {\"epoch\": 39, \"metric\": \"Training Loss\", \"value\": 0.01638607867062092}, {\"epoch\": 40, \"metric\": \"Training Loss\", \"value\": 0.015180139802396297}, {\"epoch\": 41, \"metric\": \"Training Loss\", \"value\": 0.014315434731543064}, {\"epoch\": 42, \"metric\": \"Training Loss\", \"value\": 0.015286280773580074}, {\"epoch\": 43, \"metric\": \"Training Loss\", \"value\": 0.015119150280952454}, {\"epoch\": 44, \"metric\": \"Training Loss\", \"value\": 0.014332696795463562}, {\"epoch\": 45, \"metric\": \"Training Loss\", \"value\": 0.01309904083609581}, {\"epoch\": 46, \"metric\": \"Training Loss\", \"value\": 0.014828590676188469}, {\"epoch\": 47, \"metric\": \"Training Loss\", \"value\": 0.012735571712255478}, {\"epoch\": 48, \"metric\": \"Training Loss\", \"value\": 0.013497625477612019}, {\"epoch\": 49, \"metric\": \"Training Loss\", \"value\": 0.012272427789866924}, {\"epoch\": 50, \"metric\": \"Training Loss\", \"value\": 0.012457813136279583}, {\"epoch\": 51, \"metric\": \"Training Loss\", \"value\": 0.009583605453372002}, {\"epoch\": 52, \"metric\": \"Training Loss\", \"value\": 0.010551955550909042}, {\"epoch\": 53, \"metric\": \"Training Loss\", \"value\": 0.011764480732381344}, {\"epoch\": 54, \"metric\": \"Training Loss\", \"value\": 0.011900101788341999}, {\"epoch\": 55, \"metric\": \"Training Loss\", \"value\": 0.010367291048169136}, {\"epoch\": 56, \"metric\": \"Training Loss\", \"value\": 0.009827198460698128}, {\"epoch\": 57, \"metric\": \"Training Loss\", \"value\": 0.011044074781239033}, {\"epoch\": 58, \"metric\": \"Training Loss\", \"value\": 0.010656309314072132}, {\"epoch\": 59, \"metric\": \"Training Loss\", \"value\": 0.00888175331056118}, {\"epoch\": 60, \"metric\": \"Training Loss\", \"value\": 0.010630756616592407}, {\"epoch\": 61, \"metric\": \"Training Loss\", \"value\": 0.010545304976403713}, {\"epoch\": 62, \"metric\": \"Training Loss\", \"value\": 0.009569293819367886}, {\"epoch\": 63, \"metric\": \"Training Loss\", \"value\": 0.010568078607320786}, {\"epoch\": 64, \"metric\": \"Training Loss\", \"value\": 0.00746958190575242}, {\"epoch\": 65, \"metric\": \"Training Loss\", \"value\": 0.008223393931984901}, {\"epoch\": 66, \"metric\": \"Training Loss\", \"value\": 0.008634218946099281}, {\"epoch\": 67, \"metric\": \"Training Loss\", \"value\": 0.010598558001220226}, {\"epoch\": 68, \"metric\": \"Training Loss\", \"value\": 0.008439143188297749}, {\"epoch\": 69, \"metric\": \"Training Loss\", \"value\": 0.008043834939599037}, {\"epoch\": 70, \"metric\": \"Training Loss\", \"value\": 0.009270232170820236}, {\"epoch\": 71, \"metric\": \"Training Loss\", \"value\": 0.009273081086575985}, {\"epoch\": 72, \"metric\": \"Training Loss\", \"value\": 0.007699036970734596}, {\"epoch\": 73, \"metric\": \"Training Loss\", \"value\": 0.007429551333189011}, {\"epoch\": 74, \"metric\": \"Training Loss\", \"value\": 0.007290474604815245}, {\"epoch\": 75, \"metric\": \"Training Loss\", \"value\": 0.008559044450521469}, {\"epoch\": 76, \"metric\": \"Training Loss\", \"value\": 0.007919530384242535}, {\"epoch\": 77, \"metric\": \"Training Loss\", \"value\": 0.00847025029361248}, {\"epoch\": 78, \"metric\": \"Training Loss\", \"value\": 0.006865199189633131}, {\"epoch\": 79, \"metric\": \"Training Loss\", \"value\": 0.008681739680469036}, {\"epoch\": 80, \"metric\": \"Training Loss\", \"value\": 0.007166403345763683}, {\"epoch\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7381669282913208}, {\"epoch\": 2, \"metric\": \"Validation Loss\", \"value\": 0.720087468624115}, {\"epoch\": 3, \"metric\": \"Validation Loss\", \"value\": 0.8073447942733765}, {\"epoch\": 4, \"metric\": \"Validation Loss\", \"value\": 0.9401220679283142}, {\"epoch\": 5, \"metric\": \"Validation Loss\", \"value\": 1.2046319246292114}, {\"epoch\": 6, \"metric\": \"Validation Loss\", \"value\": 1.4385849237442017}, {\"epoch\": 7, \"metric\": \"Validation Loss\", \"value\": 1.5346463918685913}, {\"epoch\": 8, \"metric\": \"Validation Loss\", \"value\": 1.832830786705017}, {\"epoch\": 9, \"metric\": \"Validation Loss\", \"value\": 1.8718749284744263}, {\"epoch\": 10, \"metric\": \"Validation Loss\", \"value\": 1.818366527557373}, {\"epoch\": 11, \"metric\": \"Validation Loss\", \"value\": 2.1961710453033447}, {\"epoch\": 12, \"metric\": \"Validation Loss\", \"value\": 2.23947811126709}, {\"epoch\": 13, \"metric\": \"Validation Loss\", \"value\": 2.2536091804504395}, {\"epoch\": 14, \"metric\": \"Validation Loss\", \"value\": 2.2683889865875244}, {\"epoch\": 15, \"metric\": \"Validation Loss\", \"value\": 2.268594264984131}, {\"epoch\": 16, \"metric\": \"Validation Loss\", \"value\": 2.2647488117218018}, {\"epoch\": 17, \"metric\": \"Validation Loss\", \"value\": 2.45090913772583}, {\"epoch\": 18, \"metric\": \"Validation Loss\", \"value\": 2.4414496421813965}, {\"epoch\": 19, \"metric\": \"Validation Loss\", \"value\": 2.53328013420105}, {\"epoch\": 20, \"metric\": \"Validation Loss\", \"value\": 2.6525166034698486}, {\"epoch\": 21, \"metric\": \"Validation Loss\", \"value\": 2.540128469467163}, {\"epoch\": 22, \"metric\": \"Validation Loss\", \"value\": 2.5779995918273926}, {\"epoch\": 23, \"metric\": \"Validation Loss\", \"value\": 2.7435226440429688}, {\"epoch\": 24, \"metric\": \"Validation Loss\", \"value\": 2.7446088790893555}, {\"epoch\": 25, \"metric\": \"Validation Loss\", \"value\": 2.585000514984131}, {\"epoch\": 26, \"metric\": \"Validation Loss\", \"value\": 2.8889007568359375}, {\"epoch\": 27, \"metric\": \"Validation Loss\", \"value\": 2.9699926376342773}, {\"epoch\": 28, \"metric\": \"Validation Loss\", \"value\": 2.709104061126709}, {\"epoch\": 29, \"metric\": \"Validation Loss\", \"value\": 2.804914951324463}, {\"epoch\": 30, \"metric\": \"Validation Loss\", \"value\": 2.8587286472320557}, {\"epoch\": 31, \"metric\": \"Validation Loss\", \"value\": 2.8090991973876953}, {\"epoch\": 32, \"metric\": \"Validation Loss\", \"value\": 3.1747517585754395}, {\"epoch\": 33, \"metric\": \"Validation Loss\", \"value\": 2.739495277404785}, {\"epoch\": 34, \"metric\": \"Validation Loss\", \"value\": 3.215644598007202}, {\"epoch\": 35, \"metric\": \"Validation Loss\", \"value\": 3.0567586421966553}, {\"epoch\": 36, \"metric\": \"Validation Loss\", \"value\": 3.215141534805298}, {\"epoch\": 37, \"metric\": \"Validation Loss\", \"value\": 3.366436004638672}, {\"epoch\": 38, \"metric\": \"Validation Loss\", \"value\": 3.5439276695251465}, {\"epoch\": 39, \"metric\": \"Validation Loss\", \"value\": 3.1660430431365967}, {\"epoch\": 40, \"metric\": \"Validation Loss\", \"value\": 3.136889934539795}, {\"epoch\": 41, \"metric\": \"Validation Loss\", \"value\": 3.604515790939331}, {\"epoch\": 42, \"metric\": \"Validation Loss\", \"value\": 3.2332394123077393}, {\"epoch\": 43, \"metric\": \"Validation Loss\", \"value\": 3.1992740631103516}, {\"epoch\": 44, \"metric\": \"Validation Loss\", \"value\": 3.106781244277954}, {\"epoch\": 45, \"metric\": \"Validation Loss\", \"value\": 3.7293102741241455}, {\"epoch\": 46, \"metric\": \"Validation Loss\", \"value\": 2.865161180496216}, {\"epoch\": 47, \"metric\": \"Validation Loss\", \"value\": 3.2989418506622314}, {\"epoch\": 48, \"metric\": \"Validation Loss\", \"value\": 3.3579225540161133}, {\"epoch\": 49, \"metric\": \"Validation Loss\", \"value\": 3.9792139530181885}, {\"epoch\": 50, \"metric\": \"Validation Loss\", \"value\": 3.594238758087158}, {\"epoch\": 51, \"metric\": \"Validation Loss\", \"value\": 3.824070453643799}, {\"epoch\": 52, \"metric\": \"Validation Loss\", \"value\": 4.299159526824951}, {\"epoch\": 53, \"metric\": \"Validation Loss\", \"value\": 3.754051685333252}, {\"epoch\": 54, \"metric\": \"Validation Loss\", \"value\": 3.82776141166687}, {\"epoch\": 55, \"metric\": \"Validation Loss\", \"value\": 4.051171779632568}, {\"epoch\": 56, \"metric\": \"Validation Loss\", \"value\": 3.675837516784668}, {\"epoch\": 57, \"metric\": \"Validation Loss\", \"value\": 4.196296691894531}, {\"epoch\": 58, \"metric\": \"Validation Loss\", \"value\": 4.200723171234131}, {\"epoch\": 59, \"metric\": \"Validation Loss\", \"value\": 4.587156295776367}, {\"epoch\": 60, \"metric\": \"Validation Loss\", \"value\": 3.709333658218384}, {\"epoch\": 61, \"metric\": \"Validation Loss\", \"value\": 3.6087074279785156}, {\"epoch\": 62, \"metric\": \"Validation Loss\", \"value\": 3.6557486057281494}, {\"epoch\": 63, \"metric\": \"Validation Loss\", \"value\": 4.172222137451172}, {\"epoch\": 64, \"metric\": \"Validation Loss\", \"value\": 4.637632369995117}, {\"epoch\": 65, \"metric\": \"Validation Loss\", \"value\": 4.218421459197998}, {\"epoch\": 66, \"metric\": \"Validation Loss\", \"value\": 5.101426124572754}, {\"epoch\": 67, \"metric\": \"Validation Loss\", \"value\": 4.021761894226074}, {\"epoch\": 68, \"metric\": \"Validation Loss\", \"value\": 4.106746196746826}, {\"epoch\": 69, \"metric\": \"Validation Loss\", \"value\": 4.484408378601074}, {\"epoch\": 70, \"metric\": \"Validation Loss\", \"value\": 4.415560722351074}, {\"epoch\": 71, \"metric\": \"Validation Loss\", \"value\": 4.515346050262451}, {\"epoch\": 72, \"metric\": \"Validation Loss\", \"value\": 4.686837196350098}, {\"epoch\": 73, \"metric\": \"Validation Loss\", \"value\": 4.220017433166504}, {\"epoch\": 74, \"metric\": \"Validation Loss\", \"value\": 4.50567102432251}, {\"epoch\": 75, \"metric\": \"Validation Loss\", \"value\": 5.638530254364014}, {\"epoch\": 76, \"metric\": \"Validation Loss\", \"value\": 5.411885738372803}, {\"epoch\": 77, \"metric\": \"Validation Loss\", \"value\": 4.7683844566345215}, {\"epoch\": 78, \"metric\": \"Validation Loss\", \"value\": 4.538104057312012}, {\"epoch\": 79, \"metric\": \"Validation Loss\", \"value\": 4.2540388107299805}, {\"epoch\": 80, \"metric\": \"Validation Loss\", \"value\": 5.082311153411865}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "# Select a complex model that overfits\n",
    "model_overfit = Sequential([\n",
    "    InputLayer(input_shape=(462,)),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_overfit.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_overfit = model_overfit.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=80,  # Increased epochs to observe overfitting\n",
    "    batch_size=32,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Prepare data for plotting\n",
    "df_overfit = pd.DataFrame({\n",
    "    'epoch': range(1, 81),\n",
    "    'training_accuracy': history_overfit.history['accuracy'],\n",
    "    'validation_accuracy': history_overfit.history['val_accuracy'],\n",
    "    'training_loss': history_overfit.history['loss'],\n",
    "    'validation_loss': history_overfit.history['val_loss']\n",
    "})\n",
    "\n",
    "# Melt the dataframe for long format\n",
    "df_overfit_long = df_overfit.melt(id_vars=['epoch'], \n",
    "                                  value_vars=['training_accuracy', 'validation_accuracy', 'training_loss', 'validation_loss'],\n",
    "                                  var_name='metric', value_name='value')\n",
    "\n",
    "# Define the color mapping for metrics\n",
    "color_mapping = {\n",
    "    'training_accuracy': 'Training Accuracy',\n",
    "    'validation_accuracy': 'Validation Accuracy',\n",
    "    'training_loss': 'Training Loss',\n",
    "    'validation_loss': 'Validation Loss'\n",
    "}\n",
    "\n",
    "df_overfit_long['metric'] = df_overfit_long['metric'].map(color_mapping)\n",
    "\n",
    "# Altair plot: Interactive plot for accuracy and loss\n",
    "accuracy_chart = alt.Chart(df_overfit_long[df_overfit_long['metric'].str.contains('Accuracy')]).mark_line().encode(\n",
    "    x='epoch',\n",
    "    y='value',\n",
    "    color='metric',\n",
    "    tooltip=['epoch', 'value', 'metric']\n",
    ").properties(\n",
    "    title=\"Model Accuracy Illustrating Overfitting\",\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "loss_chart = alt.Chart(df_overfit_long[df_overfit_long['metric'].str.contains('Loss')]).mark_line().encode(\n",
    "    x='epoch',\n",
    "    y='value',\n",
    "    color='metric',\n",
    "    tooltip=['epoch', 'value', 'metric']\n",
    ").properties(\n",
    "    title=\"Model Loss Illustrating Overfitting\",\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Display the charts\n",
    "(accuracy_chart & loss_chart).display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy:\n",
    "- The training precision quickly reaches nearly 100%, indicating that the model is very effective at memorizing the training data.\n",
    "- The validation precision remains stable around 65%, with no significant improvement, suggesting that the model is unable to generalize to unseen data.\n",
    "\n",
    "Loss:\n",
    "- The training loss decreases rapidly, nearing zero, which is typical of a model that perfectly fits the training data.\n",
    "- The validation loss increases continuously and even becomes unstable, which is a classic sign of overfitting, where the model is too tailored to the training data and fails to generalize.\n",
    "\n",
    "Key indicators of overfitting in the graph:\n",
    "  - The training performance continues to improve while the validation performance dicreases.\n",
    "  - A significant gap between training and validation performance metrics.\n",
    "  \n",
    "By examining these indicators in the graph, we can conclude that the model is overfitting.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - **Activation function**.\n",
    "\n",
    "        - Present results for one of the configurations mentioned above by varying the activation function. Test at least `relu` (the default) and `sigmoid`. The choice of the specific model, including the number of layers and nodes, is at your discretion. Document your observations accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with activation function: relu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with activation function: sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-73a053f4fbd744258b13f017ea93751d.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-73a053f4fbd744258b13f017ea93751d.vega-embed details,\n",
       "  #altair-viz-73a053f4fbd744258b13f017ea93751d.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-73a053f4fbd744258b13f017ea93751d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-73a053f4fbd744258b13f017ea93751d\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-73a053f4fbd744258b13f017ea93751d\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-86a0286847a3ab724db44a66fcd676ca\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"column\": {\"field\": \"activation\", \"type\": \"ordinal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}, {\"field\": \"activation\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Model Performance: Accuracy & Loss for Different Activation Functions\", \"width\": 300, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-86a0286847a3ab724db44a66fcd676ca\": [{\"epoch\": 1, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.6694515347480774}, {\"epoch\": 2, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.720368504524231}, {\"epoch\": 3, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.7588649988174438}, {\"epoch\": 4, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.7940676808357239}, {\"epoch\": 5, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.8243468403816223}, {\"epoch\": 6, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.8510404825210571}, {\"epoch\": 7, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.8736168742179871}, {\"epoch\": 8, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.8938429355621338}, {\"epoch\": 9, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9080303907394409}, {\"epoch\": 10, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9187009930610657}, {\"epoch\": 11, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9283766150474548}, {\"epoch\": 12, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9359249472618103}, {\"epoch\": 13, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9433188438415527}, {\"epoch\": 14, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9486370086669922}, {\"epoch\": 15, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9518622159957886}, {\"epoch\": 16, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9568544030189514}, {\"epoch\": 17, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9591875076293945}, {\"epoch\": 18, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9627043604850769}, {\"epoch\": 19, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9647115468978882}, {\"epoch\": 20, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9669932126998901}, {\"epoch\": 21, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9684857130050659}, {\"epoch\": 22, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.971693754196167}, {\"epoch\": 23, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9737867116928101}, {\"epoch\": 24, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9738209843635559}, {\"epoch\": 25, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.974798858165741}, {\"epoch\": 26, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9741812348365784}, {\"epoch\": 27, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.977475106716156}, {\"epoch\": 28, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9796709418296814}, {\"epoch\": 29, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9787102937698364}, {\"epoch\": 30, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9796195030212402}, {\"epoch\": 31, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9815237522125244}, {\"epoch\": 32, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9818325042724609}, {\"epoch\": 33, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9821928143501282}, {\"epoch\": 34, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9817982316017151}, {\"epoch\": 35, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9841999411582947}, {\"epoch\": 36, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9836167097091675}, {\"epoch\": 37, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9843200445175171}, {\"epoch\": 38, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9850234389305115}, {\"epoch\": 39, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.984508752822876}, {\"epoch\": 40, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9844744205474854}, {\"epoch\": 41, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9860184192657471}, {\"epoch\": 42, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9871678352355957}, {\"epoch\": 43, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9868247509002686}, {\"epoch\": 44, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9863786697387695}, {\"epoch\": 45, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9857267737388611}, {\"epoch\": 46, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9879912734031677}, {\"epoch\": 47, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9876653552055359}, {\"epoch\": 48, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9876824617385864}, {\"epoch\": 49, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9876310229301453}, {\"epoch\": 50, \"activation\": \"relu\", \"metric\": \"Training Accuracy\", \"value\": 0.9891063570976257}, {\"epoch\": 1, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.684707760810852}, {\"epoch\": 2, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.7053583264350891}, {\"epoch\": 3, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.7087326049804688}, {\"epoch\": 4, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.7034687399864197}, {\"epoch\": 5, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6884869933128357}, {\"epoch\": 6, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6844378709793091}, {\"epoch\": 7, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6729652881622314}, {\"epoch\": 8, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6679713726043701}, {\"epoch\": 9, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6602780222892761}, {\"epoch\": 10, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6540693640708923}, {\"epoch\": 11, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6450263261795044}, {\"epoch\": 12, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6461060643196106}, {\"epoch\": 13, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6390876173973083}, {\"epoch\": 14, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6342286467552185}, {\"epoch\": 15, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6397624611854553}, {\"epoch\": 16, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6324740052223206}, {\"epoch\": 17, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6361182332038879}, {\"epoch\": 18, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6374679207801819}, {\"epoch\": 19, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6359832882881165}, {\"epoch\": 20, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6322040557861328}, {\"epoch\": 21, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6342286467552185}, {\"epoch\": 22, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6270751953125}, {\"epoch\": 23, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6377378702163696}, {\"epoch\": 24, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6388176679611206}, {\"epoch\": 25, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6299095749855042}, {\"epoch\": 26, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6295046806335449}, {\"epoch\": 27, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6309893131256104}, {\"epoch\": 28, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.633013904094696}, {\"epoch\": 29, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6311243176460266}, {\"epoch\": 30, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6301795244216919}, {\"epoch\": 31, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.634768545627594}, {\"epoch\": 32, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6331488490104675}, {\"epoch\": 33, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6411121487617493}, {\"epoch\": 34, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.635443389415741}, {\"epoch\": 35, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.63436359167099}, {\"epoch\": 36, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6349034905433655}, {\"epoch\": 37, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6286948323249817}, {\"epoch\": 38, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.634768545627594}, {\"epoch\": 39, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6382777690887451}, {\"epoch\": 40, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6307194232940674}, {\"epoch\": 41, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6369280815124512}, {\"epoch\": 42, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6392225623130798}, {\"epoch\": 43, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6419219970703125}, {\"epoch\": 44, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6376029253005981}, {\"epoch\": 45, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6455662250518799}, {\"epoch\": 46, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.642731785774231}, {\"epoch\": 47, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6409772038459778}, {\"epoch\": 48, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6403023600578308}, {\"epoch\": 49, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6419219970703125}, {\"epoch\": 50, \"activation\": \"relu\", \"metric\": \"Validation Accuracy\", \"value\": 0.6324740052223206}, {\"epoch\": 1, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.7669419646263123}, {\"epoch\": 2, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.6720422506332397}, {\"epoch\": 3, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.5870301723480225}, {\"epoch\": 4, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.5123437643051147}, {\"epoch\": 5, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.4453624188899994}, {\"epoch\": 6, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.3860641121864319}, {\"epoch\": 7, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.3325689136981964}, {\"epoch\": 8, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.28550100326538086}, {\"epoch\": 9, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.25014376640319824}, {\"epoch\": 10, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.21861532330513}, {\"epoch\": 11, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.19346939027309418}, {\"epoch\": 12, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.17365996539592743}, {\"epoch\": 13, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.1541832983493805}, {\"epoch\": 14, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.14031243324279785}, {\"epoch\": 15, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.13314031064510345}, {\"epoch\": 16, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.11719435453414917}, {\"epoch\": 17, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.11190005391836166}, {\"epoch\": 18, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.1033879965543747}, {\"epoch\": 19, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.09805534780025482}, {\"epoch\": 20, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.09150519222021103}, {\"epoch\": 21, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.08770091831684113}, {\"epoch\": 22, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.0774569883942604}, {\"epoch\": 23, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.07326369732618332}, {\"epoch\": 24, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.07433860003948212}, {\"epoch\": 25, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.06980419158935547}, {\"epoch\": 26, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.07283961772918701}, {\"epoch\": 27, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.06372635811567307}, {\"epoch\": 28, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.05735236033797264}, {\"epoch\": 29, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.060083240270614624}, {\"epoch\": 30, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.05735468119382858}, {\"epoch\": 31, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.05412440001964569}, {\"epoch\": 32, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.05368473008275032}, {\"epoch\": 33, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.05196474865078926}, {\"epoch\": 34, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.0529816597700119}, {\"epoch\": 35, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.04620060697197914}, {\"epoch\": 36, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.04795369505882263}, {\"epoch\": 37, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.04582049325108528}, {\"epoch\": 38, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.043092917650938034}, {\"epoch\": 39, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.043000541627407074}, {\"epoch\": 40, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.04452391713857651}, {\"epoch\": 41, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.04229016229510307}, {\"epoch\": 42, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.038937751203775406}, {\"epoch\": 43, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.0384419821202755}, {\"epoch\": 44, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.03950609266757965}, {\"epoch\": 45, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.04057819023728371}, {\"epoch\": 46, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.037153441458940506}, {\"epoch\": 47, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.03648656979203224}, {\"epoch\": 48, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.03619978949427605}, {\"epoch\": 49, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.0357450433075428}, {\"epoch\": 50, \"activation\": \"relu\", \"metric\": \"Training Loss\", \"value\": 0.03150719404220581}, {\"epoch\": 1, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 0.7400123476982117}, {\"epoch\": 2, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 0.6983593106269836}, {\"epoch\": 3, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 0.7084799408912659}, {\"epoch\": 4, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 0.7513790130615234}, {\"epoch\": 5, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 0.8157235383987427}, {\"epoch\": 6, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 0.9009950757026672}, {\"epoch\": 7, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 0.997350811958313}, {\"epoch\": 8, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 1.1367768049240112}, {\"epoch\": 9, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 1.2558033466339111}, {\"epoch\": 10, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 1.3918484449386597}, {\"epoch\": 11, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 1.5092535018920898}, {\"epoch\": 12, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 1.6700700521469116}, {\"epoch\": 13, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 1.7829382419586182}, {\"epoch\": 14, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 1.8820315599441528}, {\"epoch\": 15, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 2.0087432861328125}, {\"epoch\": 16, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 2.158863067626953}, {\"epoch\": 17, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 2.220322370529175}, {\"epoch\": 18, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 2.292949676513672}, {\"epoch\": 19, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 2.4257915019989014}, {\"epoch\": 20, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 2.487515449523926}, {\"epoch\": 21, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 2.5870418548583984}, {\"epoch\": 22, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 2.6143581867218018}, {\"epoch\": 23, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 2.7575953006744385}, {\"epoch\": 24, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 2.8686795234680176}, {\"epoch\": 25, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 2.949680805206299}, {\"epoch\": 26, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 2.9871554374694824}, {\"epoch\": 27, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 3.0635831356048584}, {\"epoch\": 28, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 3.2010695934295654}, {\"epoch\": 29, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 3.1714529991149902}, {\"epoch\": 30, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 3.265876531600952}, {\"epoch\": 31, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 3.410597801208496}, {\"epoch\": 32, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 3.389636278152466}, {\"epoch\": 33, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 3.548027276992798}, {\"epoch\": 34, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 3.4779675006866455}, {\"epoch\": 35, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 3.6792361736297607}, {\"epoch\": 36, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 3.757688045501709}, {\"epoch\": 37, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 3.6897644996643066}, {\"epoch\": 38, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 3.824582576751709}, {\"epoch\": 39, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 3.830791711807251}, {\"epoch\": 40, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 3.855879545211792}, {\"epoch\": 41, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 4.0302839279174805}, {\"epoch\": 42, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 4.001900672912598}, {\"epoch\": 43, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 4.036313056945801}, {\"epoch\": 44, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 4.125609397888184}, {\"epoch\": 45, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 4.13224983215332}, {\"epoch\": 46, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 4.306674957275391}, {\"epoch\": 47, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 4.267326354980469}, {\"epoch\": 48, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 4.305502891540527}, {\"epoch\": 49, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 4.385069370269775}, {\"epoch\": 50, \"activation\": \"relu\", \"metric\": \"Validation Loss\", \"value\": 4.390232086181641}, {\"epoch\": 1, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.6485563516616821}, {\"epoch\": 2, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.6860750317573547}, {\"epoch\": 3, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.6883051991462708}, {\"epoch\": 4, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.689917802810669}, {\"epoch\": 5, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.6907069683074951}, {\"epoch\": 6, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.6915475726127625}, {\"epoch\": 7, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.6926798224449158}, {\"epoch\": 8, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.693709135055542}, {\"epoch\": 9, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.6940522789955139}, {\"epoch\": 10, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.6947556138038635}, {\"epoch\": 11, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.6960765719413757}, {\"epoch\": 12, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.6979464888572693}, {\"epoch\": 13, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.7007085084915161}, {\"epoch\": 14, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.7052031755447388}, {\"epoch\": 15, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.7126314640045166}, {\"epoch\": 16, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.7231305241584778}, {\"epoch\": 17, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.7312106490135193}, {\"epoch\": 18, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.7377468347549438}, {\"epoch\": 19, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.7445060014724731}, {\"epoch\": 20, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.7510421872138977}, {\"epoch\": 21, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.756154477596283}, {\"epoch\": 22, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.7619872689247131}, {\"epoch\": 23, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.7684205174446106}, {\"epoch\": 24, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.7754027247428894}, {\"epoch\": 25, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.7827795147895813}, {\"epoch\": 26, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.7909625768661499}, {\"epoch\": 27, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.7985966801643372}, {\"epoch\": 28, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.808255136013031}, {\"epoch\": 29, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.8173131346702576}, {\"epoch\": 30, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.8269887566566467}, {\"epoch\": 31, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.8366643190383911}, {\"epoch\": 32, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.846717357635498}, {\"epoch\": 33, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.8569418787956238}, {\"epoch\": 34, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.8668404817581177}, {\"epoch\": 35, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.8766190409660339}, {\"epoch\": 36, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.8857971429824829}, {\"epoch\": 37, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.8943747878074646}, {\"epoch\": 38, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.9023863077163696}, {\"epoch\": 39, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.9100204110145569}, {\"epoch\": 40, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.9179461598396301}, {\"epoch\": 41, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.9252715110778809}, {\"epoch\": 42, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.9324595332145691}, {\"epoch\": 43, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.939012885093689}, {\"epoch\": 44, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.9449486136436462}, {\"epoch\": 45, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.9507642984390259}, {\"epoch\": 46, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.956442654132843}, {\"epoch\": 47, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.961537778377533}, {\"epoch\": 48, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.9663069844245911}, {\"epoch\": 49, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.9709217548370361}, {\"epoch\": 50, \"activation\": \"sigmoid\", \"metric\": \"Training Accuracy\", \"value\": 0.9746615886688232}, {\"epoch\": 1, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6720204949378967}, {\"epoch\": 2, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6782291531562805}, {\"epoch\": 3, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6763395667076111}, {\"epoch\": 4, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6763395667076111}, {\"epoch\": 5, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6763395667076111}, {\"epoch\": 6, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6757997274398804}, {\"epoch\": 7, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6749898791313171}, {\"epoch\": 8, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6757997274398804}, {\"epoch\": 9, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6768794655799866}, {\"epoch\": 10, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6784991025924683}, {\"epoch\": 11, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6793089509010315}, {\"epoch\": 12, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6818733811378479}, {\"epoch\": 13, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.684707760810852}, {\"epoch\": 14, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6906465291976929}, {\"epoch\": 15, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6949656009674072}, {\"epoch\": 16, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.7029288411140442}, {\"epoch\": 17, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.7053583264350891}, {\"epoch\": 18, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.708867609500885}, {\"epoch\": 19, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.7098124027252197}, {\"epoch\": 20, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.7107571959495544}, {\"epoch\": 21, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.7130516767501831}, {\"epoch\": 22, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.7127817273139954}, {\"epoch\": 23, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.7117019891738892}, {\"epoch\": 24, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.7106221914291382}, {\"epoch\": 25, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.7079228162765503}, {\"epoch\": 26, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.7056282758712769}, {\"epoch\": 27, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.7026589512825012}, {\"epoch\": 28, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6988797187805176}, {\"epoch\": 29, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6961803436279297}, {\"epoch\": 30, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6930760145187378}, {\"epoch\": 31, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6913213729858398}, {\"epoch\": 32, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.687137246131897}, {\"epoch\": 33, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6833580732345581}, {\"epoch\": 34, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6779592633247375}, {\"epoch\": 35, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6741800308227539}, {\"epoch\": 36, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.671075701713562}, {\"epoch\": 37, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6655418872833252}, {\"epoch\": 38, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6613578200340271}, {\"epoch\": 39, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6570387482643127}, {\"epoch\": 40, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6527196764945984}, {\"epoch\": 41, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6498852968215942}, {\"epoch\": 42, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6467809677124023}, {\"epoch\": 43, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6446214318275452}, {\"epoch\": 44, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6415171027183533}, {\"epoch\": 45, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6409772038459778}, {\"epoch\": 46, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6412471532821655}, {\"epoch\": 47, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6385477185249329}, {\"epoch\": 48, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6346335411071777}, {\"epoch\": 49, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6355783343315125}, {\"epoch\": 50, \"activation\": \"sigmoid\", \"metric\": \"Validation Accuracy\", \"value\": 0.6344985961914062}, {\"epoch\": 1, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.8067575097084045}, {\"epoch\": 2, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.7468363642692566}, {\"epoch\": 3, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.7417215704917908}, {\"epoch\": 4, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.7383081912994385}, {\"epoch\": 5, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.7356314063072205}, {\"epoch\": 6, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.7332576513290405}, {\"epoch\": 7, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.7308822274208069}, {\"epoch\": 8, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.7282191514968872}, {\"epoch\": 9, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.7251020669937134}, {\"epoch\": 10, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.7214885950088501}, {\"epoch\": 11, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.7172759771347046}, {\"epoch\": 12, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.7121609449386597}, {\"epoch\": 13, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.7054731845855713}, {\"epoch\": 14, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.6954332590103149}, {\"epoch\": 15, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.6788545250892639}, {\"epoch\": 16, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.657427191734314}, {\"epoch\": 17, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.6385084390640259}, {\"epoch\": 18, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.6227303147315979}, {\"epoch\": 19, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.6086363196372986}, {\"epoch\": 20, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.5953453183174133}, {\"epoch\": 21, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.5822530388832092}, {\"epoch\": 22, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.5688924789428711}, {\"epoch\": 23, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.554911196231842}, {\"epoch\": 24, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.5400437116622925}, {\"epoch\": 25, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.5240952372550964}, {\"epoch\": 26, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.5069311261177063}, {\"epoch\": 27, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.48851481080055237}, {\"epoch\": 28, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.46898046135902405}, {\"epoch\": 29, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.4486529231071472}, {\"epoch\": 30, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.4279012084007263}, {\"epoch\": 31, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.4070330262184143}, {\"epoch\": 32, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.3863038122653961}, {\"epoch\": 33, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.3659168481826782}, {\"epoch\": 34, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.34599408507347107}, {\"epoch\": 35, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.32657569646835327}, {\"epoch\": 36, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.3076578676700592}, {\"epoch\": 37, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.28925949335098267}, {\"epoch\": 38, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.27137136459350586}, {\"epoch\": 39, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.25398313999176025}, {\"epoch\": 40, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.23708082735538483}, {\"epoch\": 41, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.22067669034004211}, {\"epoch\": 42, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.2047683447599411}, {\"epoch\": 43, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.18934547901153564}, {\"epoch\": 44, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.1743835061788559}, {\"epoch\": 45, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.15989544987678528}, {\"epoch\": 46, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.1459600031375885}, {\"epoch\": 47, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.13258136808872223}, {\"epoch\": 48, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.11990045011043549}, {\"epoch\": 49, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.10795651376247406}, {\"epoch\": 50, \"activation\": \"sigmoid\", \"metric\": \"Training Loss\", \"value\": 0.09683307260274887}, {\"epoch\": 1, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7751586437225342}, {\"epoch\": 2, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7621958255767822}, {\"epoch\": 3, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7592988014221191}, {\"epoch\": 4, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7600371241569519}, {\"epoch\": 5, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7608086466789246}, {\"epoch\": 6, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7607743740081787}, {\"epoch\": 7, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7601398229598999}, {\"epoch\": 8, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7591841816902161}, {\"epoch\": 9, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7579815983772278}, {\"epoch\": 10, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7565444707870483}, {\"epoch\": 11, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7547096014022827}, {\"epoch\": 12, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7520422339439392}, {\"epoch\": 13, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7476027011871338}, {\"epoch\": 14, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7391541600227356}, {\"epoch\": 15, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7234480977058411}, {\"epoch\": 16, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7081050276756287}, {\"epoch\": 17, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.6999282836914062}, {\"epoch\": 18, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.6956831216812134}, {\"epoch\": 19, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.6938580870628357}, {\"epoch\": 20, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.6939395666122437}, {\"epoch\": 21, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.6956954002380371}, {\"epoch\": 22, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.6991179585456848}, {\"epoch\": 23, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7043547034263611}, {\"epoch\": 24, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7116186618804932}, {\"epoch\": 25, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7211639881134033}, {\"epoch\": 26, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7332639694213867}, {\"epoch\": 27, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7482116222381592}, {\"epoch\": 28, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7662805318832397}, {\"epoch\": 29, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.7876343131065369}, {\"epoch\": 30, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.8124312162399292}, {\"epoch\": 31, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.8409134149551392}, {\"epoch\": 32, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.8732520937919617}, {\"epoch\": 33, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.9098190665245056}, {\"epoch\": 34, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.9510254859924316}, {\"epoch\": 35, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 0.9971323013305664}, {\"epoch\": 36, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 1.0484079122543335}, {\"epoch\": 37, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 1.1050021648406982}, {\"epoch\": 38, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 1.167051076889038}, {\"epoch\": 39, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 1.23471999168396}, {\"epoch\": 40, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 1.3081973791122437}, {\"epoch\": 41, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 1.387819528579712}, {\"epoch\": 42, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 1.4746235609054565}, {\"epoch\": 43, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 1.5693613290786743}, {\"epoch\": 44, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 1.6731483936309814}, {\"epoch\": 45, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 1.7864060401916504}, {\"epoch\": 46, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 1.9099856615066528}, {\"epoch\": 47, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 2.0422699451446533}, {\"epoch\": 48, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 2.1827290058135986}, {\"epoch\": 49, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 2.329392194747925}, {\"epoch\": 50, \"activation\": \"sigmoid\", \"metric\": \"Validation Loss\", \"value\": 2.48620343208313}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define the model configuration\n",
    "num_layers = 2\n",
    "nodes_per_layer = 128\n",
    "activation_functions = ['relu', 'sigmoid']\n",
    "\n",
    "# Prepare a DataFrame to collect all metrics for plotting\n",
    "df_all_models = pd.DataFrame()\n",
    "\n",
    "for activation in activation_functions:\n",
    "    print(f\"\\nTraining model with activation function: {activation}\")\n",
    "    \n",
    "    # Define the model architecture\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=(462,)),\n",
    "        Dense(nodes_per_layer, activation=activation),\n",
    "        Dense(nodes_per_layer, activation=activation),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': range(1, 51),\n",
    "        'training_accuracy': history.history['accuracy'],\n",
    "        'validation_accuracy': history.history['val_accuracy'],\n",
    "        'training_loss': history.history['loss'],\n",
    "        'validation_loss': history.history['val_loss'],\n",
    "        'activation': [activation] * 50\n",
    "    })\n",
    "    \n",
    "    # Melt the dataframe for long format\n",
    "    df_long = df.melt(id_vars=['epoch', 'activation'], \n",
    "                      value_vars=['training_accuracy', 'validation_accuracy', 'training_loss', 'validation_loss'],\n",
    "                      var_name='metric', value_name='value')\n",
    "    \n",
    "    # Concatenate all data\n",
    "    df_all_models = pd.concat([df_all_models, df_long], ignore_index=True)\n",
    "\n",
    "# Define the color mapping for metrics\n",
    "color_mapping = {\n",
    "    'training_accuracy': 'Training Accuracy',\n",
    "    'validation_accuracy': 'Validation Accuracy',\n",
    "    'training_loss': 'Training Loss',\n",
    "    'validation_loss': 'Validation Loss'\n",
    "}\n",
    "\n",
    "df_all_models['metric'] = df_all_models['metric'].map(color_mapping)\n",
    "\n",
    "# Altair plot: Interactive plot for all models\n",
    "chart = alt.Chart(df_all_models).mark_line().encode(\n",
    "    x='epoch',\n",
    "    y='value',\n",
    "    color='metric',\n",
    "    column='activation:O',  # Separate charts for each activation function\n",
    "    tooltip=['epoch', 'value', 'metric', 'activation']\n",
    ").properties(\n",
    "    title=\"Model Performance: Accuracy & Loss for Different Activation Functions\",\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "chart.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance with Different Activation Functions\n",
    "\n",
    "In this section, we explore the impact of varying the activation function on the performance of our neural network model. We tested two activation functions: `relu` and `sigmoid`. The model configuration includes 2 hidden layers, each with 128 nodes.\n",
    "\n",
    "From the graphs, we can observe the following:\n",
    "\n",
    "- **ReLU Activation Function**:\n",
    "    - The training accuracy increases steadily over the epochs.\n",
    "    - The validation accuracy also improves but starts to plateau after a certain number of epochs.\n",
    "    - The training loss decreases consistently, indicating that the model is learning the training data well.\n",
    "    - The validation loss decreases initially but starts to increase after a certain number of epochs, indicating potential overfitting.\n",
    "\n",
    "- **Sigmoid Activation Function**:\n",
    "    - The training accuracy increases steadily but at a slower rate compared to ReLU.\n",
    "    - The validation accuracy shows a similar trend, improving initially but plateauing earlier than ReLU.\n",
    "    - The training loss decreases consistently, but the rate of decrease is slower than ReLU.\n",
    "    - The validation loss decreases initially but starts to increase earlier than ReLU, indicating overfitting.\n",
    "\n",
    "Overall, the ReLU activation function performs better in terms of both training and validation accuracy. However, both activation functions show signs of overfitting after a certain number of epochs. The choice of activation function can significantly impact the model's performance, and ReLU appears to be a better choice for this specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - **Regularization** in neural networks is a technique used to prevent overfitting.\n",
    "\n",
    "        - One technique involves adding a penalty to the loss function to discourage excessively complex models. Apply an `l2` penalty to some or all layers. Exercise caution, as overly aggressive penalties have been problematic in our experiments. Begin with the default `l2` value of 0.01, then reduce it to 0.001 and 1e-4. Select a specific model from the above experiments and present a case where you successfully reduced overfitting. Include a pair of graphs comparing results with and without regularization. Explain your rationale to conclude that overfitting has been reduced. Do not expect to completely eliminate overfitting. Again, this is a challenging dataset to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with L2 regularization (lambda=0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with L2 regularization (lambda=0.001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with L2 regularization (lambda=0.0001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-f35d0734d343434c91f4f3ace578a853.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-f35d0734d343434c91f4f3ace578a853.vega-embed details,\n",
       "  #altair-viz-f35d0734d343434c91f4f3ace578a853.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-f35d0734d343434c91f4f3ace578a853\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-f35d0734d343434c91f4f3ace578a853\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-f35d0734d343434c91f4f3ace578a853\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-234a3f4c77ea7dc75d9c63175f481817\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"column\": {\"field\": \"l2_value\", \"type\": \"ordinal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}, {\"field\": \"l2_value\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Model Performance: Accuracy & Loss for Different L2 Regularization Values\", \"width\": 300, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-234a3f4c77ea7dc75d9c63175f481817\": [{\"epoch\": 1, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6503405570983887}, {\"epoch\": 2, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6725738048553467}, {\"epoch\": 3, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6780120134353638}, {\"epoch\": 4, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6790756583213806}, {\"epoch\": 5, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6804652810096741}, {\"epoch\": 6, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.68609219789505}, {\"epoch\": 7, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6893860101699829}, {\"epoch\": 8, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6912387609481812}, {\"epoch\": 9, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6929200291633606}, {\"epoch\": 10, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6950644254684448}, {\"epoch\": 11, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6946526765823364}, {\"epoch\": 12, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6952874660491943}, {\"epoch\": 13, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6963167786598206}, {\"epoch\": 14, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6970029473304749}, {\"epoch\": 15, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6965569257736206}, {\"epoch\": 16, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6959050297737122}, {\"epoch\": 17, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6968657374382019}, {\"epoch\": 18, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6969171762466431}, {\"epoch\": 19, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6973803639411926}, {\"epoch\": 20, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.6994390487670898}, {\"epoch\": 21, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7026813626289368}, {\"epoch\": 22, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7032474875450134}, {\"epoch\": 23, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7037964463233948}, {\"epoch\": 24, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7034019231796265}, {\"epoch\": 25, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7028014659881592}, {\"epoch\": 26, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7042596340179443}, {\"epoch\": 27, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7034876942634583}, {\"epoch\": 28, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7028529047966003}, {\"epoch\": 29, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7036764025688171}, {\"epoch\": 30, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.703710675239563}, {\"epoch\": 31, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7035048007965088}, {\"epoch\": 32, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7041738629341125}, {\"epoch\": 33, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7033847570419312}, {\"epoch\": 34, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.703865110874176}, {\"epoch\": 35, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7031102776527405}, {\"epoch\": 36, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7036420702934265}, {\"epoch\": 37, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7029386758804321}, {\"epoch\": 38, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7030245065689087}, {\"epoch\": 39, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7041224241256714}, {\"epoch\": 40, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7034533619880676}, {\"epoch\": 41, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7034019231796265}, {\"epoch\": 42, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7030759453773499}, {\"epoch\": 43, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.703127384185791}, {\"epoch\": 44, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7034876942634583}, {\"epoch\": 45, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7037278413772583}, {\"epoch\": 46, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7043797373771667}, {\"epoch\": 47, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7044998407363892}, {\"epoch\": 48, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7032989859580994}, {\"epoch\": 49, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7040538191795349}, {\"epoch\": 50, \"l2_value\": 0.01, \"metric\": \"Training Accuracy\", \"value\": 0.7040709257125854}, {\"epoch\": 1, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6614927649497986}, {\"epoch\": 2, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6695910096168518}, {\"epoch\": 3, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6716156005859375}, {\"epoch\": 4, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.671075701713562}, {\"epoch\": 5, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6731002926826477}, {\"epoch\": 6, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6767445206642151}, {\"epoch\": 7, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6771494150161743}, {\"epoch\": 8, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6768794655799866}, {\"epoch\": 9, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.67917400598526}, {\"epoch\": 10, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6811985373497009}, {\"epoch\": 11, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6793089509010315}, {\"epoch\": 12, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6820083856582642}, {\"epoch\": 13, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.679443895816803}, {\"epoch\": 14, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.680523693561554}, {\"epoch\": 15, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.679848849773407}, {\"epoch\": 16, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6799837946891785}, {\"epoch\": 17, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6799837946891785}, {\"epoch\": 18, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6813335418701172}, {\"epoch\": 19, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6809285879135132}, {\"epoch\": 20, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6834930777549744}, {\"epoch\": 21, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6829531788825989}, {\"epoch\": 22, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6802537441253662}, {\"epoch\": 23, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6811985373497009}, {\"epoch\": 24, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6795789003372192}, {\"epoch\": 25, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6813335418701172}, {\"epoch\": 26, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6807936429977417}, {\"epoch\": 27, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6807936429977417}, {\"epoch\": 28, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.680523693561554}, {\"epoch\": 29, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6832231283187866}, {\"epoch\": 30, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6828181743621826}, {\"epoch\": 31, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6828181743621826}, {\"epoch\": 32, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.685112714767456}, {\"epoch\": 33, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6795789003372192}, {\"epoch\": 34, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6801187992095947}, {\"epoch\": 35, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6802537441253662}, {\"epoch\": 36, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6817384362220764}, {\"epoch\": 37, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6817384362220764}, {\"epoch\": 38, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6813335418701172}, {\"epoch\": 39, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6820083856582642}, {\"epoch\": 40, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6813335418701172}, {\"epoch\": 41, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6801187992095947}, {\"epoch\": 42, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6790390014648438}, {\"epoch\": 43, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6814684867858887}, {\"epoch\": 44, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6784991025924683}, {\"epoch\": 45, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6828181743621826}, {\"epoch\": 46, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6776893138885498}, {\"epoch\": 47, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6772843599319458}, {\"epoch\": 48, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6824132800102234}, {\"epoch\": 49, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6813335418701172}, {\"epoch\": 50, \"l2_value\": 0.01, \"metric\": \"Validation Accuracy\", \"value\": 0.6825482249259949}, {\"epoch\": 1, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.9773461222648621}, {\"epoch\": 2, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.8357622623443604}, {\"epoch\": 3, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.8162935376167297}, {\"epoch\": 4, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.8072249889373779}, {\"epoch\": 5, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.8011131882667542}, {\"epoch\": 6, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7950197458267212}, {\"epoch\": 7, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7899945974349976}, {\"epoch\": 8, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7857674956321716}, {\"epoch\": 9, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7827047109603882}, {\"epoch\": 10, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7801792025566101}, {\"epoch\": 11, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7785784602165222}, {\"epoch\": 12, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7770397067070007}, {\"epoch\": 13, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7755470871925354}, {\"epoch\": 14, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.774351954460144}, {\"epoch\": 15, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7734180092811584}, {\"epoch\": 16, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7728737592697144}, {\"epoch\": 17, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7722543478012085}, {\"epoch\": 18, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7715039849281311}, {\"epoch\": 19, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.770260214805603}, {\"epoch\": 20, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7679747939109802}, {\"epoch\": 21, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7644942998886108}, {\"epoch\": 22, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7631592154502869}, {\"epoch\": 23, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7625470161437988}, {\"epoch\": 24, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7620857357978821}, {\"epoch\": 25, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7621590495109558}, {\"epoch\": 26, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7617543339729309}, {\"epoch\": 27, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7617362141609192}, {\"epoch\": 28, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7615492343902588}, {\"epoch\": 29, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7613024115562439}, {\"epoch\": 30, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7612476944923401}, {\"epoch\": 31, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7609102129936218}, {\"epoch\": 32, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7608159780502319}, {\"epoch\": 33, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7610577940940857}, {\"epoch\": 34, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7603548169136047}, {\"epoch\": 35, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7602790594100952}, {\"epoch\": 36, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7601042985916138}, {\"epoch\": 37, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7600090503692627}, {\"epoch\": 38, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7600592374801636}, {\"epoch\": 39, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7597705721855164}, {\"epoch\": 40, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7593867182731628}, {\"epoch\": 41, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7594860792160034}, {\"epoch\": 42, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7591526508331299}, {\"epoch\": 43, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7589903473854065}, {\"epoch\": 44, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7588430047035217}, {\"epoch\": 45, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7589371204376221}, {\"epoch\": 46, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.758694589138031}, {\"epoch\": 47, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7586314082145691}, {\"epoch\": 48, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7584972977638245}, {\"epoch\": 49, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.7580891847610474}, {\"epoch\": 50, \"l2_value\": 0.01, \"metric\": \"Training Loss\", \"value\": 0.758122980594635}, {\"epoch\": 1, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8753724694252014}, {\"epoch\": 2, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8435287475585938}, {\"epoch\": 3, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.830609917640686}, {\"epoch\": 4, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.824368953704834}, {\"epoch\": 5, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.819577693939209}, {\"epoch\": 6, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8141122460365295}, {\"epoch\": 7, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8127382397651672}, {\"epoch\": 8, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8100844025611877}, {\"epoch\": 9, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8099581003189087}, {\"epoch\": 10, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8085034489631653}, {\"epoch\": 11, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8080317974090576}, {\"epoch\": 12, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8054966926574707}, {\"epoch\": 13, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8062404990196228}, {\"epoch\": 14, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8045486211776733}, {\"epoch\": 15, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.806412935256958}, {\"epoch\": 16, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.803781270980835}, {\"epoch\": 17, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8055146336555481}, {\"epoch\": 18, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8025364279747009}, {\"epoch\": 19, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8037074208259583}, {\"epoch\": 20, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.796164870262146}, {\"epoch\": 21, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.7961228489875793}, {\"epoch\": 22, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.7975385785102844}, {\"epoch\": 23, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8008602261543274}, {\"epoch\": 24, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.801808774471283}, {\"epoch\": 25, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.7974459528923035}, {\"epoch\": 26, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.7991756796836853}, {\"epoch\": 27, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.7990351319313049}, {\"epoch\": 28, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.7983942627906799}, {\"epoch\": 29, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.7985853552818298}, {\"epoch\": 30, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.7959125638008118}, {\"epoch\": 31, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.79737389087677}, {\"epoch\": 32, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.7944173216819763}, {\"epoch\": 33, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.7975167632102966}, {\"epoch\": 34, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.797319233417511}, {\"epoch\": 35, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.7971625328063965}, {\"epoch\": 36, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.7989624738693237}, {\"epoch\": 37, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.7972850799560547}, {\"epoch\": 38, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8003324866294861}, {\"epoch\": 39, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.7977979183197021}, {\"epoch\": 40, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8008479475975037}, {\"epoch\": 41, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.800995409488678}, {\"epoch\": 42, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8067295551300049}, {\"epoch\": 43, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.7991541028022766}, {\"epoch\": 44, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8050435185432434}, {\"epoch\": 45, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8015985488891602}, {\"epoch\": 46, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.809339165687561}, {\"epoch\": 47, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8093876242637634}, {\"epoch\": 48, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.7999338507652283}, {\"epoch\": 49, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8029932975769043}, {\"epoch\": 50, \"l2_value\": 0.01, \"metric\": \"Validation Loss\", \"value\": 0.8039617538452148}, {\"epoch\": 1, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.6666037440299988}, {\"epoch\": 2, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7017549872398376}, {\"epoch\": 3, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7173834443092346}, {\"epoch\": 4, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7273850440979004}, {\"epoch\": 5, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7346760034561157}, {\"epoch\": 6, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7405946254730225}, {\"epoch\": 7, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7461186051368713}, {\"epoch\": 8, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7516083121299744}, {\"epoch\": 9, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7540786862373352}, {\"epoch\": 10, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.757801353931427}, {\"epoch\": 11, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7595340609550476}, {\"epoch\": 12, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7623475193977356}, {\"epoch\": 13, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.765864372253418}, {\"epoch\": 14, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7673225998878479}, {\"epoch\": 15, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.769072413444519}, {\"epoch\": 16, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7701360583305359}, {\"epoch\": 17, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7713712453842163}, {\"epoch\": 18, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7723662257194519}, {\"epoch\": 19, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.773635745048523}, {\"epoch\": 20, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7751110792160034}, {\"epoch\": 21, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7757286429405212}, {\"epoch\": 22, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7749567031860352}, {\"epoch\": 23, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7756772041320801}, {\"epoch\": 24, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.77543705701828}, {\"epoch\": 25, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7785249948501587}, {\"epoch\": 26, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7785935997962952}, {\"epoch\": 27, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7792969942092896}, {\"epoch\": 28, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7792798280715942}, {\"epoch\": 29, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7792283296585083}, {\"epoch\": 30, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7796229124069214}, {\"epoch\": 31, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7806522250175476}, {\"epoch\": 32, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7802577018737793}, {\"epoch\": 33, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7813899517059326}, {\"epoch\": 34, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7808924317359924}, {\"epoch\": 35, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7817673683166504}, {\"epoch\": 36, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7820932865142822}, {\"epoch\": 37, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.782470703125}, {\"epoch\": 38, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7817502021789551}, {\"epoch\": 39, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7826422452926636}, {\"epoch\": 40, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7821447849273682}, {\"epoch\": 41, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7833799123764038}, {\"epoch\": 42, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7817330360412598}, {\"epoch\": 43, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7844778895378113}, {\"epoch\": 44, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7842034101486206}, {\"epoch\": 45, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7840147018432617}, {\"epoch\": 46, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7839803695678711}, {\"epoch\": 47, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7852327227592468}, {\"epoch\": 48, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7845121622085571}, {\"epoch\": 49, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7864679098129272}, {\"epoch\": 50, \"l2_value\": 0.001, \"metric\": \"Training Accuracy\", \"value\": 0.7858160138130188}, {\"epoch\": 1, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6766095161437988}, {\"epoch\": 2, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6922661662101746}, {\"epoch\": 3, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.694830596446991}, {\"epoch\": 4, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6957753896713257}, {\"epoch\": 5, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6980699300765991}, {\"epoch\": 6, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6988797187805176}, {\"epoch\": 7, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6968551874160767}, {\"epoch\": 8, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6940208077430725}, {\"epoch\": 9, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6917262673377991}, {\"epoch\": 10, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6902415752410889}, {\"epoch\": 11, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6913213729858398}, {\"epoch\": 12, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6899716854095459}, {\"epoch\": 13, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6919962167739868}, {\"epoch\": 14, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6890268325805664}, {\"epoch\": 15, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6884869933128357}, {\"epoch\": 16, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6884869933128357}, {\"epoch\": 17, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6887569427490234}, {\"epoch\": 18, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6906465291976929}, {\"epoch\": 19, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6915913224220276}, {\"epoch\": 20, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6872722506523132}, {\"epoch\": 21, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6879470944404602}, {\"epoch\": 22, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6841679215431213}, {\"epoch\": 23, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6894317865371704}, {\"epoch\": 24, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6856526136398315}, {\"epoch\": 25, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6833580732345581}, {\"epoch\": 26, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6859225034713745}, {\"epoch\": 27, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6826832294464111}, {\"epoch\": 28, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6841679215431213}, {\"epoch\": 29, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.685112714767456}, {\"epoch\": 30, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6809285879135132}, {\"epoch\": 31, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6826832294464111}, {\"epoch\": 32, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6803886890411377}, {\"epoch\": 33, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6821433305740356}, {\"epoch\": 34, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6802537441253662}, {\"epoch\": 35, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6755297780036926}, {\"epoch\": 36, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6790390014648438}, {\"epoch\": 37, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6807936429977417}, {\"epoch\": 38, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6778242588043213}, {\"epoch\": 39, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6757997274398804}, {\"epoch\": 40, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.678769052028656}, {\"epoch\": 41, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6786341071128845}, {\"epoch\": 42, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6774193644523621}, {\"epoch\": 43, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6770144701004028}, {\"epoch\": 44, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.678769052028656}, {\"epoch\": 45, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6774193644523621}, {\"epoch\": 46, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6740450859069824}, {\"epoch\": 47, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6695910096168518}, {\"epoch\": 48, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6731002926826477}, {\"epoch\": 49, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6735051870346069}, {\"epoch\": 50, \"l2_value\": 0.001, \"metric\": \"Validation Accuracy\", \"value\": 0.6768794655799866}, {\"epoch\": 1, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.883756160736084}, {\"epoch\": 2, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.7714451551437378}, {\"epoch\": 3, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.7362880110740662}, {\"epoch\": 4, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.7175555229187012}, {\"epoch\": 5, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.7049773335456848}, {\"epoch\": 6, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.695117175579071}, {\"epoch\": 7, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6875831484794617}, {\"epoch\": 8, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6812469363212585}, {\"epoch\": 9, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.675964891910553}, {\"epoch\": 10, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6719738841056824}, {\"epoch\": 11, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6679745316505432}, {\"epoch\": 12, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6648755669593811}, {\"epoch\": 13, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6614950299263}, {\"epoch\": 14, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6586881875991821}, {\"epoch\": 15, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6565496921539307}, {\"epoch\": 16, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6549614667892456}, {\"epoch\": 17, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6525750160217285}, {\"epoch\": 18, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6513105034828186}, {\"epoch\": 19, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6499260067939758}, {\"epoch\": 20, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6483586430549622}, {\"epoch\": 21, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6476003527641296}, {\"epoch\": 22, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6473347544670105}, {\"epoch\": 23, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6460729241371155}, {\"epoch\": 24, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6458333134651184}, {\"epoch\": 25, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6436247229576111}, {\"epoch\": 26, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6437260508537292}, {\"epoch\": 27, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6431224942207336}, {\"epoch\": 28, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6419260501861572}, {\"epoch\": 29, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6410775184631348}, {\"epoch\": 30, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6411112546920776}, {\"epoch\": 31, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6399931311607361}, {\"epoch\": 32, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6394791007041931}, {\"epoch\": 33, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6386520862579346}, {\"epoch\": 34, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.638870120048523}, {\"epoch\": 35, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.637495219707489}, {\"epoch\": 36, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6375405192375183}, {\"epoch\": 37, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6373992562294006}, {\"epoch\": 38, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6369381546974182}, {\"epoch\": 39, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6364032626152039}, {\"epoch\": 40, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6359304189682007}, {\"epoch\": 41, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6349903345108032}, {\"epoch\": 42, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6354796886444092}, {\"epoch\": 43, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6328327655792236}, {\"epoch\": 44, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6340270042419434}, {\"epoch\": 45, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6325795650482178}, {\"epoch\": 46, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.633350670337677}, {\"epoch\": 47, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6328780651092529}, {\"epoch\": 48, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6325544714927673}, {\"epoch\": 49, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6319230794906616}, {\"epoch\": 50, \"l2_value\": 0.001, \"metric\": \"Training Loss\", \"value\": 0.6316657066345215}, {\"epoch\": 1, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8186357021331787}, {\"epoch\": 2, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.7785816788673401}, {\"epoch\": 3, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.7671818733215332}, {\"epoch\": 4, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.7660304307937622}, {\"epoch\": 5, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.7671598196029663}, {\"epoch\": 6, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.7704840302467346}, {\"epoch\": 7, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.7763221263885498}, {\"epoch\": 8, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.7837733030319214}, {\"epoch\": 9, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.7901891469955444}, {\"epoch\": 10, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8012657761573792}, {\"epoch\": 11, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8085562586784363}, {\"epoch\": 12, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8124901652336121}, {\"epoch\": 13, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8165439367294312}, {\"epoch\": 14, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8219118714332581}, {\"epoch\": 15, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.827001690864563}, {\"epoch\": 16, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.832329273223877}, {\"epoch\": 17, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8364672064781189}, {\"epoch\": 18, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.835719108581543}, {\"epoch\": 19, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8375634551048279}, {\"epoch\": 20, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8446986079216003}, {\"epoch\": 21, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8486390113830566}, {\"epoch\": 22, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8507829308509827}, {\"epoch\": 23, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.853336751461029}, {\"epoch\": 24, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8575706481933594}, {\"epoch\": 25, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8653674721717834}, {\"epoch\": 26, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.862938404083252}, {\"epoch\": 27, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8676639795303345}, {\"epoch\": 28, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8678383231163025}, {\"epoch\": 29, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.866696298122406}, {\"epoch\": 30, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8741684556007385}, {\"epoch\": 31, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8685529232025146}, {\"epoch\": 32, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8718903660774231}, {\"epoch\": 33, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8743928670883179}, {\"epoch\": 34, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8795491456985474}, {\"epoch\": 35, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8843222856521606}, {\"epoch\": 36, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8803855180740356}, {\"epoch\": 37, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8823459148406982}, {\"epoch\": 38, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8912414908409119}, {\"epoch\": 39, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8986400961875916}, {\"epoch\": 40, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8889461159706116}, {\"epoch\": 41, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8974078893661499}, {\"epoch\": 42, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8972374200820923}, {\"epoch\": 43, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.9013304114341736}, {\"epoch\": 44, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.8991219997406006}, {\"epoch\": 45, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.9102482795715332}, {\"epoch\": 46, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.9159977436065674}, {\"epoch\": 47, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.9271389245986938}, {\"epoch\": 48, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.9249483942985535}, {\"epoch\": 49, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.9311249256134033}, {\"epoch\": 50, \"l2_value\": 0.001, \"metric\": \"Validation Loss\", \"value\": 0.9251464009284973}, {\"epoch\": 1, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.6694687008857727}, {\"epoch\": 2, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.7185500264167786}, {\"epoch\": 3, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.7498756051063538}, {\"epoch\": 4, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.7757458090782166}, {\"epoch\": 5, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.7995573878288269}, {\"epoch\": 6, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.8242610096931458}, {\"epoch\": 7, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.8439725041389465}, {\"epoch\": 8, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.8612478971481323}, {\"epoch\": 9, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.8736168742179871}, {\"epoch\": 10, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.884922206401825}, {\"epoch\": 11, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.8934140801429749}, {\"epoch\": 12, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9007908701896667}, {\"epoch\": 13, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9059889316558838}, {\"epoch\": 14, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9122677445411682}, {\"epoch\": 15, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.919009804725647}, {\"epoch\": 16, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9229898452758789}, {\"epoch\": 17, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9252543449401855}, {\"epoch\": 18, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9305381774902344}, {\"epoch\": 19, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.932511031627655}, {\"epoch\": 20, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.937606155872345}, {\"epoch\": 21, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9383438229560852}, {\"epoch\": 22, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9429757595062256}, {\"epoch\": 23, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9434904456138611}, {\"epoch\": 24, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9449314475059509}, {\"epoch\": 25, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9465097784996033}, {\"epoch\": 26, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9474875926971436}, {\"epoch\": 27, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9505412578582764}, {\"epoch\": 28, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9500609040260315}, {\"epoch\": 29, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9532346129417419}, {\"epoch\": 30, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9523082375526428}, {\"epoch\": 31, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.956442654132843}, {\"epoch\": 32, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9549158811569214}, {\"epoch\": 33, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9559451937675476}, {\"epoch\": 34, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9574548602104187}, {\"epoch\": 35, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9568372368812561}, {\"epoch\": 36, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.958587110042572}, {\"epoch\": 37, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9591532349586487}, {\"epoch\": 38, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9604741930961609}, {\"epoch\": 39, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9597879648208618}, {\"epoch\": 40, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9599595069885254}, {\"epoch\": 41, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.962224006652832}, {\"epoch\": 42, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9621210694313049}, {\"epoch\": 43, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9626357555389404}, {\"epoch\": 44, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9627557992935181}, {\"epoch\": 45, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.963922381401062}, {\"epoch\": 46, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9628759026527405}, {\"epoch\": 47, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9646772146224976}, {\"epoch\": 48, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9648659229278564}, {\"epoch\": 49, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9646772146224976}, {\"epoch\": 50, \"l2_value\": 0.0001, \"metric\": \"Training Accuracy\", \"value\": 0.9642311930656433}, {\"epoch\": 1, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.687542200088501}, {\"epoch\": 2, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.7027938961982727}, {\"epoch\": 3, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.7040086388587952}, {\"epoch\": 4, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6899716854095459}, {\"epoch\": 5, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6826832294464111}, {\"epoch\": 6, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6733702421188354}, {\"epoch\": 7, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.664462149143219}, {\"epoch\": 8, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.655419111251831}, {\"epoch\": 9, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.657443642616272}, {\"epoch\": 10, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6384127140045166}, {\"epoch\": 11, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6470508575439453}, {\"epoch\": 12, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6392225623130798}, {\"epoch\": 13, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6494803428649902}, {\"epoch\": 14, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6440815329551697}, {\"epoch\": 15, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.642056941986084}, {\"epoch\": 16, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6469159126281738}, {\"epoch\": 17, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6428667902946472}, {\"epoch\": 18, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6428667902946472}, {\"epoch\": 19, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6388176679611206}, {\"epoch\": 20, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.642461895942688}, {\"epoch\": 21, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6416520476341248}, {\"epoch\": 22, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6434066891670227}, {\"epoch\": 23, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.643136739730835}, {\"epoch\": 24, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.634768545627594}, {\"epoch\": 25, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6405722498893738}, {\"epoch\": 26, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.641382098197937}, {\"epoch\": 27, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6362531781196594}, {\"epoch\": 28, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6376029253005981}, {\"epoch\": 29, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6392225623130798}, {\"epoch\": 30, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6300445199012756}, {\"epoch\": 31, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6380078196525574}, {\"epoch\": 32, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6390876173973083}, {\"epoch\": 33, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6457011699676514}, {\"epoch\": 34, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6411121487617493}, {\"epoch\": 35, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6392225623130798}, {\"epoch\": 36, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6382777690887451}, {\"epoch\": 37, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6439465284347534}, {\"epoch\": 38, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6405722498893738}, {\"epoch\": 39, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6415171027183533}, {\"epoch\": 40, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6405722498893738}, {\"epoch\": 41, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6376029253005981}, {\"epoch\": 42, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6416520476341248}, {\"epoch\": 43, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6295046806335449}, {\"epoch\": 44, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6421919465065002}, {\"epoch\": 45, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.63436359167099}, {\"epoch\": 46, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.641382098197937}, {\"epoch\": 47, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6369280815124512}, {\"epoch\": 48, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6390876173973083}, {\"epoch\": 49, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6335538029670715}, {\"epoch\": 50, \"l2_value\": 0.0001, \"metric\": \"Validation Accuracy\", \"value\": 0.6282899379730225}, {\"epoch\": 1, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.7969297766685486}, {\"epoch\": 2, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.7040653824806213}, {\"epoch\": 3, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.647068202495575}, {\"epoch\": 4, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.5999842882156372}, {\"epoch\": 5, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.5542866587638855}, {\"epoch\": 6, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.5111320614814758}, {\"epoch\": 7, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.4748014211654663}, {\"epoch\": 8, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.44219574332237244}, {\"epoch\": 9, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.4180773198604584}, {\"epoch\": 10, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.3954941928386688}, {\"epoch\": 11, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.3811437487602234}, {\"epoch\": 12, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.3671617805957794}, {\"epoch\": 13, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.35930466651916504}, {\"epoch\": 14, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.34891170263290405}, {\"epoch\": 15, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.33837997913360596}, {\"epoch\": 16, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.3317340016365051}, {\"epoch\": 17, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.32842254638671875}, {\"epoch\": 18, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.3216325640678406}, {\"epoch\": 19, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.31940293312072754}, {\"epoch\": 20, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.30886927247047424}, {\"epoch\": 21, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.3124988079071045}, {\"epoch\": 22, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.30386149883270264}, {\"epoch\": 23, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.30507388710975647}, {\"epoch\": 24, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.30288854241371155}, {\"epoch\": 25, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.3015672564506531}, {\"epoch\": 26, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.29831671714782715}, {\"epoch\": 27, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.29212626814842224}, {\"epoch\": 28, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.29697686433792114}, {\"epoch\": 29, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.29027077555656433}, {\"epoch\": 30, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.29293370246887207}, {\"epoch\": 31, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.2849140763282776}, {\"epoch\": 32, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.2923658490180969}, {\"epoch\": 33, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.28822198510169983}, {\"epoch\": 34, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.28359511494636536}, {\"epoch\": 35, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.2869567275047302}, {\"epoch\": 36, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.2840794324874878}, {\"epoch\": 37, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.2822844982147217}, {\"epoch\": 38, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.27847540378570557}, {\"epoch\": 39, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.2797513008117676}, {\"epoch\": 40, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.2825985252857208}, {\"epoch\": 41, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.27423906326293945}, {\"epoch\": 42, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.27804943919181824}, {\"epoch\": 43, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.27667972445487976}, {\"epoch\": 44, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.2753855586051941}, {\"epoch\": 45, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.27237457036972046}, {\"epoch\": 46, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.2723931074142456}, {\"epoch\": 47, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.2707671523094177}, {\"epoch\": 48, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.26845037937164307}, {\"epoch\": 49, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.2712858021259308}, {\"epoch\": 50, \"l2_value\": 0.0001, \"metric\": \"Training Loss\", \"value\": 0.2734117805957794}, {\"epoch\": 1, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 0.7667366862297058}, {\"epoch\": 2, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 0.7347889542579651}, {\"epoch\": 3, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 0.7485016584396362}, {\"epoch\": 4, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 0.7914533615112305}, {\"epoch\": 5, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 0.8591529130935669}, {\"epoch\": 6, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 0.9335495233535767}, {\"epoch\": 7, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 1.011662244796753}, {\"epoch\": 8, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 1.096097707748413}, {\"epoch\": 9, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 1.1599280834197998}, {\"epoch\": 10, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 1.2919626235961914}, {\"epoch\": 11, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 1.3395897150039673}, {\"epoch\": 12, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 1.4010192155838013}, {\"epoch\": 13, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 1.452461838722229}, {\"epoch\": 14, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 1.5291383266448975}, {\"epoch\": 15, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 1.601884365081787}, {\"epoch\": 16, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 1.6704930067062378}, {\"epoch\": 17, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 1.6870259046554565}, {\"epoch\": 18, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 1.6833815574645996}, {\"epoch\": 19, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 1.810117483139038}, {\"epoch\": 20, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 1.9287370443344116}, {\"epoch\": 21, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 1.953953504562378}, {\"epoch\": 22, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.004818916320801}, {\"epoch\": 23, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.0687005519866943}, {\"epoch\": 24, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.1077194213867188}, {\"epoch\": 25, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.113769769668579}, {\"epoch\": 26, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.1174192428588867}, {\"epoch\": 27, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.1958844661712646}, {\"epoch\": 28, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.170442581176758}, {\"epoch\": 29, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.1756088733673096}, {\"epoch\": 30, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.2270548343658447}, {\"epoch\": 31, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.2776520252227783}, {\"epoch\": 32, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.2003560066223145}, {\"epoch\": 33, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.231006145477295}, {\"epoch\": 34, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.2591700553894043}, {\"epoch\": 35, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.277226209640503}, {\"epoch\": 36, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.3460566997528076}, {\"epoch\": 37, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.3542072772979736}, {\"epoch\": 38, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.4126205444335938}, {\"epoch\": 39, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.343682050704956}, {\"epoch\": 40, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.343700647354126}, {\"epoch\": 41, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.3349223136901855}, {\"epoch\": 42, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.3982903957366943}, {\"epoch\": 43, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.3186328411102295}, {\"epoch\": 44, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.4245734214782715}, {\"epoch\": 45, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.367011785507202}, {\"epoch\": 46, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.282144546508789}, {\"epoch\": 47, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.4398107528686523}, {\"epoch\": 48, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.403754949569702}, {\"epoch\": 49, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.4508602619171143}, {\"epoch\": 50, \"l2_value\": 0.0001, \"metric\": \"Validation Loss\", \"value\": 2.5158698558807373}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "l2_values = [0.01, 0.001, 1e-4]\n",
    "\n",
    "# Prepare a DataFrame to collect all metrics for plotting\n",
    "df_all_models = pd.DataFrame()\n",
    "\n",
    "for l2_value in l2_values:\n",
    "    print(f\"\\nTraining model with L2 regularization (lambda={l2_value})\")\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=(462,)),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(l2_value)),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(l2_value)),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': range(1, 51),\n",
    "        'training_accuracy': history.history['accuracy'],\n",
    "        'validation_accuracy': history.history['val_accuracy'],\n",
    "        'training_loss': history.history['loss'],\n",
    "        'validation_loss': history.history['val_loss'],\n",
    "        'l2_value': [l2_value] * 50\n",
    "    })\n",
    "    \n",
    "    # Melt the dataframe for long format\n",
    "    df_long = df.melt(id_vars=['epoch', 'l2_value'], \n",
    "                      value_vars=['training_accuracy', 'validation_accuracy', 'training_loss', 'validation_loss'],\n",
    "                      var_name='metric', value_name='value')\n",
    "    \n",
    "    # Concatenate all data\n",
    "    df_all_models = pd.concat([df_all_models, df_long], ignore_index=True)\n",
    "\n",
    "# Define the color mapping for metrics\n",
    "color_mapping = {\n",
    "    'training_accuracy': 'Training Accuracy',\n",
    "    'validation_accuracy': 'Validation Accuracy',\n",
    "    'training_loss': 'Training Loss',\n",
    "    'validation_loss': 'Validation Loss'\n",
    "}\n",
    "\n",
    "df_all_models['metric'] = df_all_models['metric'].map(color_mapping)\n",
    "\n",
    "# Altair plot: Interactive plot for all models\n",
    "chart = alt.Chart(df_all_models).mark_line().encode(\n",
    "    x='epoch',\n",
    "    y='value',\n",
    "    color='metric',\n",
    "    column='l2_value:O',  # Separate charts for each L2 value\n",
    "    tooltip=['epoch', 'value', 'metric', 'l2_value']\n",
    ").properties(\n",
    "    title=\"Model Performance: Accuracy & Loss for Different L2 Regularization Values\",\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "chart.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        - Dropout layers are a regularization technique in neural networks where a random subset of neurons is temporarily removed during training. This helps prevent overfitting by promoting redundancy and improving the network's ability to generalize to new data. Select a specific model from the above experiments where you have muliple layers and experiment adding one or of few dropout layers into your network. Experiment with two different rates, say 0.25 and 0.5. Document your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with dropout rate 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with dropout rate 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-ef15b541a9cd485cb53719fa27a1d312.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-ef15b541a9cd485cb53719fa27a1d312.vega-embed details,\n",
       "  #altair-viz-ef15b541a9cd485cb53719fa27a1d312.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-ef15b541a9cd485cb53719fa27a1d312\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ef15b541a9cd485cb53719fa27a1d312\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ef15b541a9cd485cb53719fa27a1d312\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-c8d040071e0eddd4fbf93c92ec672c6c\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"column\": {\"field\": \"dropout_rate\", \"type\": \"ordinal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}, {\"field\": \"dropout_rate\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Model Performance: Accuracy & Loss for Different Dropout Rates\", \"width\": 300, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-c8d040071e0eddd4fbf93c92ec672c6c\": [{\"epoch\": 1, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.6597244739532471}, {\"epoch\": 2, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.7066270709037781}, {\"epoch\": 3, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.7322571277618408}, {\"epoch\": 4, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.7508706450462341}, {\"epoch\": 5, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.7679401636123657}, {\"epoch\": 6, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.7806179523468018}, {\"epoch\": 7, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.792335033416748}, {\"epoch\": 8, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8008097410202026}, {\"epoch\": 9, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8108798861503601}, {\"epoch\": 10, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8160779476165771}, {\"epoch\": 11, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8224254250526428}, {\"epoch\": 12, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8284469246864319}, {\"epoch\": 13, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8319809436798096}, {\"epoch\": 14, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.838019609451294}, {\"epoch\": 15, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8417251110076904}, {\"epoch\": 16, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8440582752227783}, {\"epoch\": 17, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8475922346115112}, {\"epoch\": 18, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8486215472221375}, {\"epoch\": 19, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.854042649269104}, {\"epoch\": 20, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8534765243530273}, {\"epoch\": 21, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8594465851783752}, {\"epoch\": 22, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8617968559265137}, {\"epoch\": 23, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8626202940940857}, {\"epoch\": 24, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.865450918674469}, {\"epoch\": 25, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8663086891174316}, {\"epoch\": 26, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8696368336677551}, {\"epoch\": 27, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8708891868591309}, {\"epoch\": 28, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8729478120803833}, {\"epoch\": 29, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8751779794692993}, {\"epoch\": 30, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8764646053314209}, {\"epoch\": 31, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8763445615768433}, {\"epoch\": 32, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8784889578819275}, {\"epoch\": 33, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8797069787979126}, {\"epoch\": 34, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8826748728752136}, {\"epoch\": 35, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8823660612106323}, {\"epoch\": 36, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8845104575157166}, {\"epoch\": 37, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8847334980964661}, {\"epoch\": 38, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8852481245994568}, {\"epoch\": 39, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8870666027069092}, {\"epoch\": 40, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8882331848144531}, {\"epoch\": 41, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.890652060508728}, {\"epoch\": 42, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8898114562034607}, {\"epoch\": 43, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8913039565086365}, {\"epoch\": 44, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8938258290290833}, {\"epoch\": 45, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8929508924484253}, {\"epoch\": 46, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8934826850891113}, {\"epoch\": 47, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8951124548912048}, {\"epoch\": 48, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8967078924179077}, {\"epoch\": 49, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8933969140052795}, {\"epoch\": 50, \"dropout_rate\": 0.25, \"metric\": \"Training Accuracy\", \"value\": 0.8974970579147339}, {\"epoch\": 1, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.685787558555603}, {\"epoch\": 2, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6987447738647461}, {\"epoch\": 3, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.702523946762085}, {\"epoch\": 4, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.7056282758712769}, {\"epoch\": 5, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.7022539973258972}, {\"epoch\": 6, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.694830596446991}, {\"epoch\": 7, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6936158537864685}, {\"epoch\": 8, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6919962167739868}, {\"epoch\": 9, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6878121495246887}, {\"epoch\": 10, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.687137246131897}, {\"epoch\": 11, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6874071955680847}, {\"epoch\": 12, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.685112714767456}, {\"epoch\": 13, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.685787558555603}, {\"epoch\": 14, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6820083856582642}, {\"epoch\": 15, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6811985373497009}, {\"epoch\": 16, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6776893138885498}, {\"epoch\": 17, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6740450859069824}, {\"epoch\": 18, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.679848849773407}, {\"epoch\": 19, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.679848849773407}, {\"epoch\": 20, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6802537441253662}, {\"epoch\": 21, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.679443895816803}, {\"epoch\": 22, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6759346723556519}, {\"epoch\": 23, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6762046217918396}, {\"epoch\": 24, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6751248240470886}, {\"epoch\": 25, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6762046217918396}, {\"epoch\": 26, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6759346723556519}, {\"epoch\": 27, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6737751364707947}, {\"epoch\": 28, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6753947734832764}, {\"epoch\": 29, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6763395667076111}, {\"epoch\": 30, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6739100813865662}, {\"epoch\": 31, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6708057522773743}, {\"epoch\": 32, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6697260141372681}, {\"epoch\": 33, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6741800308227539}, {\"epoch\": 34, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6724254488945007}, {\"epoch\": 35, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6732352375984192}, {\"epoch\": 36, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6686462163925171}, {\"epoch\": 37, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6735051870346069}, {\"epoch\": 38, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6739100813865662}, {\"epoch\": 39, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6705358624458313}, {\"epoch\": 40, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6718855500221252}, {\"epoch\": 41, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6701309084892273}, {\"epoch\": 42, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6729652881622314}, {\"epoch\": 43, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6762046217918396}, {\"epoch\": 44, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6678364276885986}, {\"epoch\": 45, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6698609590530396}, {\"epoch\": 46, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6675664782524109}, {\"epoch\": 47, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6705358624458313}, {\"epoch\": 48, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6699959635734558}, {\"epoch\": 49, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6682413220405579}, {\"epoch\": 50, \"dropout_rate\": 0.25, \"metric\": \"Validation Accuracy\", \"value\": 0.6706708073616028}, {\"epoch\": 1, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.7895169258117676}, {\"epoch\": 2, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.7034957408905029}, {\"epoch\": 3, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.6479003429412842}, {\"epoch\": 4, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.604167640209198}, {\"epoch\": 5, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.5697162747383118}, {\"epoch\": 6, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.5389253497123718}, {\"epoch\": 7, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.5140868425369263}, {\"epoch\": 8, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.4938698709011078}, {\"epoch\": 9, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.47299429774284363}, {\"epoch\": 10, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.45974281430244446}, {\"epoch\": 11, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.443576455116272}, {\"epoch\": 12, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.43000584840774536}, {\"epoch\": 13, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.4217512607574463}, {\"epoch\": 14, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.4095458686351776}, {\"epoch\": 15, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.4014711081981659}, {\"epoch\": 16, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.3936765789985657}, {\"epoch\": 17, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.3867746591567993}, {\"epoch\": 18, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.37952473759651184}, {\"epoch\": 19, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.3705753982067108}, {\"epoch\": 20, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.36828821897506714}, {\"epoch\": 21, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.3583565354347229}, {\"epoch\": 22, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.3552263081073761}, {\"epoch\": 23, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.3509867489337921}, {\"epoch\": 24, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.34359627962112427}, {\"epoch\": 25, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.3423102796077728}, {\"epoch\": 26, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.33278095722198486}, {\"epoch\": 27, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.33095240592956543}, {\"epoch\": 28, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.32422229647636414}, {\"epoch\": 29, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.3236357271671295}, {\"epoch\": 30, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.31705212593078613}, {\"epoch\": 31, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.3183761537075043}, {\"epoch\": 32, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.313649982213974}, {\"epoch\": 33, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.3090285360813141}, {\"epoch\": 34, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.3046012222766876}, {\"epoch\": 35, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.30247387290000916}, {\"epoch\": 36, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.29911431670188904}, {\"epoch\": 37, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.2968355715274811}, {\"epoch\": 38, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.29782602190971375}, {\"epoch\": 39, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.2919156551361084}, {\"epoch\": 40, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.2860429286956787}, {\"epoch\": 41, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.28721359372138977}, {\"epoch\": 42, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.28658822178840637}, {\"epoch\": 43, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.284505695104599}, {\"epoch\": 44, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.2776258885860443}, {\"epoch\": 45, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.2786021828651428}, {\"epoch\": 46, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.2814435362815857}, {\"epoch\": 47, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.274892121553421}, {\"epoch\": 48, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.27154919505119324}, {\"epoch\": 49, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.27592045068740845}, {\"epoch\": 50, \"dropout_rate\": 0.25, \"metric\": \"Training Loss\", \"value\": 0.26844602823257446}, {\"epoch\": 1, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.748012125492096}, {\"epoch\": 2, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.713249146938324}, {\"epoch\": 3, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.7006208300590515}, {\"epoch\": 4, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.6997648477554321}, {\"epoch\": 5, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.7114931344985962}, {\"epoch\": 6, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.7330076098442078}, {\"epoch\": 7, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.7499542832374573}, {\"epoch\": 8, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.7691347599029541}, {\"epoch\": 9, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.780195951461792}, {\"epoch\": 10, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.8033531904220581}, {\"epoch\": 11, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.8020417094230652}, {\"epoch\": 12, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.8333426117897034}, {\"epoch\": 13, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.8270225524902344}, {\"epoch\": 14, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.8582285642623901}, {\"epoch\": 15, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.8763829469680786}, {\"epoch\": 16, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.892354428768158}, {\"epoch\": 17, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.9009422659873962}, {\"epoch\": 18, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.9113376140594482}, {\"epoch\": 19, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.9188584685325623}, {\"epoch\": 20, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.9296114444732666}, {\"epoch\": 21, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.9285712242126465}, {\"epoch\": 22, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.9337862133979797}, {\"epoch\": 23, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.9545485973358154}, {\"epoch\": 24, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.960658073425293}, {\"epoch\": 25, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.9661490321159363}, {\"epoch\": 26, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.9918052554130554}, {\"epoch\": 27, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.9632596969604492}, {\"epoch\": 28, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.9886182546615601}, {\"epoch\": 29, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 0.9994475841522217}, {\"epoch\": 30, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.010277271270752}, {\"epoch\": 31, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.0001217126846313}, {\"epoch\": 32, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.0200213193893433}, {\"epoch\": 33, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.0305715799331665}, {\"epoch\": 34, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.0392391681671143}, {\"epoch\": 35, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.033911943435669}, {\"epoch\": 36, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.041319727897644}, {\"epoch\": 37, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.0585989952087402}, {\"epoch\": 38, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.0569909811019897}, {\"epoch\": 39, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.0576802492141724}, {\"epoch\": 40, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.076776385307312}, {\"epoch\": 41, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.0840117931365967}, {\"epoch\": 42, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.0762898921966553}, {\"epoch\": 43, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.0691418647766113}, {\"epoch\": 44, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.1099376678466797}, {\"epoch\": 45, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.086155652999878}, {\"epoch\": 46, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.0887503623962402}, {\"epoch\": 47, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.1065118312835693}, {\"epoch\": 48, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.122905969619751}, {\"epoch\": 49, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.104050874710083}, {\"epoch\": 50, \"dropout_rate\": 0.25, \"metric\": \"Validation Loss\", \"value\": 1.133740782737732}, {\"epoch\": 1, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.6307663321495056}, {\"epoch\": 2, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.6849256157875061}, {\"epoch\": 3, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7005198001861572}, {\"epoch\": 4, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7150846719741821}, {\"epoch\": 5, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7267845869064331}, {\"epoch\": 6, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7349333763122559}, {\"epoch\": 7, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7417097091674805}, {\"epoch\": 8, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7478855848312378}, {\"epoch\": 9, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7529464364051819}, {\"epoch\": 10, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7552281022071838}, {\"epoch\": 11, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7596884369850159}, {\"epoch\": 12, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7632224559783936}, {\"epoch\": 13, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7657442688941956}, {\"epoch\": 14, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7697243094444275}, {\"epoch\": 15, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7734641432762146}, {\"epoch\": 16, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7751968502998352}, {\"epoch\": 17, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7783534526824951}, {\"epoch\": 18, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7823163270950317}, {\"epoch\": 19, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7822305560112}, {\"epoch\": 20, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7814585566520691}, {\"epoch\": 21, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7828996181488037}, {\"epoch\": 22, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7882177233695984}, {\"epoch\": 23, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7896931171417236}, {\"epoch\": 24, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7880805134773254}, {\"epoch\": 25, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7931756377220154}, {\"epoch\": 26, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7918031811714172}, {\"epoch\": 27, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.793347179889679}, {\"epoch\": 28, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7942392230033875}, {\"epoch\": 29, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7942907214164734}, {\"epoch\": 30, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.798545241355896}, {\"epoch\": 31, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7982879281044006}, {\"epoch\": 32, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.7994372844696045}, {\"epoch\": 33, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.8009984493255615}, {\"epoch\": 34, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.8025767207145691}, {\"epoch\": 35, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.8008783459663391}, {\"epoch\": 36, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.8007411360740662}, {\"epoch\": 37, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.803451657295227}, {\"epoch\": 38, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.8045324087142944}, {\"epoch\": 39, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.8065395951271057}, {\"epoch\": 40, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.8054073452949524}, {\"epoch\": 41, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.8077919483184814}, {\"epoch\": 42, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.8083580732345581}, {\"epoch\": 43, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.8073973655700684}, {\"epoch\": 44, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.8086325526237488}, {\"epoch\": 45, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.8104510307312012}, {\"epoch\": 46, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.8091472387313843}, {\"epoch\": 47, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.8121665716171265}, {\"epoch\": 48, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.8137620091438293}, {\"epoch\": 49, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.8161980509757996}, {\"epoch\": 50, \"dropout_rate\": 0.5, \"metric\": \"Training Accuracy\", \"value\": 0.8155461549758911}, {\"epoch\": 1, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6760696172714233}, {\"epoch\": 2, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6870023012161255}, {\"epoch\": 3, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6972600817680359}, {\"epoch\": 4, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6996895670890808}, {\"epoch\": 5, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.7050883769989014}, {\"epoch\": 6, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.701849102973938}, {\"epoch\": 7, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.7014442086219788}, {\"epoch\": 8, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6990147233009338}, {\"epoch\": 9, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.7026589512825012}, {\"epoch\": 10, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.7017141580581665}, {\"epoch\": 11, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.701849102973938}, {\"epoch\": 12, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6995546221733093}, {\"epoch\": 13, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6988797187805176}, {\"epoch\": 14, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.7003644108772278}, {\"epoch\": 15, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.7026589512825012}, {\"epoch\": 16, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6967201828956604}, {\"epoch\": 17, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6983398795127869}, {\"epoch\": 18, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.695235550403595}, {\"epoch\": 19, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6980699300765991}, {\"epoch\": 20, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6926710605621338}, {\"epoch\": 21, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6975300312042236}, {\"epoch\": 22, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6915913224220276}, {\"epoch\": 23, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.694830596446991}, {\"epoch\": 24, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6925361156463623}, {\"epoch\": 25, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6921312212944031}, {\"epoch\": 26, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6932109594345093}, {\"epoch\": 27, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6906465291976929}, {\"epoch\": 28, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6930760145187378}, {\"epoch\": 29, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6937508583068848}, {\"epoch\": 30, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6913213729858398}, {\"epoch\": 31, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.687137246131897}, {\"epoch\": 32, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6894317865371704}, {\"epoch\": 33, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6890268325805664}, {\"epoch\": 34, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6913213729858398}, {\"epoch\": 35, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6879470944404602}, {\"epoch\": 36, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6913213729858398}, {\"epoch\": 37, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6890268325805664}, {\"epoch\": 38, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6918612718582153}, {\"epoch\": 39, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6967201828956604}, {\"epoch\": 40, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6938858032226562}, {\"epoch\": 41, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.694830596446991}, {\"epoch\": 42, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6911863684654236}, {\"epoch\": 43, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6945606470108032}, {\"epoch\": 44, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6872722506523132}, {\"epoch\": 45, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6879470944404602}, {\"epoch\": 46, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6895667314529419}, {\"epoch\": 47, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.687137246131897}, {\"epoch\": 48, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6898366808891296}, {\"epoch\": 49, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6890268325805664}, {\"epoch\": 50, \"dropout_rate\": 0.5, \"metric\": \"Validation Accuracy\", \"value\": 0.6888918876647949}, {\"epoch\": 1, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.8382617235183716}, {\"epoch\": 2, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.7543562650680542}, {\"epoch\": 3, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.7185790538787842}, {\"epoch\": 4, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.6848758459091187}, {\"epoch\": 5, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.6608853340148926}, {\"epoch\": 6, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.6434482336044312}, {\"epoch\": 7, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.630081295967102}, {\"epoch\": 8, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.6152816414833069}, {\"epoch\": 9, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.6009689569473267}, {\"epoch\": 10, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5956605672836304}, {\"epoch\": 11, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5867751240730286}, {\"epoch\": 12, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5769096612930298}, {\"epoch\": 13, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5738316178321838}, {\"epoch\": 14, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5647697448730469}, {\"epoch\": 15, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5585906505584717}, {\"epoch\": 16, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5521462559700012}, {\"epoch\": 17, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5505836009979248}, {\"epoch\": 18, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.542447566986084}, {\"epoch\": 19, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5383833646774292}, {\"epoch\": 20, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5342423319816589}, {\"epoch\": 21, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5313655138015747}, {\"epoch\": 22, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5236591696739197}, {\"epoch\": 23, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5197741985321045}, {\"epoch\": 24, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5188302397727966}, {\"epoch\": 25, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.511206328868866}, {\"epoch\": 26, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5169118046760559}, {\"epoch\": 27, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5093792080879211}, {\"epoch\": 28, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5087223052978516}, {\"epoch\": 29, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.507478654384613}, {\"epoch\": 30, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.500279426574707}, {\"epoch\": 31, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.5006074905395508}, {\"epoch\": 32, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.49654197692871094}, {\"epoch\": 33, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.49461624026298523}, {\"epoch\": 34, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.491985023021698}, {\"epoch\": 35, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.4874874949455261}, {\"epoch\": 36, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.491166889667511}, {\"epoch\": 37, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.48879557847976685}, {\"epoch\": 38, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.485632985830307}, {\"epoch\": 39, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.4849940538406372}, {\"epoch\": 40, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.4840930700302124}, {\"epoch\": 41, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.4779661297798157}, {\"epoch\": 42, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.47422802448272705}, {\"epoch\": 43, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.47411632537841797}, {\"epoch\": 44, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.4720032811164856}, {\"epoch\": 45, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.4718914330005646}, {\"epoch\": 46, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.4705215394496918}, {\"epoch\": 47, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.46581676602363586}, {\"epoch\": 48, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.4602280259132385}, {\"epoch\": 49, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.45895740389823914}, {\"epoch\": 50, \"dropout_rate\": 0.5, \"metric\": \"Training Loss\", \"value\": 0.46115800738334656}, {\"epoch\": 1, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7676148414611816}, {\"epoch\": 2, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7440410852432251}, {\"epoch\": 3, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7181621789932251}, {\"epoch\": 4, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7063391804695129}, {\"epoch\": 5, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.700800895690918}, {\"epoch\": 6, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.6990495920181274}, {\"epoch\": 7, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7006328701972961}, {\"epoch\": 8, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7009606957435608}, {\"epoch\": 9, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7044501304626465}, {\"epoch\": 10, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7073958516120911}, {\"epoch\": 11, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.707310140132904}, {\"epoch\": 12, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7103360891342163}, {\"epoch\": 13, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7169012427330017}, {\"epoch\": 14, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.712893009185791}, {\"epoch\": 15, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7144888043403625}, {\"epoch\": 16, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7190927267074585}, {\"epoch\": 17, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7206514477729797}, {\"epoch\": 18, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7288510799407959}, {\"epoch\": 19, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7274888157844543}, {\"epoch\": 20, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7316837906837463}, {\"epoch\": 21, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7273582220077515}, {\"epoch\": 22, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7329021096229553}, {\"epoch\": 23, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7330037951469421}, {\"epoch\": 24, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7353145480155945}, {\"epoch\": 25, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7462829351425171}, {\"epoch\": 26, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.742382824420929}, {\"epoch\": 27, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7391228675842285}, {\"epoch\": 28, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7451292276382446}, {\"epoch\": 29, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7441686391830444}, {\"epoch\": 30, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7560864686965942}, {\"epoch\": 31, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7540863752365112}, {\"epoch\": 32, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7606079578399658}, {\"epoch\": 33, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.760508120059967}, {\"epoch\": 34, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7553398013114929}, {\"epoch\": 35, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7621000409126282}, {\"epoch\": 36, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7677052021026611}, {\"epoch\": 37, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7693923115730286}, {\"epoch\": 38, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7680584788322449}, {\"epoch\": 39, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7717211842536926}, {\"epoch\": 40, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7600234150886536}, {\"epoch\": 41, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7766127586364746}, {\"epoch\": 42, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7765710353851318}, {\"epoch\": 43, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7805548310279846}, {\"epoch\": 44, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7971585392951965}, {\"epoch\": 45, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7877622246742249}, {\"epoch\": 46, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7802280783653259}, {\"epoch\": 47, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7832664847373962}, {\"epoch\": 48, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.7963047623634338}, {\"epoch\": 49, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.8111678957939148}, {\"epoch\": 50, \"dropout_rate\": 0.5, \"metric\": \"Validation Loss\", \"value\": 0.8005502820014954}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "dropout_rates = [0.25, 0.5]\n",
    "\n",
    "# Prepare a DataFrame to collect all metrics for plotting\n",
    "df_all_models = pd.DataFrame()\n",
    "\n",
    "for rate in dropout_rates:\n",
    "    print(f\"\\nTraining model with dropout rate {rate}\")\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=(462,)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(rate),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(rate),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': range(1, 51),\n",
    "        'training_accuracy': history.history['accuracy'],\n",
    "        'validation_accuracy': history.history['val_accuracy'],\n",
    "        'training_loss': history.history['loss'],\n",
    "        'validation_loss': history.history['val_loss'],\n",
    "        'dropout_rate': [rate] * 50\n",
    "    })\n",
    "    \n",
    "    # Melt the dataframe for long format\n",
    "    df_long = df.melt(id_vars=['epoch', 'dropout_rate'], \n",
    "                      value_vars=['training_accuracy', 'validation_accuracy', 'training_loss', 'validation_loss'],\n",
    "                      var_name='metric', value_name='value')\n",
    "    \n",
    "    # Concatenate all data\n",
    "    df_all_models = pd.concat([df_all_models, df_long], ignore_index=True)\n",
    "\n",
    "# Define the color mapping for metrics\n",
    "color_mapping = {\n",
    "    'training_accuracy': 'Training Accuracy',\n",
    "    'validation_accuracy': 'Validation Accuracy',\n",
    "    'training_loss': 'Training Loss',\n",
    "    'validation_loss': 'Validation Loss'\n",
    "}\n",
    "\n",
    "df_all_models['metric'] = df_all_models['metric'].map(color_mapping)\n",
    "\n",
    "# Altair plot: Interactive plot for all models\n",
    "chart = alt.Chart(df_all_models).mark_line().encode(\n",
    "    x='epoch',\n",
    "    y='value',\n",
    "    color='metric',\n",
    "    column='dropout_rate:O',  # Separate charts for each dropout rate\n",
    "    tooltip=['epoch', 'value', 'metric', 'dropout_rate']\n",
    ").properties(\n",
    "    title=\"Model Performance: Accuracy & Loss for Different Dropout Rates\",\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "chart.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph generated in the cell above displays the model performance in terms of accuracy and loss for different dropout rates (0.25 and 0.5). Here are the key observations:\n",
    "\n",
    "### Dropout Rate 0.25:\n",
    "- **Training Accuracy**: The training accuracy increases steadily over the epochs, indicating that the model is learning the training data well.\n",
    "- **Validation Accuracy**: The validation accuracy also improves initially but starts to plateau and slightly decrease after a certain number of epochs, suggesting the onset of overfitting.\n",
    "- **Training Loss**: The training loss decreases consistently, showing that the model is minimizing the error on the training data.\n",
    "- **Validation Loss**: The validation loss decreases initially but starts to increase after a certain number of epochs, indicating overfitting.\n",
    "\n",
    "### Dropout Rate 0.5:\n",
    "- **Training Accuracy**: The training accuracy increases but at a slower rate compared to the dropout rate of 0.25. This is expected as a higher dropout rate introduces more regularization, making it harder for the model to overfit the training data.\n",
    "- **Validation Accuracy**: The validation accuracy shows a similar trend, improving initially but plateauing earlier than the dropout rate of 0.25.\n",
    "- **Training Loss**: The training loss decreases but at a slower rate compared to the dropout rate of 0.25, indicating that the model is learning more slowly due to the higher dropout rate.\n",
    "- **Validation Loss**: The validation loss decreases initially but starts to increase earlier than the dropout rate of 0.25, indicating overfitting.\n",
    "\n",
    "### General Observations:\n",
    "- **Overfitting**: Both dropout rates show signs of overfitting, as indicated by the increasing validation loss after a certain number of epochs. However, the dropout rate of 0.5 seems to mitigate overfitting better than the dropout rate of 0.25, as the validation loss starts to increase later and the validation accuracy remains more stable.\n",
    "- **Regularization Effect**: The higher dropout rate (0.5) introduces more regularization, which helps in reducing overfitting but also slows down the learning process, as seen from the slower increase in training accuracy and slower decrease in training loss.\n",
    "\n",
    "In conclusion, while both dropout rates help in regularizing the model and reducing overfitting, the dropout rate of 0.5 appears to be more effective in this regard. However, it also slows down the learning process, which is a trade-off to consider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        - Early stopping is a regularization technique in neural network training wherein the process is halted when validation set performance starts to decline, thus preventing overfitting by avoiding the learning of noise in the training data. From all the experiments conducted thus far, choose **one** configuration (the number of layers, number of nodes, activation function, L2 penalty, and dropout layers) that yielded the best performance. Use a graph of loss and accuracy to determine the optimal number of training iterations for this network. What is the optimal number of epochs for this network configuration and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 823us/step - accuracy: 0.6221 - loss: 0.8746 - val_accuracy: 0.6830 - val_loss: 0.7849\n",
      "Epoch 2/100\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.7008 - loss: 0.7475 - val_accuracy: 0.6955 - val_loss: 0.7530\n",
      "Epoch 3/100\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.7264 - loss: 0.7013 - val_accuracy: 0.7045 - val_loss: 0.7428\n",
      "Epoch 4/100\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 887us/step - accuracy: 0.7441 - loss: 0.6690 - val_accuracy: 0.7047 - val_loss: 0.7487\n",
      "Epoch 5/100\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - accuracy: 0.7584 - loss: 0.6432 - val_accuracy: 0.7016 - val_loss: 0.7665\n",
      "Epoch 6/100\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.7690 - loss: 0.6258 - val_accuracy: 0.6987 - val_loss: 0.7824\n",
      "Epoch 7/100\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.7783 - loss: 0.6092 - val_accuracy: 0.6982 - val_loss: 0.7929\n",
      "Epoch 8/100\n",
      "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 0.7852 - loss: 0.5979 - val_accuracy: 0.6997 - val_loss: 0.8048\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-63e7c2cd648749f48e3143735ab43cc3.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-63e7c2cd648749f48e3143735ab43cc3.vega-embed details,\n",
       "  #altair-viz-63e7c2cd648749f48e3143735ab43cc3.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-63e7c2cd648749f48e3143735ab43cc3\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-63e7c2cd648749f48e3143735ab43cc3\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-63e7c2cd648749f48e3143735ab43cc3\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"vconcat\": [{\"data\": {\"name\": \"data-9a6298e9826448b7ce63ef180d81d83b\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Model Accuracy with Early Stopping\", \"width\": 400}, {\"data\": {\"name\": \"data-0d8709972d84643a9faa2815220521d7\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"epoch\", \"type\": \"quantitative\"}, {\"field\": \"value\", \"type\": \"quantitative\"}, {\"field\": \"metric\", \"type\": \"nominal\"}], \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Model Loss with Early Stopping\", \"width\": 400}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-9a6298e9826448b7ce63ef180d81d83b\": [{\"epoch\": 1, \"metric\": \"Training Accuracy\", \"value\": 0.6593642234802246}, {\"epoch\": 2, \"metric\": \"Training Accuracy\", \"value\": 0.7044483423233032}, {\"epoch\": 3, \"metric\": \"Training Accuracy\", \"value\": 0.7262870669364929}, {\"epoch\": 4, \"metric\": \"Training Accuracy\", \"value\": 0.7438197731971741}, {\"epoch\": 5, \"metric\": \"Training Accuracy\", \"value\": 0.7574239373207092}, {\"epoch\": 6, \"metric\": \"Training Accuracy\", \"value\": 0.7668079137802124}, {\"epoch\": 7, \"metric\": \"Training Accuracy\", \"value\": 0.7783705592155457}, {\"epoch\": 8, \"metric\": \"Training Accuracy\", \"value\": 0.7851812243461609}, {\"epoch\": 1, \"metric\": \"Validation Accuracy\", \"value\": 0.6829531788825989}, {\"epoch\": 2, \"metric\": \"Validation Accuracy\", \"value\": 0.6955054402351379}, {\"epoch\": 3, \"metric\": \"Validation Accuracy\", \"value\": 0.7045485377311707}, {\"epoch\": 4, \"metric\": \"Validation Accuracy\", \"value\": 0.7046834826469421}, {\"epoch\": 5, \"metric\": \"Validation Accuracy\", \"value\": 0.7015791535377502}, {\"epoch\": 6, \"metric\": \"Validation Accuracy\", \"value\": 0.6987447738647461}, {\"epoch\": 7, \"metric\": \"Validation Accuracy\", \"value\": 0.6982048749923706}, {\"epoch\": 8, \"metric\": \"Validation Accuracy\", \"value\": 0.6996895670890808}], \"data-0d8709972d84643a9faa2815220521d7\": [{\"epoch\": 1, \"metric\": \"Training Loss\", \"value\": 0.8215991854667664}, {\"epoch\": 2, \"metric\": \"Training Loss\", \"value\": 0.7446820139884949}, {\"epoch\": 3, \"metric\": \"Training Loss\", \"value\": 0.6993275880813599}, {\"epoch\": 4, \"metric\": \"Training Loss\", \"value\": 0.6694546937942505}, {\"epoch\": 5, \"metric\": \"Training Loss\", \"value\": 0.644518256187439}, {\"epoch\": 6, \"metric\": \"Training Loss\", \"value\": 0.6269394159317017}, {\"epoch\": 7, \"metric\": \"Training Loss\", \"value\": 0.6104992628097534}, {\"epoch\": 8, \"metric\": \"Training Loss\", \"value\": 0.5999084115028381}, {\"epoch\": 1, \"metric\": \"Validation Loss\", \"value\": 0.7849003076553345}, {\"epoch\": 2, \"metric\": \"Validation Loss\", \"value\": 0.7530295848846436}, {\"epoch\": 3, \"metric\": \"Validation Loss\", \"value\": 0.7428429126739502}, {\"epoch\": 4, \"metric\": \"Validation Loss\", \"value\": 0.7487108707427979}, {\"epoch\": 5, \"metric\": \"Validation Loss\", \"value\": 0.7665003538131714}, {\"epoch\": 6, \"metric\": \"Validation Loss\", \"value\": 0.7823922634124756}, {\"epoch\": 7, \"metric\": \"Validation Loss\", \"value\": 0.7928832173347473}, {\"epoch\": 8, \"metric\": \"Validation Loss\", \"value\": 0.804822564125061}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of epochs is 8\n"
     ]
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "# Define the model with the best configuration\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(462,)),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(1e-4)),\n",
    "    Dropout(0.25),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(1e-4)),\n",
    "    Dropout(0.25),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Prepare data for plotting\n",
    "epochs_range = range(1, len(history.history['accuracy']) + 1)\n",
    "df = pd.DataFrame({\n",
    "    'epoch': epochs_range,\n",
    "    'training_accuracy': history.history['accuracy'],\n",
    "    'validation_accuracy': history.history['val_accuracy'],\n",
    "    'training_loss': history.history['loss'],\n",
    "    'validation_loss': history.history['val_loss']\n",
    "})\n",
    "\n",
    "# Melt the dataframe for long format\n",
    "df_long = df.melt(id_vars=['epoch'], \n",
    "                  value_vars=['training_accuracy', 'validation_accuracy', 'training_loss', 'validation_loss'],\n",
    "                  var_name='metric', value_name='value')\n",
    "\n",
    "# Define the color mapping for metrics\n",
    "color_mapping = {\n",
    "    'training_accuracy': 'Training Accuracy',\n",
    "    'validation_accuracy': 'Validation Accuracy',\n",
    "    'training_loss': 'Training Loss',\n",
    "    'validation_loss': 'Validation Loss'\n",
    "}\n",
    "\n",
    "df_long['metric'] = df_long['metric'].map(color_mapping)\n",
    "\n",
    "# Altair plot: Interactive plot for accuracy and loss\n",
    "accuracy_chart = alt.Chart(df_long[df_long['metric'].str.contains('Accuracy')]).mark_line().encode(\n",
    "    x='epoch',\n",
    "    y='value',\n",
    "    color='metric',\n",
    "    tooltip=['epoch', 'value', 'metric']\n",
    ").properties(\n",
    "    title=\"Model Accuracy with Early Stopping\",\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "loss_chart = alt.Chart(df_long[df_long['metric'].str.contains('Loss')]).mark_line().encode(\n",
    "    x='epoch',\n",
    "    y='value',\n",
    "    color='metric',\n",
    "    tooltip=['epoch', 'value', 'metric']\n",
    ").properties(\n",
    "    title=\"Model Loss with Early Stopping\",\n",
    "    width=400,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Display the charts\n",
    "(accuracy_chart & loss_chart).display()\n",
    "\n",
    "print(f\"The optimal number of epochs is {len(epochs_range)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "9. **Model Comparison**:\n",
    "\n",
    "    - Evaluate the baseline model on the test set, using the optimal parameter set identified through grid search. Additionally, apply your best-performing neural network configuration to the test set.\n",
    "\n",
    "    - Quantify the performance of the baseline model (best hyperparameter configuration) and your neural network (best configuration) using precision, recall, and F1-score as metrics. How do these two models compare to the dummy model?\n",
    "\n",
    "    - Provide recommendations on which model(s) to choose for this task and justify your choices based on the analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the Baseline Model on the Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76      2528\n",
      "           1       0.70      0.56      0.62      1852\n",
      "           2       0.70      0.75      0.73      3052\n",
      "\n",
      "    accuracy                           0.72      7432\n",
      "   macro avg       0.71      0.70      0.70      7432\n",
      "weighted avg       0.71      0.72      0.71      7432\n",
      "\n",
      "\n",
      "Performance of the Neural Network on the Test Set:\n",
      "Loss: 0.6768\n",
      "Accuracy: 0.7382\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      2528\n",
      "           1       0.71      0.63      0.67      1852\n",
      "           2       0.71      0.77      0.74      3052\n",
      "\n",
      "    accuracy                           0.74      7432\n",
      "   macro avg       0.74      0.73      0.73      7432\n",
      "weighted avg       0.74      0.74      0.74      7432\n",
      "\n",
      "\n",
      "Performance of the Dummy Model on the Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2528\n",
      "           1       0.00      0.00      0.00      1852\n",
      "           2       0.41      1.00      0.58      3052\n",
      "\n",
      "    accuracy                           0.41      7432\n",
      "   macro avg       0.14      0.33      0.19      7432\n",
      "weighted avg       0.17      0.41      0.24      7432\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ismail/Documents/Study/CSI4106/Assignments/A3/A3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the best Logistic Regression model on the test set\n",
    "best_log_reg = grid_search_lr.best_estimator_\n",
    "y_pred_log_reg = best_log_reg.predict(X_test)\n",
    "\n",
    "print(\"Performance of the Baseline Model on the Test Set:\")\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "\n",
    "# Evaluate the best Neural Network model on the test set\n",
    "nn_eval_test = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"\\nPerformance of the Neural Network on the Test Set:\")\n",
    "print(f\"Loss: {nn_eval_test[0]:.4f}\")\n",
    "print(f\"Accuracy: {nn_eval_test[1]:.4f}\")\n",
    "\n",
    "# Predict using the neural network\n",
    "y_pred_nn = model.predict(X_test)\n",
    "y_pred_nn_classes = np.argmax(y_pred_nn, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_nn_classes))\n",
    "\n",
    "# Evaluate the Dummy Classifier on the test set\n",
    "y_pred_dummy = dummy_classifier.predict(X_test)\n",
    "print(\"\\nPerformance of the Dummy Model on the Test Set:\")\n",
    "print(classification_report(y_test, y_pred_dummy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/)\n",
    "- [NumPy Documentation](https://numpy.org/doc/)\n",
    "- [Matplotlib Documentation](https://matplotlib.org/stable/contents.html)\n",
    "- [Scikit-learn Documentation](https://scikit-learn.org/stable/documentation.html)\n",
    "- [TensorFlow Documentation](https://www.tensorflow.org/api_docs)\n",
    "- [Keras Documentation](https://keras.io/api/)\n",
    "- [Altair Documentation](https://altair-viz.github.io/)\n",
    "- [GeeksforGeeks: Pandas - How to Shuffle a DataFrame Rows](https://www.geeksforgeeks.org/pandas-how-to-shuffle-a-dataframe-rows/)\n",
    "- [GeeksforGeeks: Logistic Regression](https://www.geeksforgeeks.org/logistic-regression-using-python/)\n",
    "- [GeeksforGeeks: Neural Networks](https://www.geeksforgeeks.org/neural-networks/)\n",
    "- [GeeksforGeeks: Cross-Validation](https://www.geeksforgeeks.org/cross-validation-machine-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "A3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
